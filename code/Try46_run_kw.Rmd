---
title: "Untitled"
author: "Felix"
date: "1/29/2026"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r pkgs}

pacman::p_load(
  MASS,
  dplyr,
  tibble,
  purrr,
  readr,
  ggplot2,
  tidyr,
  broom,
  here,
  scales,
  furrr  # parallel version of purrr
)

dt <- lubridate::today()
#dir.create("results", showWarnings = FALSE)
#dir.create("figures", showWarnings = FALSE)

plan(multisession, workers = 4) # use 4 cores 

```

# ======================================================
# Monte Carlo for Two-Part Model with Extreme Treatments
# (UPDATED: shared COEF + zPCS + RQ4 ATT + factorial ANOVA + plots)
# ======================================================

# ------------------------------------------------------
# 0) ONE SOURCE OF TRUTH: DGP COEFFICIENTS (Try45-aligned)
# ------------------------------------------------------
# Matches your original DGP:
# Part 1: 0.2*post - 0.2*tx + 1.2*female - 0.8*hisp - 0.2*zPCS
# Part 2: 7 + 0.2*post + 0.2*tx + 0.4*female - 0.2*hisp - 0.4*zPCS
# NOTE: Your original DGP has NO post*tx interaction (int = 0).
```{r coefs_helpers}
COEF <- list(
  p1 = list(b0 = 0.0, post = 0.2, tx = -0.2, int = 0.0,
            female = 1.2, hisp = -0.8, zpcs = -0.2),
  p2 = list(b0 = 7.0, post = 0.2, tx =  0.2, int = 0.0,
            female = 0.4, hisp = -0.2, zpcs = -0.4)
)

# --- helper: log-uniform draw for extremes ---
rlogunif <- function(n, min_val, max_val) {
  if (n <= 0) return(numeric(0))
  exp(runif(n, log(min_val), log(max_val)))
}

# --- helper: extreme value ranges ---
extreme_range <- function(mag_level) {
  switch(as.character(mag_level),
         "1" = c(5e4, 1e6),
         "2" = c(5e4, 2e6),
         "3" = c(5e4, 3e6),
         stop("Invalid magnitude_level"))
}

```



------------------------------------------------------
1) DGP: two-part Gamma with extremes (UPDATED to use COEF)
------------------------------------------------------

 - Creates a 2-period panel (pre/post) for n individuals  
 - time indicator: ind_post (0 for pre, 1 for post)  
 - Baseline Covariates (time-invariant, assigned at individual level), all replicated across both time periods using `rep(., each=T)`  
    - Treatment assignment, 50% probability  
    - Female: 50% probability  
    - Hispanic: 20% probability  
  - Health Status (PCS42) with temporal correlation:  
    - Generates correlated Physical Component Scores across the 2 periods  
    - Uses bivariate normal wth correlation `rho=0.5`  
    - Mean 50, then standardizes to zPCS (mean 0, SD 10)  
    - To capture realistic correlation in health status over time  
  - Random effects generated, but not actually used in linear predictors  
  - TPM part 2: gamma distribution with fixed shape = 3, scale adjusted for each observation (gamma's 2 parameterizations: Shape-Rate [`shape` and `rate`] and Shape-Scale [`shape` and `scale` > what this code is using...]). Their relationship is `mean=shape*scale`. In code, for each observation, the shape parameter stays constant (at 3) but scale parameter varies based on that observation's covariates to ensure `E[TOTEXPYY | covariates] = mu = exp(lp_cont)`. All obs will have the same shape (to control distributional form / variance) but different scales (controls the mean). This is how to implement a GLM-style Gamma regression where the mean depends on covars but the coeff. of variation stays constant.  
  

```{r dgp}
simulate_panel_data <- function(
  n, magnitude_level, prop_extreme = 0.01,
  p_treated = 0.5, sigma_u = 0.5, rho = 0.5,
  gamma_shape = 3,
  COEF
) {
  T <- 2; N <- n * T
  ids <- rep(1:n, each = T)
  ind_post <- rep(0:1, times = n)

  # covariates
  ind_tx_i     <- rbinom(n, 1, p_treated)
  ind_female_i <- rbinom(n, 1, 0.5)
  HISPANX_i    <- rbinom(n, 1, 0.2)
  #INSCOV_i     <- sample(1:3, n, replace = TRUE)

  ind_tx     <- rep(ind_tx_i, each = T)
  ind_female <- rep(ind_female_i, each = T)
  HISPANX    <- rep(HISPANX_i, each = T)
  #INSCOV     <- factor(rep(INSCOV_i, each = T))

  # PCS42 with correlation (keep your approach)
  Sigma <- matrix(c(1, rho, rho, 1), 2, 2)
  pcs   <- MASS::mvrnorm(n, mu = c(50, 50), Sigma = Sigma)
  PCS42 <- as.vector(t(pcs))
  zPCS  <- (PCS42 - 50) / 10  # standardized PCS42

  # random intercept (kept for fidelity; not used in lp by design)
  u_i <- rnorm(n, 0, sigma_u)
  u   <- u_i[ids]

  # Part 1: logistic >0 (use COEF)
  lp_cov <- COEF$p1$b0 +
    COEF$p1$post   * ind_post +
    COEF$p1$tx     * ind_tx +
    COEF$p1$int    * (ind_post * ind_tx) +
    COEF$p1$female * ind_female +
    COEF$p1$hisp   * HISPANX +
    COEF$p1$zpcs   * zPCS

  pr_pos  <- plogis(lp_cov)
  ind_gt0 <- rbinom(N, 1, pr_pos)

  # Part 2: Gamma for positives (use COEF)
  lp_cont <- COEF$p2$b0 +
    COEF$p2$post   * ind_post +
    COEF$p2$tx     * ind_tx +
    COEF$p2$int    * (ind_post * ind_tx) +
    COEF$p2$female * ind_female +
    COEF$p2$hisp   * HISPANX +
    COEF$p2$zpcs   * zPCS

  mu <- exp(lp_cont)
  shape <- gamma_shape
  scale <- mu / shape

  TOTEXPYY <- rep(0, N)
  TOTEXPYY[ind_gt0 == 1] <- rgamma(sum(ind_gt0),
                                   shape = shape,
                                   scale = scale[ind_gt0 == 1])

  # inject extremes
  K_ext <- rbinom(1, N, prop_extreme)
  if (K_ext > 0) {
    rng <- extreme_range(magnitude_level)
    idx_ext <- sample.int(N, size = K_ext, replace = FALSE)
    TOTEXPYY[idx_ext] <- rlogunif(K_ext, rng[1], rng[2])
  } else idx_ext <- integer(0)

  tibble(
    DUPERSID = factor(ids),
    ind_post, ind_tx, ind_female, HISPANX, PCS42, zPCS, #INSCOV,
    ind_gt0 = ind_gt0,
    TOTEXPYY = TOTEXPYY,
    extreme_flag = as.integer(seq_len(N) %in% idx_ext),
    magnitude_level, 
    prop_extreme
  )
}


```



# ------------------------------------------------------
# 2) Treatments for extreme values (UPDATED)
# - mean/median preserved uses values > q95 only
# - truncation removes rows (not NA)
# ------------------------------------------------------

```{r treatments}
treat_extremes_df <- function(dat, method = "raw") {
  if (method == "raw") return(dat)

  q95 <- quantile(dat$TOTEXPYY, 0.95, na.rm = TRUE)

  if (method == "topcode") {
    dat$TOTEXPYY <- pmin(dat$TOTEXPYY, q95)
    return(dat)
  }

  if (method == "mean_adj") {
    m <- mean(dat$TOTEXPYY[dat$TOTEXPYY > q95], na.rm = TRUE)
    dat$TOTEXPYY[dat$TOTEXPYY > q95] <- m
    return(dat)
  }

  if (method == "median_adj") {
    m <- median(dat$TOTEXPYY[dat$TOTEXPYY > q95], na.rm = TRUE)
    dat$TOTEXPYY[dat$TOTEXPYY > q95] <- m
    return(dat)
  }

  if (method == "truncate") {
    dat <- dat %>% filter(TOTEXPYY <= q95)
    return(dat)
  }

  stop("Unknown treatment method")
}

```



# ------------------------------------------------------
# 3) Safe Gamma fit wrapper (UPDATED to use zPCS)
# ------------------------------------------------------  
Fit a gamma GLM to estimate DiD effect on positive expenditures only. Returns NULL if fewer than 10 positive observations (prevents fitting issues with tiny samples). Will handle edge cases gracefully in simulations.  
- Link function: `log` (coefficients are interpretable as *log-rate ratios*)  
    - log(E[Y|x]]) = $\beta_0$ + ... 
    OR  
    - E[Y|X] = exp($\beta_0$ + ... )  
    
Interpreting Coefficients  

For a coefficient $\beta$:  
  - The outcome changes by a **multiplicative factor** of exp($\beta$)  
  - exp($\beta$) is called a *rate ratio* or a *relative rate *  
  - Examples from model:  
    - If $\beta$_female = 0.4, then `exp(0.4)`$\approx$`1.49`, meaning Females have expenditures that are 1.49x (or 49% higher) than males, adjusting for other factors.  
    - If $\beta$_hisp = -0.2, then `exp(-0.2)`$\approx$`0.82`, or 18% lower than non-Hispanic, adjusting for other factors.  
    - The DiD coefficient $\beta$`_post:tx`: If you estimate $\beta$`_post:tx`$\approx$`0.15`, then `exp(0.15)`$\approx$`1.16`, meaning that the treatment increases expenditures by 16% in the post-period relative to the control group. Since our true `COEF$p2$int=0`, we expect `exp(`$\beta$`)`$\approx$`1.0` (no multiplicative effect).  
    
Log-rate ratios  
  - The coefficient itself ($\beta$) is the **log** of the rate ratio  
  - The exponentiated coefficient `exp(`$\beta$`)` is the rate ratio.  
  
In the DGP:  
  - `COEF$p2$int=0` means log-rate ratio=0  
  - This means the rate-ratio = exp(0) = 1  
  - This means no multiplicative effect (0% change)  
  
This is different from linear models where coefficients are additive differences (i.e. a 1-unit increase in X leads to a $\beta_1$-unit increase in Y; this is an additive (absolute) difference, so adds to Y > like if $\beta_1$=500, the X increasing from 0 to 1 means Y increases from 5,000 to 5,000 dollars. The absolute change is constance, regardless of baseline). Here they're multiplicative factors on the original scale.)  

In Gamma GLM with log link - multiplicative effects, where:  
  - `log(E[Y|X]) = `$\beta_0$ + $\beta_1$*X  
  - E[Y|X] = exp($\beta_0$ + $\beta_1$\*X) = exp($\beta_0$) x exp($\beta_1$*X)  
Interpretation of $\beta_1$:  
  - A 1-unit increase in X leads to multiplying Y by exp($\beta_1$)  
  - This is a multiplicative (relative) difference  
  - Example:  
    - If $\beta_1$ = 0.2, then exp(0.2)$\approx$1.22, so X increasing from 0to 1 means:  
      - Y increases from 5,000 to 6,100 -> +1,110 dollars (22% increase)  
      - Y increases from 10,000 to 12,200 -> +2,200 dollars (22% increase)  
    - The percent change is constant, but the absolute change grows with baseline.  
    
HCE's are naturally multiplicative:  
  - A treatment that increases by $500 means very different things for:  
    - Someone spending $1000/year (50% increase)  
    - Someone spending $50,000/year (1% increase)  
    
The DGP reflects this (`mu <- exp(lp_cont)`)  

Null Hypothesis:  
  - Linear model: DiD effect = 0 means "no dollar difference"  
  - Gamma model: DiD effect = 0 means "no percentage difference" (rate ratio=1)  

```{r safe_gamma_fn}
safe_gamma_fit <- function(dat) {
  dat2 <- dat %>% filter(ind_gt0 == 1, is.finite(TOTEXPYY), TOTEXPYY > 0)
  if (nrow(dat2) < 10) return(NULL)

  out <- tryCatch({
    glm(
      TOTEXPYY ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
      data = dat2,
      family = Gamma(link = "log"),
      control = glm.control(maxit = 100, epsilon = 1e-8)
    )
  }, error = function(e) NULL)

  out
}


```  

```{r es_att}
# 3b) Effect size helper: baseline reference SD
compute_sd_ref <- function(dat, ref = c("control_pre", "pooled_pre", "control_all")) {

  if (missing(dat) || is.null(dat)) {
    stop("compute_sd_ref(): you must pass a data.frame/tibble as 'dat' (e.g., compute_sd_ref(dat, ref='control_pre')).")
  }

  ref <- match.arg(ref)

  dref <- switch(
    ref,
    control_pre = dat %>% dplyr::filter(ind_tx == 0, ind_post == 0),
    pooled_pre  = dat %>% dplyr::filter(ind_post == 0),
    control_all = dat %>% dplyr::filter(ind_tx == 0)
  )

  sd_ref <- sd(dref$TOTEXPYY, na.rm = TRUE)

  # guard against degenerate / invalid SD
  if (!is.finite(sd_ref) || sd_ref <= 0) return(NA_real_)
  sd_ref
}
```



# ------------------------------------------------------
# 4) ATT computation (RQ4): Estimated + TRUE using same COEF
# ------------------------------------------------------

```{r att}

compute_ATT_hat <- function(dat, fit_logit, fit_gamma) {

  treated_post <- dat %>% filter(ind_tx == 1, ind_post == 1)
  if (nrow(treated_post) == 0) return(NA_real_)

  treated_cf <- treated_post %>% mutate(ind_tx = 0)

  # Part 1: Pr(Y>0)
  p_obs <- predict(fit_logit, newdata = treated_post, type = "response")
  p_cf  <- predict(fit_logit, newdata = treated_cf,   type = "response")

  # Part 2: E[Y|Y>0] (Gamma log link; response is on original scale)
  mu_obs <- predict(fit_gamma, newdata = treated_post, type = "response")
  mu_cf  <- predict(fit_gamma, newdata = treated_cf,   type = "response")

  mean(p_obs * mu_obs - p_cf * mu_cf)
}

compute_true_ATT <- function(dat, COEF) {

  treated_post <- dat %>% filter(ind_tx == 1, ind_post == 1)
  if (nrow(treated_post) == 0) return(NA_real_)

  treated_cf <- treated_post %>% mutate(ind_tx = 0)

  # TRUE Part 1
  lp1_obs <- COEF$p1$b0 +
    COEF$p1$post   * treated_post$ind_post +
    COEF$p1$tx     * treated_post$ind_tx +
    COEF$p1$int    * (treated_post$ind_post * treated_post$ind_tx) +
    COEF$p1$female * treated_post$ind_female +
    COEF$p1$hisp   * treated_post$HISPANX +
    COEF$p1$zpcs   * treated_post$zPCS
  p_obs <- plogis(lp1_obs)

  lp1_cf <- COEF$p1$b0 +
    COEF$p1$post   * treated_cf$ind_post +
    COEF$p1$tx     * treated_cf$ind_tx +
    COEF$p1$int    * (treated_cf$ind_post * treated_cf$ind_tx) +
    COEF$p1$female * treated_cf$ind_female +
    COEF$p1$hisp   * treated_cf$HISPANX +
    COEF$p1$zpcs   * treated_cf$zPCS
  p_cf <- plogis(lp1_cf)

  # TRUE Part 2
  lp2_obs <- COEF$p2$b0 +
    COEF$p2$post   * treated_post$ind_post +
    COEF$p2$tx     * treated_post$ind_tx +
    COEF$p2$int    * (treated_post$ind_post * treated_post$ind_tx) +
    COEF$p2$female * treated_post$ind_female +
    COEF$p2$hisp   * treated_post$HISPANX +
    COEF$p2$zpcs   * treated_post$zPCS
  mu_obs <- exp(lp2_obs)

  lp2_cf <- COEF$p2$b0 +
    COEF$p2$post   * treated_cf$ind_post +
    COEF$p2$tx     * treated_cf$ind_tx +
    COEF$p2$int    * (treated_cf$ind_post * treated_cf$ind_tx) +
    COEF$p2$female * treated_cf$ind_female +
    COEF$p2$hisp   * treated_cf$HISPANX +
    COEF$p2$zpcs   * treated_cf$zPCS
  mu_cf <- exp(lp2_cf)

  mean(p_obs * mu_obs - p_cf * mu_cf)
}

```



# ------------------------------------------------------
# 5) One replication under one scenario (UPDATED)
# - uses zPCS in models
# - returns interaction estimates + ATT outputs
# - keeps long format: model = logit/gamma/ATT
# ------------------------------------------------------

```{r runs}
run_one <- function(n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF,
                    es_ref = "control_pre") {

  dat <- simulate_panel_data(
    n = n,
    magnitude_level = magnitude_level,
    prop_extreme = prop_extreme,
    gamma_shape = gamma_shape,
    COEF = COEF
  )

  # Apply treatment at the DATAFRAME level
  dat <- treat_extremes_df(dat, treatment)

  # Logistic
  fit1 <- glm(ind_gt0 ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
              data = dat, family = binomial)
  c1 <- coef(summary(fit1))["ind_post:ind_tx", c("Estimate","Std. Error")]

  # Gamma fit object (safe)
  fit2 <- safe_gamma_fit(dat)
  if (is.null(fit2)) {
    c2 <- c(NA_real_, NA_real_)
  } else {
    c2 <- coef(summary(fit2))["ind_post:ind_tx", c("Estimate","Std. Error")]
  }


  # ATT requires gamma object
  ATT_hat <- if (!is.null(fit2)) compute_ATT_hat(dat, fit1, fit2) else NA_real_
  ATT_true <- compute_true_ATT(dat, COEF)
  ATT_bias <- ATT_hat - ATT_true
  
    # --- Effect size (Cohen's d style): standardize ATT by baseline SD ---
  sd_ref <- compute_sd_ref(dat, ref = es_ref)
  d_hat  <- ifelse(is.na(ATT_hat)  || is.na(sd_ref), NA_real_, ATT_hat  / sd_ref)
  d_true <- ifelse(is.na(ATT_true) || is.na(sd_ref), NA_real_, ATT_true / sd_ref)
  d_bias <- d_hat - d_true


  tibble(
    model = c("logit", "gamma", "ATT"),
    est   = c(unname(c1[1]), unname(c2[1]), ATT_hat),
    se    = c(unname(c1[2]), unname(c2[2]), NA_real_),
    true  = c(COEF$p1$int, COEF$p2$int, ATT_true),
    bias  = c(unname(c1[1]) - COEF$p1$int,
              unname(c2[1]) - COEF$p2$int,
              ATT_bias),
    
    # effect-size columns (only meaningful for ATT row; NA for others)
    d_est  = c(NA_real_, NA_real_, d_hat),
    d_true = c(NA_real_, NA_real_, d_true),
    d_bias = c(NA_real_, NA_real_, d_bias),

    n = n, prop_extreme, magnitude_level, gamma_shape, treatment
  )
}

run_mc <- function(B, n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF, es_ref="control_pre") {
  results <- replicate(
    B,
    run_one(n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF, es_ref=es_ref),
    simplify = FALSE
  )
  bind_rows(results)
}

# ======================================================
# Step 1: Representative dataset (histograms + model fits)
# ======================================================

set.seed(123)
dat_example <- simulate_panel_data(
  n = 5000,
  magnitude_level = 1,
  prop_extreme = 0.05,
  gamma_shape = 3,
  COEF = COEF
)

p1 <- ggplot(dat_example, aes(x = TOTEXPYY)) +
  geom_histogram(bins = 100, fill = "skyblue", color = "black") +
  scale_x_continuous(labels = scales::comma) +
  labs(title = "Histogram of TOTEXPYY", x = "Spending", y = "Count") +
  theme_minimal()

p2 <- ggplot(dat_example, aes(x = TOTEXPYY)) +
  geom_histogram(bins = 100, fill = "seagreen", color = "black") +
  scale_x_log10(labels = scales::comma) +
  labs(title = "Histogram of TOTEXPYY (log scale)", x = "Spending (log)", y = "Count") +
  theme_minimal()

print(p1); print(p2)

fit_logit <- glm(ind_gt0 ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
                 data = dat_example, family = binomial)

fit_gamma <- glm(TOTEXPYY ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
                 data = dat_example %>% filter(ind_gt0 == 1),
                 family = Gamma(link = "log"))

summary(fit_logit)
summary(fit_gamma)

# ======================================================
# Step 2: Full Monte Carlo across scenarios
# ======================================================

n_vals <- c(5000, 10000, 20000)
prop_extreme_vals <- c(0.01, 0.05, 0.10)
magnitude_vals <- c(1, 2, 3)
treatment_methods <- c("raw", "topcode", "mean_adj", "median_adj", "truncate")

grid <- expand.grid(
  n = n_vals,
  prop_extreme = prop_extreme_vals,
  magnitude_level = magnitude_vals,
  treatment = treatment_methods,
  stringsAsFactors = FALSE
)

set.seed(2025)
B <- 500

# all_df <- pmap_dfr(
#   grid,
#   ~ run_mc(B, ..1, ..3, ..2, gamma_shape = 3, ..4, COEF = COEF)
# )

# Effect size reference group choice:
# "control_pre" (recommended), "pooled_pre", or "control_all"
ES_REF <- "control_pre"


all_df <- pmap_dfr(
	grid,
	~ run_mc(B, ..1, ..3, ..2, gamma_shape = 3, ..4, COEF = COEF, es_ref=ES_REF),
	.options = furrr_options(seed=TRUE)
)

# Save raw simulation output
saveRDS(all_df, file = here::here(paste0("results/all_df_", dt, ".RDS")))
write.csv(all_df, file = here::here(paste0("results/all_df_", dt, ".csv")), row.names = FALSE)

# ======================================================
# Summarise results (includes ATT row)
# ======================================================
summ_grid <- all_df %>%
  group_by(model, n, prop_extreme, magnitude_level, treatment) %>%
  summarise(
    mean_est = round(mean(est, na.rm = TRUE), 6),
    mean_true = round(mean(true, na.rm = TRUE), 6),
    bias     = round(mean(bias, na.rm = TRUE), 6),
    emp_se   = round(sd(est, na.rm = TRUE), 6),
    rmse     = round(sqrt(mean((est - true)^2, na.rm = TRUE)), 6),
    coverage = round(mean((est - 1.96*se <= true) &
                          (true <= est + 1.96*se), na.rm = TRUE), 6),
        # Effect size summary (ATT rows only; NA otherwise)
    d_mean   = round(mean(d_est, na.rm = TRUE), 6),
    d_emp_se = round(sd(d_est, na.rm = TRUE), 6),
    d_bias   = round(mean(d_bias, na.rm = TRUE), 6),

    n_fail   = sum(is.na(est)),
    .groups = "drop"
  )

print(summ_grid)

saveRDS(summ_grid, file = here::here(paste0("results/summ_grid_", dt, ".RDS")))
write.csv(summ_grid, file = here::here(paste0("results/summ_grid_", dt, ".csv")), row.names = FALSE)

```

# ======================================================
# #4 FULL-FACTORIAL ANOVA (RQ answers)
# ======================================================

  - `all_df_gamma` function: Isolates gamma results, creates a coverage indicator (1 if 95% CI contains true value, 0 if doesn't)
  
  - **Factorial ANOVA on gamma bias** (`aov(bias ~ ...)`) is testing:  
    - Main effects: Does each factor independently affect bias?  
    - Interactions: Do factors combine to affect bias? (e.g., `treatment:magnitude_level` - does the best treatment change depending on how extreme the outliers are?) with 4-way interaction, tests if optimal strategy depends on all conditions simultaneously  
    - Unit of Analysis: Each individual replication (67500 rows for gamma)  
    
  - **Factorial ANOVA on gamma SE**  
    - Tests which factors affect **precision** of estimates (e.g., does truncation increase SE more than top coding?).  
    - Looking at Bias-variance trade off (one method might reduce bias but inflates variance (hurting RMSE)).   
    
  - **Factorial ANOVA on gamma coverage**  
    - At scenario-level bc coverage is a prop. (between 0 and 1); individual reps have coverage = 0 or 1 (binary), which violates ANOVA assumptions. Aggregating to scenario-level gives approx. normal proportions. Bc each scenario has 500 reps,  coverage estimates stable.  
    - Testing if methods maintain normal coverage (~0.95)? (e.g., does "raw" (with extremes) have poor coverage due to inflated SEs?)  
    - Gold standard / coverage ~ 0.95; systematic deviations like <0.90: Underestimating uncertainty (SEs too small) or 0.97: Overestimating uncertainty (SEs too large, or method too conservative, etc.)  
      
  - **ANOVA on ATT Estimates**  
  Two DV's:  
  1) `aov_att_hat`: Tests if estimated ATT differs across conditions. This is less informative since true ATT = 0, so all methods *should* center near 0.  
  2) `aov_att_bias`: Tests if ATT bias differs across conditions. This is more relevant because it shows which methods better recover truth. It's a direct test of RQ4, "Which treatment method produces least biased ATT estimates?" Ask Tsai if okay to add to RQ term. 
  

```{r aov}

# ---- Gamma (Part 2 interaction): bias, SE, coverage ----
all_df_gamma <- all_df %>%
  dplyr::filter(model == "gamma") %>%
  dplyr::mutate(
    n = factor(n),
    prop_extreme = factor(prop_extreme),
    magnitude_level = factor(magnitude_level),
    treatment = factor(treatment),
    cover_ind = ifelse(is.na(est) | is.na(se), NA_real_,
                       as.numeric((est - 1.96*se <= true) & (true <= est + 1.96*se)))
  )

# A) factorial ANOVA on gamma bias (rep-level)
aov_gamma_bias <- aov(bias ~ treatment * n * prop_extreme * magnitude_level, data = all_df_gamma)
summary(aov_gamma_bias)

# Effect size: 
library(effectsize)
eta_squared(aov_gamma_bias, partial=TRUE) # for partial eta squared (or general?)

# B) factorial ANOVA on gamma SE (rep-level)
aov_gamma_se <- aov(se ~ treatment * n * prop_extreme * magnitude_level, data = all_df_gamma)
summary(aov_gamma_se)

# B v2) factorial ANOVA on gamma emp SE  (vs model SE, bc emp SE is the SD of the 500 est's of the coefficient, not the average of the model SE's, right?)
summ_grid_gamma <- summ_grid |> filter(model=="gamma")
aov_gamma_emp_se <- aov(
	emp_se ~ treatment * n * prop_extreme * magnitude_level, data = summ_grid_gamma )
summary(aov_gamma_emp_se) 

# C) coverage: scenario-level proportion (recommended)
cov_grid <- all_df_gamma %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(coverage = mean(cover_ind, na.rm = TRUE), .groups = "drop")

aov_gamma_cov <- aov(coverage ~ treatment * n * prop_extreme * magnitude_level, data = cov_grid)
summary(aov_gamma_cov)

# ---- ATT (RQ4): ATT_hat and ATT_bias across treatments ----
all_df_att <- all_df %>%
  dplyr::filter(model == "ATT") %>%
  dplyr::mutate(
    n = factor(n),
    prop_extreme = factor(prop_extreme),
    magnitude_level = factor(magnitude_level),
    treatment = factor(treatment)
  )

# ATT_hat across conditions
aov_att_hat <- aov(est ~ treatment * n * prop_extreme * magnitude_level, data = all_df_att)
summary(aov_att_hat)

# ATT_bias across conditions (recommended DV)
aov_att_bias <- aov(bias ~ treatment * n * prop_extreme * magnitude_level, data = all_df_att)
summary(aov_att_bias)

# Effect size (d_est) across conditions (optional but usually helpful)
aov_att_d <- aov(d_est ~ treatment * n * prop_extreme * magnitude_level, data = all_df_att)
summary(aov_att_d)


# Save ANOVA-ready datasets
write.csv(all_df_gamma, file = here::here(paste0("results/all_df_gamma_", dt, ".csv")), row.names = FALSE)
write.csv(all_df_att,   file = here::here(paste0("results/all_df_att_", dt, ".csv")), row.names = FALSE)
write.csv(cov_grid,     file = here::here(paste0("results/cov_grid_", dt, ".csv")), row.names = FALSE)

```



# ======================================================
# Publication-ready plots (faceted)
# ======================================================

```{r}

# ---- 1) Gamma bias by treatment (scenario-level mean bias) ----
gamma_grid <- all_df_gamma %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(
    mean_bias = mean(bias, na.rm = TRUE),
    mean_se   = mean(se, na.rm = TRUE),
    coverage  = mean(cover_ind, na.rm = TRUE),
    .groups = "drop"
  )

p_gamma_bias <- ggplot(gamma_grid, aes(x = treatment, y = mean_bias)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "Gamma (Part 2) Interaction: Mean Bias by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean bias (est - true)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_gamma_bias)
ggsave(here::here(paste0("figures/gamma_bias_by_treatment_", dt, ".png")),
       p_gamma_bias, width = 10, height = 7, dpi = 300)

# ---- 2) Gamma SE by treatment ----
p_gamma_se <- ggplot(gamma_grid, aes(x = treatment, y = mean_se)) +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "Gamma (Part 2) Interaction: Mean Model SE by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean SE"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_gamma_se)
ggsave(here::here(paste0("figures/gamma_se_by_treatment_", dt, ".png")),
       p_gamma_se, width = 10, height = 7, dpi = 300)

# ---- 3) Gamma coverage by treatment ----
p_gamma_cov <- ggplot(gamma_grid, aes(x = treatment, y = coverage)) +
  geom_hline(yintercept = 0.95, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "Gamma (Part 2) Interaction: Coverage by Treatment",
    subtitle = "Dashed line = nominal 0.95; Rows = prop extreme; Cols = magnitude",
    x = "Treatment method",
    y = "Coverage"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_gamma_cov)
ggsave(here::here(paste0("figures/gamma_coverage_by_treatment_", dt, ".png")),
       p_gamma_cov, width = 10, height = 7, dpi = 300)

# ---- 4) ATT_hat by treatment (scenario-level mean ATT_hat) ----
att_grid <- all_df_att %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(
    mean_ATT_hat = mean(est, na.rm = TRUE),
    mean_ATT_bias = mean(bias, na.rm = TRUE),
    .groups = "drop"
  )

p_att_hat <- ggplot(att_grid, aes(x = treatment, y = mean_ATT_hat)) +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "ATT_hat (RQ4): Mean Estimated ATT by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean ATT_hat"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_att_hat)
ggsave(here::here(paste0("figures/att_hat_by_treatment_", dt, ".png")),
       p_att_hat, width = 10, height = 7, dpi = 300)

# ---- 5) ATT_bias by treatment ----
p_att_bias <- ggplot(att_grid, aes(x = treatment, y = mean_ATT_bias)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "ATT_bias (RQ4): Mean ATT Bias by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean ATT bias (ATT_hat - ATT_true)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_att_bias)
ggsave(here::here(paste0("figures/att_bias_by_treatment_", dt, ".png")),
       p_att_bias, width = 10, height = 7, dpi = 300)

# Also export scenario-level grids for tables
write.csv(gamma_grid, file = here::here(paste0("results/gamma_grid_", dt, ".csv")), row.names = FALSE)
write.csv(att_grid,   file = here::here(paste0("results/att_grid_", dt, ".csv")), row.names = FALSE)
```  

