---
title: "Untitled"
author: "Felix"
date: "8/11/2025"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
pacman::p_load(
  dplyr,
  MASS,   # mvnorm
  tibble
)
```  

```{r get_data}
fyc <- readRDS(here::here("data_processed/fyc_processed.RDS"))
```  

Step 1: Get true coefficients to use in sim by applying tpm to empirical dataset, `fyc`  

These models should be exactly the same as the data generating function and the models used to examine bias of applying treatments to the simulated datasets.  

*Note: For now, start without a stochastic component. We will add later if needed.*  

```{r empirical_model}

fn_emp_model <- function(){
  # Part 1: Fit the logistic model for the probability of a non-zero outcome
  model_part1 <- glm(
    formula = ind_gt0 ~ ind_tx*ind_post + ind_tx + ind_post + ind_female + HISPANX + zPCS42 + zMCS42,
    data = fyc,
    family = binomial(link = "logit")
  )
  
  # Part 2: Fit the Gamma model for the positive outcomes only
  sim_positive <- fyc %>% filter(ind_gt0 == 1)
  
  model_part2 <- glm(
    formula = TOTEXPYY ~ ind_tx*ind_post + ind_tx + ind_post+ ind_female + HISPANX + zPCS42 + zMCS42,
    data = sim_positive,
    family = Gamma(link = "log")
  )
  
  list <- list(
    model_part1 = model_part1,
    model_part2 = model_part2
  )
  
  return(list)
  
}
  
emp_model <- fn_emp_model()

```  

```{r}
# get coefficients 
# Extract coefficients
coef_part1 <- emp_model$model_part1$coefficients
coef_part1

saveRDS(coef_part1,
     here::here("data_processed/emp_coef_p1.RDS"))

# need below? maybe later when using stochastic compoents

```

```{r}
coef_part2 <- emp_model$model_part2$coefficients

saveRDS(coef_part2,
     here::here("data_processed/emp_coef_p2.RDS"))

coef_part2
``` 
```{r}

library(tidyr)
pcs_0 <- fyc |> 
  filter(ind_post==0) |> 
  dplyr::select(DUPERSID, pcs_pre=PCS42) |> 
  group_by(DUPERSID) |> 
  mutate(n=n())
pcs_1 <- fyc |> 
  filter(ind_post==1) |> 
  dplyr::select(DUPERSID, pcs_post=PCS42)
pcs_wide <- pcs_0 |> 
  full_join(pcs_1)

# Step 4: Calculate correlation between pre (time_0) and post (time_1)
correlation <- cor(pcs_wide$time_0, pcs_wide$time_1, use = "complete.obs")
print(correlation)

pcs_wide <- tidyr::pivot_wider(
  fyc,
  id_cols = DUPERSID,  # replace with actual subject ID column
  names_from = ind_post,     # replace with actual time column
  values_from = PCS42)   # replace with actual PCS42 value column

# Step 4: Calculate correlation
correlation <- cor(pcs_wide$pre, pcs_wide$post, use = "complete.obs")
print(correlation)

# Step 2: Compute correlation
cor(fyc_wide$PCS42.0, fyc_wide$PCS42.1, use = "complete.obs") #0.5223

# correlation for MCS42: 
cor(fyc_wide$MCS42.0, fyc_wide$MCS42.1, use="complete.obs")   # 0.4704

```


```{r simulator}

# ============================
# Two-part DiD simulator (updated)
# ============================

# Log-uniform sampler for heavy-tailed extremes
rlogunif <- function(n, min_val, max_val) {
  if (n <= 0) return(numeric(0))
  exp(runif(n, log(min_val), log(max_val)))
}

# Map magnitude level -> extreme value range
extreme_range <- function(mag_level) {
  switch(as.character(mag_level),
         "1" = c(5e4, 1e6),
         "2" = c(5e4, 2e6),
         "3" = c(5e4, 3e6),
         stop("Unknown magnitude level. Use 1, 2, or 3.")
  )
}

# ------------------------------
# Main simulator
# ------------------------------
simulate_panel_data <- function(
  n,                        # people (2 rows each: pre/post)
  magnitude_level,          # 1,2,3 -> extreme range
  prop_extreme,             # 0.01, 0.05, 0.10 of ALL rows
  p_treated = 0.5,          # treatment share (balanced by default)
  target_prob = 0.70,       # overall Pr(ind_gt0==1)
  sigma_u = 0.5,            # SD random intercept (person)
  sigma_e = 0.3,            # residual SD for log(TOTEXPYY)
  rho = 0.5,                # pre/post corr for PCS42
  extreme_alloc = c("proportional","equal"), # spread scheme across cells (in expectation)
  fill_zero_for_negative = TRUE,   # if TRUE, set TOTEXPYY=0 when ind_gt0==0
  exact_positives = TRUE           # if TRUE, hit 70% exactly (up to rounding)
) {
  extreme_alloc <- match.arg(extreme_alloc)

  # ----- Panel indices -----
  T <- 2
  N <- n * T
  ids <- rep(1:n, each = T)
  ind_post <- rep(0:1, times = n)

  # ----- Person-level covariates (constant across time) -----
  ind_tx_i     <- rbinom(n, 1, p_treated)
  ind_female_i <- rbinom(n, 1, 0.5)
  HISPANX_i    <- rbinom(n, 1, 0.2)
  INSCOV_i     <- sample(1:3, n, replace = TRUE)

  ind_tx     <- rep(ind_tx_i, each = T)
  ind_female <- rep(ind_female_i, each = T)
  HISPANX    <- rep(HISPANX_i, each = T)
  INSCOV     <- factor(rep(INSCOV_i, each = T))

  # ----- Time-varying PCS42 with pre/post correlation -----
  Sigma <- matrix(c(1, rho, rho, 1), 2, 2)
  pcs   <- MASS::mvrnorm(n, mu = c(50, 50), Sigma = Sigma)
  PCS42 <- as.vector(t(pcs))        # interleave pre, post
  zPCS  <- (PCS42 - 50) / 10        # standardize to avoid huge non-extreme values
  
    # ----- Time-varying MCS42 with pre/post correlation -----
  # Sigma <- matrix(c(1, rho, rho, 1), 2, 2)
  mcs   <- MASS::mvrnorm(n, mu = c(50, 50), Sigma = Sigma)
  MCS42 <- as.vector(t(mpcs))        # interleave pre, post
  zMCS  <- (MCS42 - 50) / 10        # standardize to avoid huge non-extreme values

  # ----- Random intercept per person -----
  u_i <- rnorm(n, 0, sigma_u)
  u   <- u_i[ids]

  # ----- DiD cell ID (for spreading extremes) -----
  # cells: 1=pre-ctrl, 2=pre-tx, 3=post-ctrl, 4=post-tx
  cell_id <- (ind_post * 2) + ind_tx + 1L

  # ----- Sample extreme rows from ALL rows, with random spread across cells -----
  n_ext_total <- floor(prop_extreme * N)
  if (n_ext_total > 0) {
    weights_cell <- if (extreme_alloc == "equal") rep(1, 4) else
      as.integer(table(factor(cell_id, levels = 1:4)))
    w_row <- as.numeric(weights_cell)[cell_id]
    idx_ext <- sample.int(N, size = n_ext_total, replace = FALSE, prob = w_row)
  } else {
    idx_ext <- integer(0)
  }
  n_ext <- length(idx_ext)
  extreme_flag <- integer(N); extreme_flag[idx_ext] <- 1L

  # ----- Part 1: Binary outcome (calibrate to ~30% overall with extremes forced positive) -----
  # Linear predictor WITHOUT intercept on non-extreme rows
  # lp_cov <- 0.5*ind_post + 0.7*ind_tx + 0.2*ind_female - 0.2*HISPANX + 0.1*zPCS + u
  lp_cov <- coef_part1["(Intercept)"] + 
      coef_part1["ind_post"]*ind_post + 
      coef_part1["ind_tx"]*ind_tx + 
      coef_part1["ind_tx:ind_post"]*(ind_post*ind_tx) +
      coef_part1["ind_female"]*ind_female +
      coef_part1["HISPANX"]*HISPANX + 
      coef_part1["zPCS42"]*zPCS + 
      coef_part1["MCS42"]*MCS42
  
  
  # Because extremes are forced positive, adjust target on the remaining rows:
  s <- n_ext / N
  target_rest <- (target_prob - s) / (1 - s)
  eps <- 1e-6
  if (!is.finite(target_rest) || target_rest <= 0 || target_rest >= 1) {
    warning(sprintf("prop_extreme=%.3f with target_prob=%.3f => target_rest=%.3f; clamping.",
                    prop_extreme, target_prob, target_rest))
    target_rest <- min(max(target_rest, eps), 1 - eps)
  }

  nonext <- setdiff(seq_len(N), idx_ext)
  objective_fn <- function(a0) mean(plogis(a0 + lp_cov[nonext])) - target_rest
  lv <- objective_fn(-30); uv <- objective_fn(30)
  if (lv * uv > 0) {
    a0 <- qlogis(target_rest)  # fallback
  } else {
    a0 <- uniroot(objective_fn, lower = -30, upper = 30)$root
  }

  # Build ind_gt0
  ind_gt0 <- integer(N)
  if (exact_positives) {
    # exact count to hit 70% (up to rounding)
    prob_nonext <- plogis(a0 + lp_cov[nonext])
    K_total  <- as.integer(round(target_prob * N))
    K_nonext <- max(0, K_total - n_ext)
    w <- pmax(prob_nonext, 0)
    if (!any(is.finite(w)) || sum(w) == 0) w <- rep(1, length(w))
    sel_nonext <- if (K_nonext > 0) sample(nonext, size = K_nonext, replace = FALSE, prob = w) else integer(0)
    ind_gt0[idx_ext]    <- 1L
    ind_gt0[sel_nonext] <- 1L
  } else {
    # in expectation
    prob_nonext <- plogis(a0 + lp_cov[nonext])
    ind_gt0[nonext] <- rbinom(length(nonext), 1, prob_nonext)
    ind_gt0[idx_ext] <- 1L
  }

  # ----- Part 2: Continuous outcome (on positives) -----
  # lp_cont <- 7 + 0.4*ind_post + 0.6*ind_tx + 0.15*zPCS + 
  #            0.2*ind_female - 0.1*HISPANX + u
    lp_cont <- 7 + 
    coef_part2["ind_post"]*ind_post + 
    coef_part2["ind_tx"]*ind_tx + 
    coef_part2["ind_tx:ind_post"]*(ind_tx*ind_post) + 
    coef_part2["ind_female"]*ind_female + 
    coef_part2["HISPANX"]*HISPANX + 
    coef_part2["zPCS42"]*zPCS + 
    coef_part2["zMCS42"]*zMCS
  
  eps_e <- rnorm(N, 0, sigma_e)
  log_TOT <- lp_cont + eps_e

  if (fill_zero_for_negative) {
    TOTEXPYY <- ifelse(ind_gt0 == 1, exp(log_TOT), 0)
  } else {
    TOTEXPYY <- ifelse(ind_gt0 == 1, exp(log_TOT), NA_real_)
  }

  # Overwrite extremes with magnitude-specific heavy tail
  if (n_ext > 0) {
    rng <- extreme_range(magnitude_level)
    TOTEXPYY[idx_ext] <- rlogunif(n_ext, rng[1], rng[2])
  }

  tibble(
    DUPERSID = factor(ids),
    ind_post, ind_tx, ind_female, HISPANX, PCS42, INSCOV,
    ind_gt0  = ind_gt0,
    TOTEXPYY = TOTEXPYY,
    extreme_flag = extreme_flag,
    magnitude_level = magnitude_level,
    prop_extreme = prop_extreme
  )
}

# ============================
# 27-scenario grid (n × magnitude × prop_extreme)
# ============================
sim_conditions <- expand.grid(
  n = c(1000, 2000, 10000),
  magnitude_level = c(1, 2, 3),
  prop_extreme = c(0.01, 0.05, 0.10)
)

# ============================
# Run all scenarios
# ============================
set.seed(20250811)
all_sim_results <- vector("list", nrow(sim_conditions))

for (i in seq_len(nrow(sim_conditions))) {
  cond <- sim_conditions[i, ]
  cat(sprintf("Sim %02d | n=%d, mag=%d, p_ext=%.02f\n",
              i, cond$n, cond$magnitude_level, cond$prop_extreme))
  sim_df <- simulate_panel_data(
    n               = cond$n,
    magnitude_level = cond$magnitude_level,
    prop_extreme    = cond$prop_extreme,
    p_treated       = 0.5,
    target_prob     = 0.70,
    extreme_alloc   = "proportional",  # or "equal"
    fill_zero_for_negative = TRUE,
    exact_positives = TRUE
  )
  sim_df$sim_id <- i
  sim_df$sample_size <- cond$n
  all_sim_results[[i]] <- sim_df
}

final_sim_data <- bind_rows(all_sim_results)

# ============================
# Quick checks
# ============================

# 1) Did each scenario hit ~30% positives and the correct extreme share?
summary_rates <- final_sim_data %>%
  group_by(sim_id, sample_size, magnitude_level, prop_extreme) %>%
  summarise(
    rows        = n(),
    pos_rate    = mean(ind_gt0),
    extreme_all = mean(extreme_flag == 1),
    .groups = "drop"
  )
print(summary_rates, n = Inf)

# 2) Are extremes spread across DiD cells?
ext_by_cell <- final_sim_data %>%
  group_by(sim_id, ind_post, ind_tx) %>%
  summarise(
    n_rows = n(),
    ext_ct = sum(extreme_flag == 1),
    .groups = "drop"
  ) %>%
  arrange(sim_id, ind_post, ind_tx)
print(ext_by_cell, n = 32)

# 3) Value-range checks for extremes
ext_range <- final_sim_data %>%
  filter(extreme_flag == 1) %>%
  group_by(sim_id, magnitude_level) %>%
  summarise(
    min_ext = suppressWarnings(min(TOTEXPYY, na.rm = TRUE)),
    max_ext = suppressWarnings(max(TOTEXPYY, na.rm = TRUE)),
    .groups = "drop"
  )
print(ext_range, n = Inf)

# ============================
# Example: Scenario 1 export
# ============================
# scenario 1 is the first row of the grid (n=1000, mag=1, prop_extreme=0.01)
sim1 <- subset(final_sim_data, sim_id == 1)
# write.csv(sim1, "scenario_01_n1000_mag1_ext01.csv", row.names = FALSE)

View(sim1)

# Example sanity:
with(sim1, table(ind_post, ind_tx, extreme_flag))
c(
  rows          = nrow(sim1),
  pos_rate      = mean(sim1$ind_gt0),
  extreme_share = mean(sim1$extreme_flag == 1)
)
range(sim1$TOTEXPYY[sim1$extreme_flag==1], na.rm = TRUE)
summary(sim1$TOTEXPYY[sim1$extreme_flag==0], na.rm = TRUE)  # typical values not huge

```



```{r}
set.seed(787614)
sim1 <- simulate_panel_data(
  n               = 1000,
  magnitude_level = 1,
  prop_extreme    = 0.01,
  p_treated       = 0.5,
  target_prob     = 0.70,
  extreme_alloc   = "proportional",  # or "equal"
  exact_positives = TRUE            # << ensures ~70% overall
)
```  



```{r}
# inputs for scenario 1
Nexp  <- 1000 * 2                   # rows
p_ext <- 0.01
lower <- 5e4; upper <- 1e6          # mag 1 range

N <- nrow(sim1)
K <- sum(sim1$ind_gt0)
E <- sum(sim1$extreme_flag == 1)

cat("Rows:", N, "\n")
cat("Positives overall:", sprintf("%d (%.4f)", K, K/N), "\n")
cat("Extreme share (all rows):", sprintf("%d (%.4f)", E, E/N), "\n\n")

print(table(sim1$extreme_flag, sim1$ind_gt0))
cat("\nExtreme TOTEXPYY range: ",
    paste(range(sim1$TOTEXPYY[sim1$extreme_flag==1], na.rm=TRUE), collapse="  to  "),
    "\n", sep="")

# basic PASS/FAIL with tiny tolerances
pass_pos  <- (abs(K/N - 0.30) <= 0.001)              # ~30% exactly
pass_ext  <- (abs(E/N - p_ext) <= 1/Nexp)            # exact count 1% (20/2000)
in_range  <- with(sim1, all(TOTEXPYY[extreme_flag==1] >= lower &
                             TOTEXPYY[extreme_flag==1] <= upper, na.rm=TRUE))

cat("\nEXPECTED: positives ≈", 0.30*Nexp, "and extremes =", p_ext*Nexp, "\n")
cat("PASS positives:", pass_pos, "\n")
cat("PASS extremes :", pass_ext, "\n")
cat("PASS extreme range:", in_range, "\n")
```  

```{r check_bias}
# check for bias in untreated simulated data: 

# Reference: dgf models: 
#lp_cov <- 0.5*ind_post + 0.7*ind_tx + 0.2*ind_female - 0.2*HISPANX + 0.1*zPCS 
#lp_cont <- 7 + 0.4*ind_post + 0.6*ind_tx + 0.15*zPCS + 0.2*ind_female - 0.1*HISPANX

 model_part1 <- glm(
    formula = ind_gt0 ~ ind_tx*ind_post + ind_tx + ind_post + ind_female + HISPANX + zPCS42 + INSCOV,
    data = fyc,
    family = binomial(link = "logit")
  )
  
  # Part 2: Fit the Gamma model for the positive outcomes only
  sim_positive <- fyc %>% filter(ind_gt0 == 1)
  
  model_part2 <- glm(
    formula = TOTEXPYY ~ ind_tx*ind_post + ind_tx + ind_post+ ind_female + HISPANX + zPCS42 + INSCOV,
    data = sim_positive,
    family = Gamma(link = "log")
  )

```






