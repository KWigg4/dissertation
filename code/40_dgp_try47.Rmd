---
title: "Untitled"
author: "Felix"
date: "2/2/2026"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r pkgs}
pacman::p_load(
  broom,
  dplyr,
  effectsize,
  forcats,
  furrr,
  ggforce,
  ggplot2,
  ggrepel,
  glue,
  gt,
  here,
  lubridate,
  MASS,
  purrr,
  readr,
  scales,
  tibble,
  tidyr)

dt <- lubridate::today()
dir.create("results", showWarnings = FALSE)
dir.create("figures", showWarnings = FALSE)

```


#0) ONE SOURCE OF TRUTH: DGP COEFFICIENTS

```{r helpers}
COEF <- list(
  p1 = list(b0 = 0.0, post = 0.2, tx = -0.2, int = 0.0,
            female = 1.2, hisp = -0.8, zpcs = -0.2),
  p2 = list(b0 = 7.0, post = 0.2, tx =  0.2, int = 0.0,
            female = 0.4, hisp = -0.2, zpcs = -0.4)
)

# --- helper: log-uniform draw for extremes ---
rlogunif <- function(n, min_val, max_val) {
  if (n <= 0) return(numeric(0))
  exp(runif(n, log(min_val), log(max_val)))
}

# --- helper: extreme value ranges ---
extreme_range <- function(mag_level) {
  switch(as.character(mag_level),
         "1" = c(5e4, 1e6),
         "2" = c(5e4, 2e6),
         "3" = c(5e4, 3e6),
         stop("Invalid magnitude_level"))
}

```

#1) DGP: two-part Gamma with extremes

```{r sim}
simulate_panel_data <- function(
  n, magnitude_level, prop_extreme = 0.01,
  p_treated = 0.5, sigma_u = 0.5, rho = 0.5,
  gamma_shape = 3,
  COEF
) {
  T <- 2; N <- n * T
  ids <- rep(1:n, each = T)
  ind_post <- rep(0:1, times = n)

  # covariates
  ind_tx_i     <- rbinom(n, 1, p_treated)
  ind_female_i <- rbinom(n, 1, 0.5)
  HISPANX_i    <- rbinom(n, 1, 0.2)
  #INSCOV_i     <- sample(1:3, n, replace = TRUE)

  ind_tx     <- rep(ind_tx_i, each = T)
  ind_female <- rep(ind_female_i, each = T)
  HISPANX    <- rep(HISPANX_i, each = T)
  #INSCOV     <- factor(rep(INSCOV_i, each = T))

  # PCS42 with correlation (keep your approach)
  Sigma <- matrix(c(1, rho, rho, 1), 2, 2)
  pcs   <- MASS::mvrnorm(n, mu = c(50, 50), Sigma = Sigma)
  PCS42 <- as.vector(t(pcs))
  zPCS  <- (PCS42 - 50) / 10  # standardized PCS42

  # random intercept (kept for fidelity; not used in lp by design)
  u_i <- rnorm(n, 0, sigma_u)
  u   <- u_i[ids]

  # Part 1: logistic >0 (use COEF)
  lp_cov <- COEF$p1$b0 +
    COEF$p1$post   * ind_post +
    COEF$p1$tx     * ind_tx +
    COEF$p1$int    * (ind_post * ind_tx) +
    COEF$p1$female * ind_female +
    COEF$p1$hisp   * HISPANX +
    COEF$p1$zpcs   * zPCS

  pr_pos  <- plogis(lp_cov)
  ind_gt0 <- rbinom(N, 1, pr_pos)

  # Part 2: Gamma for positives (use COEF)
  lp_cont <- COEF$p2$b0 +
    COEF$p2$post   * ind_post +
    COEF$p2$tx     * ind_tx +
    COEF$p2$int    * (ind_post * ind_tx) +
    COEF$p2$female * ind_female +
    COEF$p2$hisp   * HISPANX +
    COEF$p2$zpcs   * zPCS

  mu <- exp(lp_cont)
  shape <- gamma_shape
  scale <- mu / shape

  TOTEXPYY <- rep(0, N)
  TOTEXPYY[ind_gt0 == 1] <- rgamma(sum(ind_gt0),
                                   shape = shape,
                                   scale = scale[ind_gt0 == 1])

  # inject extremes
  K_ext <- rbinom(1, N, prop_extreme)
  if (K_ext > 0) {
    rng <- extreme_range(magnitude_level)
    idx_ext <- sample.int(N, size = K_ext, replace = FALSE)
    TOTEXPYY[idx_ext] <- rlogunif(K_ext, rng[1], rng[2])
  } else idx_ext <- integer(0)

  tibble(
    DUPERSID = factor(ids),
    ind_post, ind_tx, ind_female, HISPANX, PCS42, zPCS, #INSCOV,
    ind_gt0 = ind_gt0,
    TOTEXPYY = TOTEXPYY,
    extreme_flag = as.integer(seq_len(N) %in% idx_ext),
    magnitude_level, prop_extreme
  )
}

```


#2) Treatments for extreme values (UPDATED)
# - mean/median preserved uses values > q95 only
# - truncation removes rows (not NA)

```{r treatments}
treat_extremes_df <- function(dat, method = "raw") {
  if (method == "raw") return(dat)

  q95 <- quantile(dat$TOTEXPYY, 0.95, na.rm = TRUE)

  if (method == "topcode") {
    dat$TOTEXPYY <- pmin(dat$TOTEXPYY, q95)
    return(dat)
  }

  if (method == "mean_adj") {
    m <- mean(dat$TOTEXPYY[dat$TOTEXPYY > q95], na.rm = TRUE)
    dat$TOTEXPYY[dat$TOTEXPYY > q95] <- m
    return(dat)
  }

  if (method == "median_adj") {
    m <- median(dat$TOTEXPYY[dat$TOTEXPYY > q95], na.rm = TRUE)
    dat$TOTEXPYY[dat$TOTEXPYY > q95] <- m
    return(dat)
  }

  if (method == "truncate") {
    dat <- dat %>% filter(TOTEXPYY <= q95)
    return(dat)
  }

  stop("Unknown treatment method")
}

```

#3) Safe Gamma fit wrapper

```{r safe_gamma}
safe_gamma_fit <- function(dat) {
  dat2 <- dat %>% filter(ind_gt0 == 1, is.finite(TOTEXPYY), TOTEXPYY > 0)
  if (nrow(dat2) < 10) return(NULL)

  out <- tryCatch({
    glm(
      TOTEXPYY ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
      data = dat2,
      family = Gamma(link = "log"),
      control = glm.control(maxit = 100, epsilon = 1e-8)
    )
  }, error = function(e) NULL)

  out
}

```

#3b) Effect size helper:
```{r es_helper}
compute_sd_ref <- function(dat, ref = c("control_pre", "pooled_pre", "control_all")) {

  if (missing(dat) || is.null(dat)) {
    stop("compute_sd_ref(): you must pass a data.frame/tibble as 'dat' (e.g., compute_sd_ref(dat, ref='control_pre')).")
  }

  ref <- match.arg(ref)

  dref <- switch(
    ref,
    control_pre = dat %>% dplyr::filter(ind_tx == 0, ind_post == 0),
    pooled_pre  = dat %>% dplyr::filter(ind_post == 0),
    control_all = dat %>% dplyr::filter(ind_tx == 0)
  )

  sd_ref <- sd(dref$TOTEXPYY, na.rm = TRUE)

  # guard against degenerate / invalid SD
  if (!is.finite(sd_ref) || sd_ref <= 0) return(NA_real_)
  sd_ref
}

```

#4) ATT computation (RQ4): Estimated + TRUE using same COEF
```{r att}
compute_ATT_hat <- function(dat, fit_logit, fit_gamma) {

  treated_post <- dat %>% filter(ind_tx == 1, ind_post == 1)
  if (nrow(treated_post) == 0) return(NA_real_)

  treated_cf <- treated_post %>% mutate(ind_tx = 0)

  # Part 1: Pr(Y>0)
  p_obs <- predict(fit_logit, newdata = treated_post, type = "response")
  p_cf  <- predict(fit_logit, newdata = treated_cf,   type = "response")

  # Part 2: E[Y|Y>0] (Gamma log link; response is on original scale)
  mu_obs <- predict(fit_gamma, newdata = treated_post, type = "response")
  mu_cf  <- predict(fit_gamma, newdata = treated_cf,   type = "response")

  mean(p_obs * mu_obs - p_cf * mu_cf)
}

compute_true_ATT <- function(dat, COEF) {

  treated_post <- dat %>% filter(ind_tx == 1, ind_post == 1)
  if (nrow(treated_post) == 0) return(NA_real_)

  treated_cf <- treated_post %>% mutate(ind_tx = 0)

  # TRUE Part 1
  lp1_obs <- COEF$p1$b0 +
    COEF$p1$post   * treated_post$ind_post +
    COEF$p1$tx     * treated_post$ind_tx +
    COEF$p1$int    * (treated_post$ind_post * treated_post$ind_tx) +
    COEF$p1$female * treated_post$ind_female +
    COEF$p1$hisp   * treated_post$HISPANX +
    COEF$p1$zpcs   * treated_post$zPCS
  p_obs <- plogis(lp1_obs)

  lp1_cf <- COEF$p1$b0 +
    COEF$p1$post   * treated_cf$ind_post +
    COEF$p1$tx     * treated_cf$ind_tx +
    COEF$p1$int    * (treated_cf$ind_post * treated_cf$ind_tx) +
    COEF$p1$female * treated_cf$ind_female +
    COEF$p1$hisp   * treated_cf$HISPANX +
    COEF$p1$zpcs   * treated_cf$zPCS
  p_cf <- plogis(lp1_cf)

  # TRUE Part 2
  lp2_obs <- COEF$p2$b0 +
    COEF$p2$post   * treated_post$ind_post +
    COEF$p2$tx     * treated_post$ind_tx +
    COEF$p2$int    * (treated_post$ind_post * treated_post$ind_tx) +
    COEF$p2$female * treated_post$ind_female +
    COEF$p2$hisp   * treated_post$HISPANX +
    COEF$p2$zpcs   * treated_post$zPCS
  mu_obs <- exp(lp2_obs)

  lp2_cf <- COEF$p2$b0 +
    COEF$p2$post   * treated_cf$ind_post +
    COEF$p2$tx     * treated_cf$ind_tx +
    COEF$p2$int    * (treated_cf$ind_post * treated_cf$ind_tx) +
    COEF$p2$female * treated_cf$ind_female +
    COEF$p2$hisp   * treated_cf$HISPANX +
    COEF$p2$zpcs   * treated_cf$zPCS
  mu_cf <- exp(lp2_cf)

  mean(p_obs * mu_obs - p_cf * mu_cf)
}

```


#5) One replication under one scenario (UPDATED)
- uses zPCS in models
- returns interaction estimates + ATT outputs
- adds ATT effect size (d_est, d_true, d_bias) using baseline SD

```{r run_one}
run_one <- function(n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF,
                    es_ref = "control_pre") {

  dat <- simulate_panel_data(
    n = n,
    magnitude_level = magnitude_level,
    prop_extreme = prop_extreme,
    gamma_shape = gamma_shape,
    COEF = COEF
  )

  # Apply treatment at the DATAFRAME level
  dat <- treat_extremes_df(dat, treatment)

  # Logistic
  fit1 <- glm(ind_gt0 ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
              data = dat, family = binomial)
  c1 <- coef(summary(fit1))["ind_post:ind_tx", c("Estimate","Std. Error")]

  # Gamma fit object (safe)
  fit2 <- safe_gamma_fit(dat)
  if (is.null(fit2)) {
    c2 <- c(NA_real_, NA_real_)
  } else {
    c2 <- coef(summary(fit2))["ind_post:ind_tx", c("Estimate","Std. Error")]
  }

  # ATT requires gamma object
  ATT_hat  <- if (!is.null(fit2)) compute_ATT_hat(dat, fit1, fit2) else NA_real_
  ATT_true <- compute_true_ATT(dat, COEF)
  ATT_bias <- ATT_hat - ATT_true

  # --- Effect size (Cohen's d style): standardize ATT by baseline SD ---
  # d = ATT / SD_(Y|tx=0 & post=0) (non-treated pre group) Dr Tsai will check
  sd_ref <- compute_sd_ref(dat, ref = es_ref)
  d_hat  <- ifelse(is.na(ATT_hat)  || is.na(sd_ref), NA_real_, ATT_hat  / sd_ref)
  d_true <- ifelse(is.na(ATT_true) || is.na(sd_ref), NA_real_, ATT_true / sd_ref)
  d_bias <- d_hat - d_true

  tibble(
    model = c("logit", "gamma", "ATT"),
    est   = c(unname(c1[1]), unname(c2[1]), ATT_hat),
    se    = c(unname(c1[2]), unname(c2[2]), NA_real_),
    true  = c(COEF$p1$int, COEF$p2$int, ATT_true),
    bias  = c(unname(c1[1]) - COEF$p1$int,
              unname(c2[1]) - COEF$p2$int,
              ATT_bias),

    # effect-size columns (only meaningful for ATT row; NA for others)
    d_est  = c(NA_real_, NA_real_, d_hat),
    d_true = c(NA_real_, NA_real_, d_true),
    d_bias = c(NA_real_, NA_real_, d_bias),

    n = n, prop_extreme, magnitude_level, gamma_shape, treatment
  )
}

run_mc <- function(B, n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF,
                   es_ref = "control_pre") {
  results <- replicate(
    B,
    run_one(n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF, es_ref = es_ref),
    simplify = FALSE
  )
  bind_rows(results)
}

```

#Step 1: Representative dataset (histograms + model fits)
```{r}
set.seed(123)
dat_example <- simulate_panel_data(
  n = 1000,
  magnitude_level = 1,
  prop_extreme = 0.05,
  gamma_shape = 3,
  COEF = COEF
)

p1 <- ggplot(dat_example, aes(x = TOTEXPYY)) +
  geom_histogram(bins = 100, fill = "skyblue", color = "black") +
  scale_x_continuous(labels = scales::comma) +
  labs(title = "Histogram of TOTEXPYY", x = "Spending", y = "Count") +
  theme_minimal()

p2 <- ggplot(dat_example, aes(x = TOTEXPYY)) +
  geom_histogram(bins = 100, fill = "seagreen", color = "black") +
  scale_x_log10(labels = scales::comma) +
  labs(title = "Histogram of TOTEXPYY (log scale)", x = "Spending (log)", y = "Count") +
  theme_minimal()

print(p1); print(p2)

fit_logit <- glm(ind_gt0 ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
                 data = dat_example, family = binomial)

fit_gamma <- glm(TOTEXPYY ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
                 data = dat_example %>% filter(ind_gt0 == 1),
                 family = Gamma(link = "log"))

summary(fit_logit)
summary(fit_gamma)

```

#Step 2: Full Monte Carlo across scenarios
```{r full_mc}
n_vals <- c(5000, 10000, 20000)
prop_extreme_vals <- c(0.01, 0.05, 0.10)
magnitude_vals <- c(1, 2, 3)
treatment_methods <- c("raw", "topcode", "mean_adj", "median_adj", "truncate")

grid <- expand.grid(
  n = n_vals,
  prop_extreme = prop_extreme_vals,
  magnitude_level = magnitude_vals,
  treatment = treatment_methods,
  stringsAsFactors = FALSE
)

set.seed(2025)
B <- 500

# Effect size reference group choice:
# "control_pre" (recommended), "pooled_pre", or "control_all"
ES_REF <- "control_pre"

all_df <- furrr::future_pmap_dfr(
  grid,
  ~ run_mc(B, ..1, ..3, ..2, gamma_shape = 3, ..4, COEF = COEF, es_ref = ES_REF),
  .options=furrr::furrr_options(seed=TRUE)
)

# Save raw simulation output
saveRDS(all_df, file = here::here(paste0("results/all_df_", dt, ".RDS")))
write.csv(all_df, file = here::here(paste0("results/all_df_", dt, ".csv")))

```


#Summarise results (includes ATT effect size columns)
```{r}
summ_grid <- all_df %>%
  group_by(model, n, prop_extreme, magnitude_level, treatment) %>%
  summarise(
    mean_est  = round(mean(est, na.rm = TRUE), 6),
    mean_true = round(mean(true, na.rm = TRUE), 6),
    bias      = round(mean(bias, na.rm = TRUE), 6),

    emp_se = round(sd(est, na.rm = TRUE), 6),
    rmse   = round(sqrt(mean((est - true)^2, na.rm = TRUE)), 6),

    coverage = round(
      mean((est - 1.96*se <= true) & (true <= est + 1.96*se), na.rm = TRUE),
      6
    ),

    # Effect size summary (ATT rows only; NA otherwise)
    d_mean   = round(mean(d_est, na.rm = TRUE), 6),
    d_emp_se = round(sd(d_est, na.rm = TRUE), 6),
    d_bias   = round(mean(d_bias, na.rm = TRUE), 6),

    n_fail = sum(is.na(est)),
    .groups = "drop"
  )

print(summ_grid)

saveRDS(summ_grid, file = here::here(paste0("results/summ_grid_", dt, ".RDS")))
write.csv(summ_grid, file = here::here(paste0("results/summ_grid_", dt, ".csv")), row.names = FALSE)

```  




##4 FULL-FACTORIAL ANOVA (RQ answers)
```{r}
# ---- Gamma (Part 2 interaction): bias, SE, coverage ----
# all_df_gamma <- all_df %>%
#   dplyr::filter(model == "gamma") %>%
#   dplyr::mutate(
#     n = factor(n),
#     prop_extreme = factor(prop_extreme),
#     magnitude_level = factor(magnitude_level),
#     treatment = factor(treatment),
#     cover_ind = ifelse(is.na(est) | is.na(se), NA_real_,
#                        as.numeric((est - 1.96*se <= true) & (true <= est + 1.96*se)))
#   )

# --- Build replicate-level coverage indicator for the Gamma model ---
all_df_gamma <- all_df %>%
  dplyr::filter(model == "gamma") %>%
  dplyr::mutate(
    cover_ind = dplyr::if_else(
      is.na(est) | is.na(se) | is.na(true),
      NA_real_,
      as.numeric((est - 1.96*se <= true) & (true <= est + 1.96*se))
    ),
    # ensure factors for ANOVA
    n = as.factor(n),
    prop_extreme = as.factor(prop_extreme),
    magnitude_level = as.factor(magnitude_level),
    treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate")
  ) %>%
  dplyr::filter(!is.na(cover_ind))    # drop reps where fits failed

saveRDS(all_df_gamma, file = here::here(paste0("results/all_df_gamma_", dt, ".RDS")))
write.csv(all_df_gamma, file = here::here(paste0("results/all_df_gamma_", dt, ".csv")), row.names = FALSE)

# A) factorial ANOVA on gamma bias (rep-level)
aov_gamma_bias <- aov(bias ~ treatment * n * prop_extreme * magnitude_level, data = all_df_gamma)
summary(aov_gamma_bias)
aov_gamma_bias_df <- as.data.frame(summary(aov_gamma_bias)[[1]])
tidy_aov <- tidy(aov_gamma_bias)
write.csv(
  tidy_aov,
  here::here(paste0("results/aov_gamma_bias_", dt, ".csv")))

eta_squared(aov_gamma_bias, partial=TRUE) # for partial eta squared (or general?)

# B) factorial ANOVA on gamma emp SE  (vs model SE, bc emp SE is the SD of the 500 est's of the coefficient, not the average of the model SE's, right?)
summ_grid_gamma <- summ_grid |> filter(model=="gamma")
aov_gamma_emp_se <- aov(
	emp_se ~ treatment * n * prop_extreme * magnitude_level, data = summ_grid_gamma )
summary(aov_gamma_emp_se) 
eta_squared(aov_gamma_emp_se, partial=TRUE) # for partial eta squared (or general?)

# C) coverage: scenario-level proportion (recommended)
# cov_grid <- all_df_gamma %>%
#   group_by(treatment, n, prop_extreme, magnitude_level) %>%
#   summarise(coverage = mean(cover_ind, na.rm = TRUE), .groups = "drop")
# 
# aov_gamma_cov <- aov(coverage ~ treatment * n * prop_extreme * magnitude_level, data = cov_grid)
# summary(aov_gamma_cov)
# eta_squared(aov_gamma_cov, partial=TRUE) 

## ^^ effect size won't run because only one row per. Need to re-do: 


# --- Full factorial at replicate level now has residual df (many reps per cell) ---
aov_gamma_cov_rep <- aov(
  cover_ind ~ treatment * n * prop_extreme * magnitude_level,
  data = all_df_gamma
)

# Sanity check: residual df should be > 0
summary(aov_gamma_cov_rep)[[1]]["Residuals","Df"]

eta_squared(aov_gamma_cov_rep, partial=TRUE) 

# ---- ATT (RQ4): ATT_hat, ATT_bias, and effect size across treatments ----
all_df_att <- all_df %>%
  dplyr::filter(model == "ATT") %>%
  dplyr::mutate(
    n = factor(n),
    prop_extreme = factor(prop_extreme),
    magnitude_level = factor(magnitude_level),
    treatment = factor(treatment)
  )

# ATT_hat across conditions
aov_att_hat <- aov(est ~ treatment * n * prop_extreme * magnitude_level, data = all_df_att)
summary(aov_att_hat)

# ATT_bias across conditions (recommended DV)
aov_att_bias <- aov(bias ~ treatment * n * prop_extreme * magnitude_level, data = all_df_att)
summary(aov_att_bias)

# Effect size (d_est) across conditions (optional but usually helpful)
aov_att_d <- aov(d_est ~ treatment * n * prop_extreme * magnitude_level, data = all_df_att)
summary(aov_att_d)

# Save ANOVA-ready datasets
write.csv(all_df_att, file = here::here(paste0("results/all_df_att_", dt, ".csv")), row.names = FALSE)
write.csv(cov_grid,   file = here::here(paste0("results/cov_grid_", dt, ".csv")), row.names = FALSE)

```  


```{r descr}
# Focus on the Gamma Part-2 interaction (can switch to "ATT" later)
summ_gamma <- summ_grid %>%
  dplyr::filter(model == "gamma") %>%
  dplyr::mutate(
    treatment = forcats::fct_relevel(
      treatment, "raw", "topcode", "mean_adj", "median_adj", "truncate"
    )
  )  

# ---- Bias (overall) ----
# mean_bias is average SIGNED bias; preserves direction of estimator's errors, where neg is systematic underestimation and positive is systematic overestimation and opposing signs are going to cancel each other out. 
# The mean_abs_bias is the average absolute magnitude of the bias, which measures how far the estimator is from the truth on average. Does not allow pos/neg to cancel each other out. Always >=0. Larger values indicate more inconsistent or unstable estimation. 
# Mean_abs_bias captures estimator error magnitude, while mean_bias captures estimator direction. mean_bias answers if treatment method systematically over or under estimates the effect, while mean_abs_bias answers how large are the estimation errors, regardless of direction. A method an have a mean bias of 0 and look good but actually perform poorly when you see a large mean_abs_bias because that means it swings pos in some directions, negative in others. 
tab_gamma_bias_overall <- summ_gamma %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(
    scenarios      = dplyr::n(),
    mean_bias      = mean(bias, na.rm = TRUE),
    median_bias    = median(bias, na.rm = TRUE),
    mad_bias       = mad(bias, na.rm = TRUE),
    mean_abs_bias  = mean(abs(bias), na.rm = TRUE),
    .groups = "drop"
  )

gt_gamma_bias_overall <- tab_gamma_bias_overall %>%
  dplyr::mutate(
    mean_bias     = scales::number(mean_bias, accuracy = 0.0001),
    median_bias   = scales::number(median_bias, accuracy = 0.0001),
    mad_bias      = scales::number(mad_bias, accuracy = 0.0001),
    mean_abs_bias = scales::number(mean_abs_bias, accuracy = 0.0001)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Descriptive Statistics: Bias (All Scenarios)",
    subtitle = "Negative = underestimation; Positive = overestimation"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

# Helper for quantiles (same as before)
q_fun <- function(x, p) stats::quantile(x, probs = p, na.rm = TRUE, type = 7)

tab_bias_full_overall <- summ_gamma %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(
    scenarios        = dplyr::n(),
    mean_bias        = mean(bias, na.rm = TRUE),
    sd_bias          = sd(bias, na.rm = TRUE),
    median_bias      = median(bias, na.rm = TRUE),
    mad_bias         = mad(bias, na.rm = TRUE),
    min_bias         = min(bias, na.rm = TRUE),
    q1_bias          = q_fun(bias, 0.25),
    q3_bias          = q_fun(bias, 0.75),
    iqr_bias         = q3_bias - q1_bias,
    max_bias         = max(bias, na.rm = TRUE),
    mean_abs_bias    = mean(abs(bias), na.rm = TRUE),
    share_bias_neg   = mean(bias < 0, na.rm = TRUE),
    share_bias_pos   = mean(bias > 0, na.rm = TRUE),
    .groups = "drop"
  )

gt_bias_full_overall <- tab_bias_full_overall %>%
  dplyr::mutate(
    dplyr::across(
      c(mean_bias, sd_bias, median_bias, mad_bias, min_bias, q1_bias, q3_bias, iqr_bias, max_bias, mean_abs_bias),
      ~ scales::number(.x, accuracy = 0.0001)
    ),
    share_bias_neg = scales::percent(share_bias_neg, accuracy = 0.1),
    share_bias_pos = scales::percent(share_bias_pos, accuracy = 0.1)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Full Descriptive Statistics: Bias",
    subtitle = "Scenario-level bias (mean signed bias per scenario) summarized across scenarios by treatment"
  ) %>%
  gt::cols_label(
    scenarios      = "N scenarios",
    mean_bias      = "Mean",
    sd_bias        = "SD",
    median_bias    = "Median",
    mad_bias       = "MAD",
    min_bias       = "Min",
    q1_bias        = "Q1",
    q3_bias        = "Q3",
    iqr_bias       = "IQR",
    max_bias       = "Max",
    mean_abs_bias  = "Mean |bias|",
    share_bias_neg = "Share bias < 0",
    share_bias_pos = "Share bias > 0"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

gt_bias_full_overall

# ---- Empirical SE (overall) ----
tab_gamma_empse_overall <- summ_gamma %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(
    scenarios   = dplyr::n(),
    mean_emp_se = mean(emp_se, na.rm = TRUE),
    sd_emp_se   = sd(emp_se, na.rm = TRUE),
    .groups = "drop"
  )

gt_gamma_empse_overall <- tab_gamma_empse_overall %>%
  dplyr::mutate(
    mean_emp_se = scales::number(mean_emp_se, accuracy = 0.0001),
    sd_emp_se   = scales::number(sd_emp_se, accuracy = 0.0001)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Descriptive Statistics: Empirical SE (All Scenarios)",
    subtitle = "Empirical SE = Monte Carlo SD of the estimator across replications"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

# Helper to get quantiles safely
q_fun <- function(x, p) stats::quantile(x, probs = p, na.rm = TRUE, type = 7)

tab_empse_full_overall <- summ_gamma %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(
    scenarios       = dplyr::n(),
    mean_emp_se     = mean(emp_se, na.rm = TRUE),
    sd_emp_se       = sd(emp_se, na.rm = TRUE),
    median_emp_se   = median(emp_se, na.rm = TRUE),
    mad_emp_se      = mad(emp_se, na.rm = TRUE),
    min_emp_se      = min(emp_se, na.rm = TRUE),
    q1_emp_se       = q_fun(emp_se, 0.25),
    q3_emp_se       = q_fun(emp_se, 0.75),
    iqr_emp_se      = q3_emp_se - q1_emp_se,
    max_emp_se      = max(emp_se, na.rm = TRUE),
    .groups = "drop"
  )

gt_empse_full_overall <- tab_empse_full_overall %>%
  dplyr::mutate(
    dplyr::across(
      c(mean_emp_se, sd_emp_se, median_emp_se, mad_emp_se,
        min_emp_se, q1_emp_se, q3_emp_se, iqr_emp_se, max_emp_se),
      ~ scales::number(.x, accuracy = 0.0001)
    )
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Full Descriptive Statistics: Empirical SE",
    subtitle = "Scenario-level empirical SE (Monte Carlo SD of the estimator) summarised across scenarios by treatment"
  ) %>%
  gt::cols_label(
    scenarios = "N scenarios",
    mean_emp_se = "Mean",
    sd_emp_se = "SD",
    median_emp_se = "Median",
    mad_emp_se = "MAD",
    min_emp_se = "Min",
    q1_emp_se = "Q1",
    q3_emp_se = "Q3",
    iqr_emp_se = "IQR",
    max_emp_se = "Max"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

gt_empse_full_overall

# ---- Coverage (overall) ----
tab_gamma_cov_overall <- summ_gamma %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(
    scenarios       = dplyr::n(),
    mean_cov        = mean(coverage, na.rm = TRUE),
    p_cov_below_95  = mean(coverage < 0.95, na.rm = TRUE),
    .groups = "drop"
  )

gt_gamma_cov_overall <- tab_gamma_cov_overall %>%
  dplyr::mutate(
    mean_cov       = scales::percent(mean_cov, accuracy = 0.1),
    p_cov_below_95 = scales::percent(p_cov_below_95, accuracy = 0.1)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Descriptive Statistics: Coverage (All Scenarios)",
    subtitle = "Nominal = 95%; table reports mean coverage and share of scenarios < 95%"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

# Stratified tables by prop_extreme * n * magnitude level 
# A tiny formatter for numeric columns
num4 <- function(x) scales::number(x, accuracy = 0.0001)

tab_cov_full_overall <- summ_gamma %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(
    scenarios         = dplyr::n(),
    mean_cov          = mean(coverage, na.rm = TRUE),
    sd_cov            = sd(coverage, na.rm = TRUE),
    median_cov        = median(coverage, na.rm = TRUE),
    mad_cov           = mad(coverage, na.rm = TRUE),
    min_cov           = min(coverage, na.rm = TRUE),
    q1_cov            = q_fun(coverage, 0.25),
    q3_cov            = q_fun(coverage, 0.75),
    iqr_cov           = q3_cov - q1_cov,
    max_cov           = max(coverage, na.rm = TRUE),
    # policy-relevant shares around nominal 0.95
    p_cov_below_95    = mean(coverage < 0.95, na.rm = TRUE),
    p_cov_ge_95       = mean(coverage >= 0.95, na.rm = TRUE),
    .groups = "drop"
  )

gt_cov_full_overall <- tab_cov_full_overall %>%
  dplyr::mutate(
    # format coverage fields as percents where appropriate
    dplyr::across(
      c(mean_cov, sd_cov, median_cov, mad_cov, min_cov, q1_cov, q3_cov, iqr_cov, max_cov),
      ~ scales::percent(.x, accuracy = 0.1)
    ),
    p_cov_below_95 = scales::percent(p_cov_below_95, accuracy = 0.1),
    p_cov_ge_95    = scales::percent(p_cov_ge_95, accuracy = 0.1)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Full Descriptive Statistics: Coverage",
    subtitle = "Scenario-level coverage summarised across scenarios by treatment (nominal: 95%)"
  ) %>%
  gt::cols_label(
    scenarios = "N scenarios",
    mean_cov = "Mean",
    sd_cov = "SD",
    median_cov = "Median",
    mad_cov = "MAD",
    min_cov = "Min",
    q1_cov = "Q1",
    q3_cov = "Q3",
    iqr_cov = "IQR",
    max_cov = "Max",
    p_cov_below_95 = "Share < 95%",
    p_cov_ge_95    = "Share ≥ 95%"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

gt_cov_full_overall

# Factory that returns a gt table for a given data frame + header labels
make_gt_table <- function(df, title, subtitle) {
  gt::gt(df) |>
    gt::tab_header(title = title, subtitle = subtitle) |>
    gt::tab_options(data_row.padding = gt::px(1))
}

# Split by scenario factors
split_keys <- c("prop_extreme", "n", "magnitude_level")
gamma_groups <- summ_gamma %>% dplyr::group_by(across(all_of(split_keys))) %>% dplyr::group_split()

gt_bias_list <- lapply(gamma_groups, function(g) {
  hdr <- g %>% dplyr::slice(1) %>% dplyr::select(all_of(split_keys))
  sub_lab <- glue::glue("prop_extreme = {hdr$prop_extreme}, n = {hdr$n}, magnitude_level = {hdr$magnitude_level}")

  tab <- g %>%
    dplyr::group_by(treatment) %>%
    dplyr::summarise(
      scenarios      = dplyr::n(),
      mean_bias      = mean(bias, na.rm = TRUE),
      median_bias    = median(bias, na.rm = TRUE),
      mad_bias       = mad(bias, na.rm = TRUE),
      mean_abs_bias  = mean(abs(bias), na.rm = TRUE),
      .groups = "drop"
    ) %>%
    dplyr::mutate(
      mean_bias     = num4(mean_bias),
      median_bias   = num4(median_bias),
      mad_bias      = num4(mad_bias),
      mean_abs_bias = num4(mean_abs_bias)
    )

  make_gt_table(
    tab,
    title = glue::glue("Gamma Interaction — Bias (Stratified)"),
    subtitle = sub_lab
  )
})

gt_empse_list <- lapply(gamma_groups, function(g) {
  hdr <- g %>% dplyr::slice(1) %>% dplyr::select(all_of(split_keys))
  sub_lab <- glue::glue("prop_extreme = {hdr$prop_extreme}, n = {hdr$n}, magnitude_level = {hdr$magnitude_level}")

  tab <- g %>%
    dplyr::group_by(treatment) %>%
    dplyr::summarise(
      scenarios   = dplyr::n(),
      mean_emp_se = mean(emp_se, na.rm = TRUE),
      sd_emp_se   = sd(emp_se, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    dplyr::mutate(
      mean_emp_se = num4(mean_emp_se),
      sd_emp_se   = num4(sd_emp_se)
    )

  make_gt_table(
    tab,
    title = glue::glue("Gamma Interaction — Empirical SE (Stratified)"),
    subtitle = sub_lab
  )
})

gt_cov_list <- lapply(gamma_groups, function(g) {
  hdr <- g %>% dplyr::slice(1) %>% dplyr::select(all_of(split_keys))
  sub_lab <- glue::glue("prop_extreme = {hdr$prop_extreme}, n = {hdr$n}, magnitude_level = {hdr$magnitude_level}")

  tab <- g %>%
    dplyr::group_by(treatment) %>%
    dplyr::summarise(
      scenarios       = dplyr::n(),
      mean_cov        = mean(coverage, na.rm = TRUE),
      p_cov_below_95  = mean(coverage < 0.95, na.rm = TRUE),
      .groups = "drop"
    ) %>%
    dplyr::mutate(
      mean_cov       = scales::percent(mean_cov, accuracy = 0.1),
      p_cov_below_95 = scales::percent(p_cov_below_95, accuracy = 0.1)
    )

  make_gt_table(
    tab,
    title = glue::glue("Gamma Interaction — Coverage (Stratified)"),
    subtitle = sub_lab
  )
})

# Save all stratified tables for appendix
# Ensure output directory exists (you already create "figures" earlier)
if (!dir.exists("figures")) dir.create("figures", showWarnings = FALSE)

# Helper to extract key labels for filenames
label_from_group <- function(g) {
  hdr <- g %>% dplyr::slice(1) %>% dplyr::select(all_of(split_keys))
  paste0("prop", hdr$prop_extreme, "_n", hdr$n, "_mag", hdr$magnitude_level)
}

# Save Bias tables
for (i in seq_along(gt_bias_list)) {
  lab <- label_from_group(gamma_groups[[i]])
  gt::gtsave(gt_bias_list[[i]],
             filename = here::here(paste0("figures/table_bias_", lab, "_", dt, ".png")),
             expand = 0)
}

# Save Empirical SE tables
for (i in seq_along(gt_empse_list)) {
  lab <- label_from_group(gamma_groups[[i]])
  gt::gtsave(gt_empse_list[[i]],
             filename = here::here(paste0("figures/table_empse_", lab, "_", dt, ".png")),
             expand = 0)
}

# Save Coverage tables
for (i in seq_along(gt_cov_list)) {
  lab <- label_from_group(gamma_groups[[i]])
  gt::gtsave(gt_cov_list[[i]],
             filename = here::here(paste0("figures/table_cov_", lab, "_", dt, ".png")),
             expand = 0)
}

## ATT version: For the same stratified tables for ATT (and/or d_est),  replace summ_gamma with summ_att <- summ_grid |> dplyr::filter(model == "ATT") and reuse the same blocks. All required fields were computed earlier in pipeline.

```  

## Over/under estimation  

```{r over_underests}
# Replicate-level indicator of underestimation for gamma model
under_over_scen <- all_df %>%
  dplyr::filter(model == "gamma") %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(
    under_rate = mean(est < true, na.rm = TRUE),
    over_rate  = mean(est > true, na.rm = TRUE),
    .groups = "drop"
  )

# Scenario-level merge with your empirical SE and coverage
scenario_stats <- summ_gamma %>%
  left_join(under_over_scen,
            by = c("treatment", "n", "prop_extreme", "magnitude_level")) %>%
  mutate(
    # 'consistently under' if majority of reps are < 0 bias in that scenario
    under_majority = under_rate > 0.5,
    over_majority  = over_rate > 0.5
  )

# Aggregate to treatment-level “consistency” table
tab_consistency <- scenario_stats %>%
  group_by(treatment) %>%
  summarise(
    n_scen = dplyr::n(),
    # scenario-mean bias (your 'bias' already is scenario-level mean bias)
    avg_mean_bias = mean(bias, na.rm = TRUE),
    med_mean_bias = median(bias, na.rm = TRUE),
    share_scen_under = mean(bias < 0, na.rm = TRUE),    # % scenarios with negative mean bias
    share_scen_over  = mean(bias > 0, na.rm = TRUE),
    share_scen_under_majority = mean(under_majority, na.rm = TRUE),
    mean_cov = mean(coverage, na.rm = TRUE),
    mean_emp_se = mean(emp_se, na.rm = TRUE),
    .groups = "drop"
  )

gt_consistency <- tab_consistency %>%
  mutate(
    avg_mean_bias = scales::number(avg_mean_bias, accuracy = 0.0001),
    med_mean_bias = scales::number(med_mean_bias, accuracy = 0.0001),
    share_scen_under = scales::percent(share_scen_under, accuracy = 0.1),
    share_scen_over  = scales::percent(share_scen_over, accuracy = 0.1),
    share_scen_under_majority = scales::percent(share_scen_under_majority, accuracy = 0.1),
    mean_cov = scales::percent(mean_cov, accuracy = 0.1),
    mean_emp_se = scales::number(mean_emp_se, accuracy = 0.0001)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction: Consistency of Under/Over-Estimation by Treatment",
    subtitle = "Share of scenarios with negative mean bias and with majority underestimation"
  )

gt_consistency
```    


## Plots  

### Lollipop  

```{r plots_dir}

plot_bias_lollipop <- scenario_stats %>%
  group_by(treatment) %>%
  summarise(
    mean_of_means = mean(bias, na.rm = TRUE),
    sd_of_means   = sd(bias, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(sign = ifelse(mean_of_means < 0, "Underestimation (−)", "Overestimation (+)"),
         treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate")) %>%
  ggplot(aes(x = treatment, y = mean_of_means, color = sign)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_segment(aes(xend = treatment, y = 0, yend = mean_of_means), linewidth = 1.2) +
  geom_point(size = 3) +
  scale_color_manual(values = c("Underestimation (−)" = "#C7372F", "Overestimation (+)" = "#2B6CB0")) +
  labs(
    title = "Gamma Interaction: Average Scenario-Mean Bias by Treatment",
    subtitle = "Positive = overestimation; Negative = underestimation",
    x = NULL, y = "Average of scenario means (bias)"
  ) +
  theme_minimal() +
  theme(legend.position = "top")

plot_bias_lollipop
ggsave(here::here(paste0("figures/gamma_bias_lollipop_", dt, ".png")),
       plot_bias_lollipop, width = 8, height = 5, dpi = 300)
```  

### lollipop x2  
```{r lolli_v2}
# Reuse your scenario-level summary table for the Gamma interaction
summ_gamma <- summ_grid %>%
  dplyr::filter(model == "gamma") %>%
  dplyr::mutate(
    treatment = forcats::fct_relevel(
      treatment, "raw", "topcode", "mean_adj", "median_adj", "truncate"
    ),
    # scenario id string and absolute bias to plot
    scen_id = paste0("prop=", prop_extreme, " | mag=", magnitude_level, " | n=", n),
    abs_bias = abs(bias)
  )

# Option 1: one lollipop per scenario: 

make_lollipop <- function(df_one_scen) {
  scen_lab <- df_one_scen$scen_id[1]
  ggplot(df_one_scen, aes(x = abs_bias, y = treatment)) +
    geom_segment(aes(x = 0, xend = abs_bias, y = treatment, yend = treatment),
                 linewidth = 1.2, color = "grey55") +
    geom_point(size = 3, color = "#2B6CB0") +
    geom_text(aes(label = scales::number(abs_bias, accuracy = 0.0001)),
              nudge_x = 0.002, size = 3.1, hjust = 0) +
    labs(
      title = "Absolute Bias by Treatment (Scenario Lollipop)",
      subtitle = scen_lab,
      x = "Absolute bias |bias| (scenario mean across reps)",
      y = NULL
    ) +
    scale_x_continuous(expand = expansion(mult = c(0, .10))) +
    theme_minimal() +
    theme(panel.grid.major.y = element_blank())
}

# Split by scenario and save each plot
by_scenario <- split(summ_gamma, summ_gamma$scen_id)

for (nm in names(by_scenario)) {
  p <- make_lollipop(by_scenario[[nm]])
  out_path <- here::here(paste0("figures/lollipop_absbias_", gsub("[^A-Za-z0-9]+", "_", nm), "_", dt, ".png"))
  ggsave(out_path, p, width = 7.5, height = 4.5, dpi = 300)
}

```  

### Trend lines for how bias change with mag of extremes, prop of extremes 
```{r trend_lines}
# --- Trend lines including n as a scenario condition ---
# Treat magnitude level as numeric for trend fitting
scenario_stats_num <- scenario_stats %>%
  dplyr::mutate(
    mag = as.numeric(as.character(magnitude_level)),
    treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate"),
    n = as.factor(n)  # factor for clean facet labels
  )

plot_trends <- ggplot(
  scenario_stats_num,
  aes(x = mag, y = bias, color = treatment, group = treatment)
) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  stat_summary(fun = mean, geom = "line", linewidth = 1.1) +
  stat_summary(fun = mean, geom = "point", size = 2) +
  facet_grid(n ~ prop_extreme, labeller = label_both) +
  scale_x_continuous(breaks = c(1, 2, 3), labels = c("1", "2", "3")) +
  labs(
    title = "Gamma Interaction: Trend in Mean Bias Across Magnitude of Extremes",
    subtitle = "Rows = n; Cols = proportion extreme; lines show scenario-means averaged at each magnitude level",
    x = "Magnitude level", y = "Scenario-mean bias"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

plot_trends
ggsave(here::here(paste0("figures/gamma_bias_trends_", dt, ".png")),
       plot_trends, width = 11, height = 7, dpi = 300)
```

2C. Coverage heatmap vs nominal 0.95  
```{r plot_cov_heat}
plot_cov_heat <- summ_gamma %>%
  dplyr::mutate(
    treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate"),
    cell = paste0("prop=", prop_extreme, ", mag=", magnitude_level, ", n=", n)
  ) %>%
  ggplot(aes(x = treatment, y = cell, fill = coverage)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "#C7372F", mid = "white", high = "#2B6CB0",
    midpoint = 0.95, limits = c(0, 1), labels = scales::percent
  ) +
  labs(
    title = "Gamma Interaction: Coverage by Treatment and Scenario",
    subtitle = "Blue ≥ nominal 95%; red shows undercoverage; y-label encodes prop, mag, and n",
    x = "Treatment", y = "Scenario (prop, mag, n)", fill = "Coverage"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

plot_cov_heat
ggsave(here::here(paste0("figures/gamma_coverage_heat_", dt, ".png")),
       plot_cov_heat, width = 11, height = 8, dpi = 300)
```  
2D. Consistency bars: % of scenarios with majority underestimation  
```{r fig_underest}

plot_under_consistency <- scenario_stats %>%
  group_by(treatment) %>%
  summarise(share_under_majority = mean(under_majority, na.rm = TRUE), .groups = "drop") %>%
  mutate(treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate")) %>%
  ggplot(aes(treatment, share_under_majority)) +
  geom_col(fill = "#C7372F") +
  geom_text(aes(label = scales::percent(share_under_majority, accuracy = 0.1)),
            vjust = -0.3) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Gamma Interaction: Consistency of Underestimation by Treatment",
    subtitle = "% of scenarios where >50% of reps underestimated",
    x = NULL, y = "% scenarios"
  ) +
  theme_minimal()

plot_under_consistency
ggsave(here::here(paste0("figures/gamma_under_consistency_", dt, ".png")),
       plot_under_consistency, width = 8, height = 5, dpi = 300)
```  

3. Auto-generate sentences  
Summarize direction, magnitude, reliability per treatment using tables above  
```{r sentences}
sentences <- tab_consistency %>%
  mutate(
    dir = ifelse(as.numeric(avg_mean_bias) < 0, "underestimated", "overestimated"),
    abs_avg = abs(as.numeric(avg_mean_bias)),
    txt = glue::glue(
      "On average across {n_scen} scenarios, the {treatment} method {dir} ",
      "the Gamma interaction by {scales::number(abs_avg, accuracy = 0.0001)}. ",
      "Median scenario-mean bias was {med_mean_bias}. ",
      "{scales::percent(share_scen_under, accuracy = 0.1)} of scenarios had negative mean bias, ",
      "and {scales::percent(share_scen_under_majority, accuracy = 0.1)} showed majority underestimation. ",
      "Mean empirical SE was {mean_emp_se}, and mean coverage was {scales::percent(mean_cov, accuracy = 0.1)}."
    )
  ) %>%
  dplyr::pull(txt)

cat(paste0("- ", sentences, collapse = "\n"))
```  
## ANOVA effect-size reporting for eta-squared with p-values    

Reusable helper to extract eta-squared and p-values from an aov object  
This should pull p-values from `broom::tidy()` and eta-sq from `effectsize::eta_squared()`
which matches with how ANOVAs are already fit. 
```{r aov_eta_helper}
eta_with_p <- function(aov_obj, model_label,
                       type = c("eta2", "partial", "generalized"),
                       include_ci = TRUE, conf_level = 0.90) {
  type <- match.arg(type)

  # ---- 1) Get a tidy ANOVA table and a reliable p-value column ----
  # Try broom::tidy() first
  tab <- tryCatch(broom::tidy(aov_obj), error = function(e) NULL)

  if (is.null(tab)) {
    # Fallback: coerce to data.frame (works for car::Anova and aov objects)
    tab <- as.data.frame(aov_obj)
    # Move term names from rownames into a column
    tab <- tibble::rownames_to_column(tab, var = "term")
  }

  # Normalize the 'term' column name if broom gave a different label
  if (!("term" %in% names(tab))) {
    term_col <- grep("^term$|^Term$|^Effect$|^Parameter$", names(tab), value = TRUE)
    if (length(term_col) == 1L) names(tab)[names(tab) == term_col] <- "term"
  }

  # Identify/construct p-values:
  if (!("p.value" %in% names(tab))) {
    # Look for common alternatives like Pr(>F), Pr..F., etc.
    pv_alt <- grep("^Pr\\(>F\\)$|^Pr[.].*F[.]?$|^pval$|^p_value$", names(tab), value = TRUE)
    if (length(pv_alt) == 1L) {
      names(tab)[names(tab) == pv_alt] <- "p.value"
    } else {
      # As a last resort, try to compute p from F and dfs
      # Find F statistic and dfs
      f_col   <- grep("^F$|^F value$|^statistic$", names(tab), value = TRUE)
      df1_col <- grep("^df$|^Df1$|^num_df$|^num\\.df$", names(tab), value = TRUE)
      df2_col <- grep("^Df2$|^den_df$|^den\\.df$|^Residuals|^residual.df$|^error.df$", names(tab), value = TRUE)

      if (length(f_col) == 1L && length(df1_col) >= 1L && length(df2_col) >= 1L) {
        # Heuristic: If there is a single 'df' column, it might be numerator df; get denominator df from residuals row if present
        if (length(df1_col) == 1L && length(df2_col) == 1L) {
          Fval <- tab[[f_col]]
          df1  <- tab[[df1_col]]
          df2  <- tab[[df2_col]]
          tab$p.value <- stats::pf(Fval, df1, df2, lower.tail = FALSE)
        } else {
          # If structure is ambiguous, set NA and let the rest continue
          tab$p.value <- NA_real_
        }
      } else {
        tab$p.value <- NA_real_
      }
    }
  }

  # Keep only needed columns and drop residuals row if present
  tab_p <- tab %>%
    dplyr::filter(!is.na(term), term != "Residuals") %>%
    dplyr::select(term, p.value)

  # ---- 2) effect sizes from effectsize::eta_squared() ----
  ci_arg <- if (include_ci) conf_level else NULL
  es <- switch(
    type,
    eta2 = effectsize::eta_squared(aov_obj, ci = ci_arg),
    partial = effectsize::eta_squared(aov_obj, partial = TRUE, ci = ci_arg),
    generalized = effectsize::eta_squared(aov_obj, generalized = TRUE, ci = ci_arg)
  ) %>% as.data.frame()

  # Standardize common column names
  nm <- names(es)
  if ("Parameter" %in% nm) names(es)[nm == "Parameter"] <- "term"
  if ("Effect"    %in% nm) names(es)[nm == "Effect"]    <- "term"
  if ("Term"      %in% nm) names(es)[nm == "Term"]      <- "term"

  eta_col <- grep("^Eta2", names(es), value = TRUE)
  if (length(eta_col) == 1L) names(es)[names(es) == eta_col] <- "eta2"
  if ("CI_low"  %in% names(es)) names(es)[names(es) == "CI_low"]  <- "ci_low"
  if ("CI_high" %in% names(es)) names(es)[names(es) == "CI_high"] <- "ci_high"
  if (!("ci_low" %in% names(es))) {
    ci_low_guess <- grep("^CI[_\\.]?low", names(es), value = TRUE)
    if (length(ci_low_guess) == 1L) names(es)[names(es) == ci_low_guess] <- "ci_low"
  }
  if (!("ci_high" %in% names(es))) {
    ci_high_guess <- grep("^CI[_\\.]?high", names(es), value = TRUE)
    if (length(ci_high_guess) == 1L) names(es)[names(es) == ci_high_guess] <- "ci_high"
  }

  # ---- 3) Merge and label ----
  out <- dplyr::left_join(es, tab_p, by = "term") %>%
    dplyr::mutate(
      model  = model_label,
      es_type = switch(type, "eta2" = "eta^2", "partial" = "partial eta^2", "generalized" = "generalized eta^2"),
      stars = dplyr::case_when(
        !is.na(p.value) & p.value < .001 ~ "***",
        !is.na(p.value) & p.value < .01  ~ "**",
        !is.na(p.value) & p.value < .05  ~ "*",
        !is.na(p.value) & p.value < .10  ~ "†",
        TRUE ~ ""
      )
    ) %>%
    dplyr::select(model, es_type, term, eta2,
                  dplyr::any_of(c("ci_low", "ci_high")),
                  p.value, stars)

  out
}
```  

Apply to ANOVAs and build tables 
Groups rows by model (gamma bias, gamma coverage, ATT: bias), reports partial eta-eq, 90% CI, p-value, and sign. marks.

If we want Type II/III SS rather than the Type I default of `aov()`, can refit with `car::Anova()` and pass that object to `effectsize::eta_squared()`. (ASK TSAI)  

```{r}
# ---- Collect effect sizes for all models ----
es_eta2 <- dplyr::bind_rows(
  eta_with_p(aov_gamma_bias,   "Gamma bias",         "eta2"),
  eta_with_p(aov_gamma_emp_se, "Gamma empirical SE", "eta2"),
  eta_with_p(aov_gamma_cov,    "Gamma coverage",     "eta2"),
  eta_with_p(aov_att_hat,      "ATT: est",           "eta2"),
  eta_with_p(aov_att_bias,     "ATT: bias",          "eta2"),
  eta_with_p(aov_att_d,        "ATT: d_est",         "eta2")
)

es_partial <- dplyr::bind_rows(
  eta_with_p(aov_gamma_bias,   "Gamma bias",         "partial"),
  eta_with_p(aov_gamma_emp_se, "Gamma empirical SE", "partial"),
  eta_with_p(aov_gamma_cov,    "Gamma coverage",     "partial"),
  eta_with_p(aov_att_hat,      "ATT: est",           "partial"),
  eta_with_p(aov_att_bias,     "ATT: bias",          "partial"),
  eta_with_p(aov_att_d,        "ATT: d_est",         "partial")
)

es_gen <- dplyr::bind_rows(
  eta_with_p(aov_gamma_bias,   "Gamma bias",         "generalized"),
  eta_with_p(aov_gamma_emp_se, "Gamma empirical SE", "generalized"),
  eta_with_p(aov_gamma_cov,    "Gamma coverage",     "generalized"),
  eta_with_p(aov_att_hat,      "ATT: est",           "generalized"),
  eta_with_p(aov_att_bias,     "ATT: bias",          "generalized"),
  eta_with_p(aov_att_d,        "ATT: d_est",         "generalized")
)

# ---- Main table: partial eta^2 with p-values ----
tbl_partial <- es_partial %>%
  dplyr::mutate(
    eta2_fmt = ifelse(is.na(eta2), NA_character_, scales::number(eta2, accuracy = 0.0001)),
    ci_fmt = dplyr::if_else(
      is.na(ci_low) | is.na(ci_high), "—",
      paste0("[", scales::number(ci_low, accuracy = 0.0001), ", ",
                  scales::number(ci_high, accuracy = 0.0001), "]")
    ),
    p_fmt = ifelse(is.na(p.value), "—", scales::pvalue(p.value, accuracy = 0.001))
  ) %>%
  dplyr::select(model, term, `partial eta^2` = eta2_fmt, CI = ci_fmt, `p-value` = p_fmt, sig = stars)

gt_partial <- tbl_partial %>%
  gt::gt(groupname_col = "model") %>%
  gt::tab_header(
    title = gt::md("**ANOVA Effects: Partial η² with 90% CI and p-values**"),
    subtitle = "Design factors: treatment, n, prop_extreme, magnitude_level"
  ) %>%
  gt::tab_source_note("Signif.: *** < .001, ** < .01, * < .05, † < .10") %>%
  gt::cols_align(align = "center", columns = c(`partial eta^2`, CI, `p-value`, sig))

gt_partial
```  









#Publication-ready plots

```{r eval=FALSE}
# ---- 1) Gamma bias by treatment (scenario-level mean bias) ----
gamma_grid <- all_df_gamma %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(
    mean_bias = mean(bias, na.rm = TRUE),
    mean_se   = mean(se, na.rm = TRUE),
    coverage  = mean(cover_ind, na.rm = TRUE),
    .groups = "drop"
  )

p_gamma_bias <- ggplot(gamma_grid, aes(x = treatment, y = mean_bias)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "Gamma (Part 2) Interaction: Mean Bias by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean bias (est - true)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_gamma_bias)
ggsave(here::here(paste0("figures/gamma_bias_by_treatment_", dt, ".png")),
       p_gamma_bias, width = 10, height = 7, dpi = 300)

# ---- 2) Gamma SE by treatment ----
p_gamma_se <- ggplot(gamma_grid, aes(x = treatment, y = mean_se)) +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "Gamma (Part 2) Interaction: Mean Model SE by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean SE"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_gamma_se)
ggsave(here::here(paste0("figures/gamma_se_by_treatment_", dt, ".png")),
       p_gamma_se, width = 10, height = 7, dpi = 300)

# ---- 3) Gamma coverage by treatment ----
p_gamma_cov <- ggplot(gamma_grid, aes(x = treatment, y = coverage)) +
  geom_hline(yintercept = 0.95, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "Gamma (Part 2) Interaction: Coverage by Treatment",
    subtitle = "Dashed line = nominal 0.95; Rows = prop extreme; Cols = magnitude",
    x = "Treatment method",
    y = "Coverage"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_gamma_cov)
ggsave(here::here(paste0("figures/gamma_coverage_by_treatment_", dt, ".png")),
       p_gamma_cov, width = 10, height = 7, dpi = 300)

# ---- 4) ATT_hat and effect size by treatment ----
att_grid <- all_df_att %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(
    mean_ATT_hat  = mean(est, na.rm = TRUE),
    mean_ATT_bias = mean(bias, na.rm = TRUE),
    mean_d        = mean(d_est, na.rm = TRUE),
    .groups = "drop"
  )

p_att_hat <- ggplot(att_grid, aes(x = treatment, y = mean_ATT_hat)) +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "ATT_hat (RQ4): Mean Estimated ATT by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean ATT_hat"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_att_hat)
ggsave(here::here(paste0("figures/att_hat_by_treatment_", dt, ".png")),
       p_att_hat, width = 10, height = 7, dpi = 300)

p_att_bias <- ggplot(att_grid, aes(x = treatment, y = mean_ATT_bias)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "ATT_bias (RQ4): Mean ATT Bias by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean ATT bias (ATT_hat - ATT_true)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_att_bias)
ggsave(here::here(paste0("figures/att_bias_by_treatment_", dt, ".png")),
       p_att_bias, width = 10, height = 7, dpi = 300)

# ---- 6) Effect size (d) by treatment (optional but recommended) ----
p_att_d <- ggplot(att_grid, aes(x = treatment, y = mean_d)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "ATT Effect Size (d): Mean Standardized ATT by Treatment",
    subtitle = paste0("Standardized by baseline SD (", ES_REF, "); Rows = prop extreme; Cols = magnitude"),
    x = "Treatment method",
    y = "Mean d (ATT / baseline SD)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_att_d)
ggsave(here::here(paste0("figures/att_effect_size_d_by_treatment_", dt, ".png")),
       p_att_d, width = 10, height = 7, dpi = 300)

# Export scenario-level grids for tables
write.csv(gamma_grid, file = here::here(paste0("results/gamma_grid_", dt, ".csv")), row.names = FALSE)
write.csv(att_grid,   file = here::here(paste0("results/att_grid_", dt, ".csv")), row.names = FALSE)

```






