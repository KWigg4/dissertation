---
title: "Results"
author: "KW"
date: "`r Sys.Date()`"
output: html_document
---

PURPOSE: Chapters 4 and 5. After DGP is run and executed, tables are created for results. Import these to make display assets and run ANOVAs.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r pkgs}
pacman::p_load(
  broom,
  dplyr,
  effectsize,
  forcats,
  # furrr,
  ggforce,
  ggplot2,
  ggrepel,
  glue,
  gt,
  here,
  lubridate,
  purrr,
  readr,
  scales,
  # tibble,
  tidyr)

dt <- lubridate::today()
#dir.create("results", showWarnings = FALSE)
#dir.create("figures", showWarnings = FALSE)

conflicted::conflicts_prefer(
  dplyr::select(),
  dplyr::filter()
)

# Save csv and RDS to results directory
fn_save_results <- function(df) {
  name <- deparse(substitute(df))
  saveRDS(df, here::here(paste0("results/",name,"_",dt, ".RDS")))
  write.csv(df,here::here(paste0("results/",name,"_",dt, ".csv")))
}

```  

```{r get_data}
all_df <- readRDS(here::here("results/all_df_2026-02-06.RDS"))

summ_gamma <- readRDS(here::here("results/summ_gamma_2026-02-09.RDS")) %>% 
  mutate(
    nobs_fct = factor(
      nobs,
      levels = c("5000","10000","20000"),
      labels = c("5,000","10,000","20,000")),
    prop_extreme_fct = factor(
      prop_extreme,
      levels = c("0.01","0.05","0.1"),
      labels = c("1%", "5%", "10%")),
    magnitude_fct = factor(
      magnitude_level,
      levels = c(1,2,3),
      labels = c(1, 2, 3)),
    treatment_fct = factor(
      treatment,
      levels = c("raw","topcode", "mean_adj","median_adj","truncate"),
      labels = c("No treatment", "Top-coding","Mean-preserved top-coding",
                 "Median-preserved top-coding", "Truncation"))
    ) %>%
  mutate(
    across(c(mean_est, bias, emp_se, rmse, coverage), ~round(.x, 4))) |> 
  # just reorder and remove n
  select(design_id, n_design, model, 
         nobs, nobs_fct, 
         prop_extreme, prop_extreme_fct,
         magnitude_level, magnitude_fct,
         treatment, treatment_fct,
         everything())

summ_grid  <- readRDS(here::here("results/summ_grid_2026-02-09.RDS"))
all_df_gamma <- readRDS(here::here("results/all_df_gamma_2026-02-09.RDS"))
all_df_att   <- readRDS(here::here("results/all_df_att_2026-02-09.RDS"))

summ_att <- summ_grid |> 
  filter(model=="ATT")
```


## 

```{r descr}
# Focus on the Gamma Part-2 interaction (can switch to "ATT" later)

# ---- Bias (overall) ----
# mean_bias is average SIGNED bias; preserves direction of estimator's errors, where neg is systematic underestimation and positive is systematic overestimation and opposing signs are going to cancel each other out. 
# The mean_abs_bias is the average absolute magnitude of the bias, which measures how far the estimator is from the truth on average. Does not allow pos/neg to cancel each other out. Always >=0. Larger values indicate more inconsistent or unstable estimation. 
# Mean_abs_bias captures estimator error magnitude, while mean_bias captures estimator direction. mean_bias answers if treatment method systematically over or under estimates the effect, while mean_abs_bias answers how large are the estimation errors, regardless of direction. A method an have a mean bias of 0 and look good but actually perform poorly when you see a large mean_abs_bias because that means it swings pos in some directions, negative in others. 

# Helper for quantiles (same as before)
q_fun <- function(x, p) stats::quantile(x, probs = p, na.rm = TRUE, type = 7)

tab_bias_descr <- summ_gamma %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(
    scenarios        = dplyr::n(),
    mean_bias        = mean(bias, na.rm = TRUE),
    sd_bias          = sd(bias, na.rm = TRUE),
    median_bias      = median(bias, na.rm = TRUE),
    mad_bias         = mad(bias, na.rm = TRUE),
    min_bias         = min(bias, na.rm = TRUE),
    q1_bias          = q_fun(bias, 0.25),
    q3_bias          = q_fun(bias, 0.75),
    iqr_bias         = q3_bias - q1_bias,
    max_bias         = max(bias, na.rm = TRUE),
    mean_abs_bias    = mean(abs(bias), na.rm = TRUE),
    share_bias_neg   = mean(bias < 0, na.rm = TRUE),
    share_bias_pos   = mean(bias > 0, na.rm = TRUE),
    .groups = "drop"
  )

gt_bias_descr <- tab_bias_descr %>%
  dplyr::mutate(
    dplyr::across(
      c(mean_bias, sd_bias, median_bias, mad_bias, min_bias, q1_bias, 
        q3_bias, iqr_bias, max_bias, mean_abs_bias),
      ~ scales::number(.x, accuracy = 0.0001)
    ),
    share_bias_neg = scales::percent(share_bias_neg, accuracy = 0.1),
    share_bias_pos = scales::percent(share_bias_pos, accuracy = 0.1)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Full Descriptive Statistics: Bias",
    subtitle = "Scenario-level bias (mean signed bias per scenario) summarized across scenarios by treatment"
  ) %>%
  gt::cols_label(
    scenarios      = "N scenarios",
    mean_bias      = "Mean",
    sd_bias        = "SD",
    median_bias    = "Median",
    mad_bias       = "MAD",
    min_bias       = "Min",
    q1_bias        = "Q1",
    q3_bias        = "Q3",
    iqr_bias       = "IQR",
    max_bias       = "Max",
    mean_abs_bias  = "Mean |bias|",
    share_bias_neg = "Share bias < 0",
    share_bias_pos = "Share bias > 0"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

gtsave(gt_bias_descr, here::here("results/tbl_bias_descr.rtf"))

gt_bias_full_overall

tbl_bias_summ <- summ_gamma |> 
  select(design_id, nobs_fct, prop_extreme_fct, magnitude_fct, 
         treatment_fct, bias) |> 
  mutate(over_under = ifelse(bias>0, "Over","Under"))

fn_save_results(tbl_bias_summ)

# ---- Empirical SE (overall) ----
# tab_gamma_empse_overall <- summ_gamma %>%
#   dplyr::group_by(treatment) %>%
#   dplyr::summarise(
#     scenarios   = dplyr::n(),
#     mean_emp_se = mean(emp_se, na.rm = TRUE),
#     sd_emp_se   = sd(emp_se, na.rm = TRUE),
#     .groups = "drop"
#   )
# 
# gt_gamma_empse_overall <- tab_gamma_empse_overall %>%
#   dplyr::mutate(
#     mean_emp_se = scales::number(mean_emp_se, accuracy = 0.0001),
#     sd_emp_se   = scales::number(sd_emp_se, accuracy = 0.0001)
#   ) %>%
#   gt::gt() %>%
#   gt::tab_header(
#     title = "Gamma Interaction — Descriptive Statistics: Empirical SE (All Scenarios)",
#     subtitle = "Empirical SE = Monte Carlo SD of the estimator across replications"
#   ) %>%
#   gt::tab_options(data_row.padding = gt::px(1))

# Helper to get quantiles safely
# q_fun <- function(x, p) stats::quantile(x, probs = p, na.rm = TRUE, type = 7)
# 
# tab_empse <- summ_gamma %>%
#   dplyr::group_by(treatment) %>%
#   dplyr::summarise(
#     scenarios       = dplyr::n(),
#     mean_emp_se     = mean(emp_se, na.rm = TRUE),
#     sd_emp_se       = sd(emp_se, na.rm = TRUE),
#     median_emp_se   = median(emp_se, na.rm = TRUE),
#     mad_emp_se      = mad(emp_se, na.rm = TRUE),
#     min_emp_se      = min(emp_se, na.rm = TRUE),
#     q1_emp_se       = q_fun(emp_se, 0.25),
#     q3_emp_se       = q_fun(emp_se, 0.75),
#     iqr_emp_se      = q3_emp_se - q1_emp_se,
#     max_emp_se      = max(emp_se, na.rm = TRUE),
#     .groups = "drop"
#   )
# 
# gt_empse <- tab_empse %>%
#   dplyr::mutate(
#     dplyr::across(
#       c(mean_emp_se, sd_emp_se, median_emp_se, mad_emp_se,
#         min_emp_se, q1_emp_se, q3_emp_se, iqr_emp_se, max_emp_se),
#       ~ scales::number(.x, accuracy = 0.0001)
#     )
#   ) %>%
#   gt::gt() %>%
#   gt::tab_header(
#     title = "Gamma Interaction — Full Descriptive Statistics: Empirical SE",
#     subtitle = "Scenario-level empirical SE (Monte Carlo SD of the estimator) summarised across scenarios by treatment"
#   ) %>%
#   gt::cols_label(
#     scenarios = "N scenarios",
#     mean_emp_se = "Mean",
#     sd_emp_se = "SD",
#     median_emp_se = "Median",
#     mad_emp_se = "MAD",
#     min_emp_se = "Min",
#     q1_emp_se = "Q1",
#     q3_emp_se = "Q3",
#     iqr_emp_se = "IQR",
#     max_emp_se = "Max"
#   ) %>%
#   gt::tab_options(data_row.padding = gt::px(1))
# 
# gt_empse_full_overall |> 
#   gtsave(
#     here::here("results/tbl_empse_descr.rtf")
#   )

compute_ESE_metrics <- function(df) {

  df |>
    group_by(treatment, nobs, prop_extreme, magnitude_level) |>
    summarise(
      # Empirical standard error
      ese = sd(est, na.rm = TRUE),

      # Model-based SE summaries
      se_model_mean = mean(se, na.rm = TRUE),
      se_model_median = median(se, na.rm = TRUE),

      # Ratio of empirical to model SE
      ratio_ese_model = ese / se_model_mean,

      # RMSE of SE estimator
      rmse_se = sqrt(mean((se - ese)^2, na.rm = TRUE)),

      # Monte Carlo standard error of ESE
      mcse_ese = sd(est, na.rm = TRUE) / sqrt(n()),

      # Distribution summaries of ESE across reps
      ese_min = min(est, na.rm = TRUE),
      ese_max = max(est, na.rm = TRUE),
      ese_median = median(est, na.rm = TRUE),
      ese_mad = mad(est, na.rm = TRUE),

      # Under/over calibration
      prop_under_se = mean(se < ese, na.rm = TRUE),
      under_majority_se = prop_under_se > 0.5,

      .groups = "drop"
    )
}

ese_results <- compute_ESE_metrics(all_df_gamma)

ese_by_treatment <-  ese_results |>
  group_by(treatment) |>
  summarise(
    mean_ese = mean(ese),
    median_ese = median(ese),
    sd_ese = sd(ese),
    mad_ese = mad(ese),
    min_ese = min(ese),
    max_ese = max(ese),

    # calibration across treatments
    n_treat_under = sum(under_majority_se),
    prop_treat_under = mean(under_majority_se),

    .groups = "drop"
  )

ese_by_treatment_gt <- ese_by_treatment %>%
  dplyr::mutate(
    dplyr::across(
      c(mean_ese, sd_ese, median_ese, mad_ese,
        min_ese, max_ese, prop_treat_under),
      ~ scales::number(.x, accuracy = 0.0001)
    )
  ) |> 
  gt()
ese_by_treatment_gt


ese_by_scenario <- ese_results |>
  group_by(nobs, prop_extreme, magnitude_level) |>
  summarise(
    mean_ese = mean(ese),
    median_ese = median(ese),
    sd_ese = sd(ese),
    mad_ese = mad(ese),
    min_ese = min(ese),
    max_ese = max(ese),

    # calibration across treatments
    n_treat_under = sum(under_majority_se),
    prop_treat_under = mean(under_majority_se),

    .groups = "drop"
  )

# ---- Coverage (overall) ----
tab_gamma_cov_overall <- summ_gamma %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(
    scenarios       = dplyr::n(),
    mean_cov        = mean(coverage, na.rm = TRUE),
    p_cov_below_95  = mean(coverage < 0.95, na.rm = TRUE),
    .groups = "drop"
  )

gt_gamma_cov_overall <- tab_gamma_cov_overall %>%
  dplyr::mutate(
    mean_cov       = scales::percent(mean_cov, accuracy = 0.1),
    p_cov_below_95 = scales::percent(p_cov_below_95, accuracy = 0.1)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Descriptive Statistics: Coverage (All Scenarios)",
    subtitle = "Nominal = 95%; table reports mean coverage and share of scenarios < 95%"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

# Stratified tables by prop_extreme * n * magnitude level 
# A tiny formatter for numeric columns
num4 <- function(x) scales::number(x, accuracy = 0.0001)

tab_cov_full_overall <- summ_gamma %>%
  dplyr::group_by(treatment) %>%
  dplyr::summarise(
    scenarios         = dplyr::n(),
    mean_cov          = mean(coverage, na.rm = TRUE),
    sd_cov            = sd(coverage, na.rm = TRUE),
    median_cov        = median(coverage, na.rm = TRUE),
    mad_cov           = mad(coverage, na.rm = TRUE),
    min_cov           = min(coverage, na.rm = TRUE),
    q1_cov            = q_fun(coverage, 0.25),
    q3_cov            = q_fun(coverage, 0.75),
    iqr_cov           = q3_cov - q1_cov,
    max_cov           = max(coverage, na.rm = TRUE),
    # policy-relevant shares around nominal 0.95
    p_cov_below_95    = mean(coverage < 0.95, na.rm = TRUE),
    p_cov_ge_95       = mean(coverage >= 0.95, na.rm = TRUE),
    .groups = "drop"
  )

gt_cov_full_overall <- tab_cov_full_overall %>%
  dplyr::mutate(
    # format coverage fields as percents where appropriate
    dplyr::across(
      c(mean_cov, sd_cov, median_cov, mad_cov, min_cov, q1_cov, q3_cov, iqr_cov, max_cov),
      ~ scales::percent(.x, accuracy = 0.1)
    ),
    p_cov_below_95 = scales::percent(p_cov_below_95, accuracy = 0.1),
    p_cov_ge_95    = scales::percent(p_cov_ge_95, accuracy = 0.1)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Full Descriptive Statistics: Coverage",
    subtitle = "Scenario-level coverage summarised across scenarios by treatment (nominal: 95%)"
  ) %>%
  gt::cols_label(
    scenarios = "N scenarios",
    mean_cov = "Mean",
    sd_cov = "SD",
    median_cov = "Median",
    mad_cov = "MAD",
    min_cov = "Min",
    q1_cov = "Q1",
    q3_cov = "Q3",
    iqr_cov = "IQR",
    max_cov = "Max",
    p_cov_below_95 = "Share < 95%",
    p_cov_ge_95    = "Share ≥ 95%"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

gt_cov_full_overall

# Factory that returns a gt table for a given data frame + header labels
make_gt_table <- function(df, title, subtitle) {
  gt::gt(df) |>
    gt::tab_header(title = title, subtitle = subtitle) |>
    gt::tab_options(data_row.padding = gt::px(1))
}

num4 <- function(x) scales::number(x, accuracy = 0.0001)


tab_bias_stratified <- all_df_gamma %>%
  dplyr::group_by(treatment, prop_extreme, nobs, magnitude_level) %>%
  dplyr::summarise(
    scenarios      = dplyr::n(),
    mean_bias      = mean(bias, na.rm = TRUE),
    median_bias    = median(bias, na.rm = TRUE),
    mad_bias       = mad(bias, na.rm = TRUE),
    mean_abs_bias  = mean(abs(bias), na.rm = TRUE),
    .groups = "drop"
  ) %>%
  dplyr::mutate(
    mean_bias     = num4(mean_bias),
    median_bias   = num4(median_bias),
    mad_bias      = num4(mad_bias),
    mean_abs_bias = num4(mean_abs_bias)
  )

bias_tables_by_treatment <- tab_bias_stratified %>%
  dplyr::group_split(treatment)

gt_bias_by_treatment <- lapply(bias_tables_by_treatment, function(df) {
  trt <- df$treatment[1]

  make_gt_table(
    df %>% dplyr::select(-treatment),
    title = glue::glue("Gamma Interaction — Bias (All Scenarios)"),
    subtitle = glue::glue("Treatment = {trt}")
  )
})

for (i in seq_along(gt_bias_by_treatment)) { 
  trt <- unique(bias_tables_by_treatment[[i]]$treatment) 
  
  gt::gtsave( 
    gt_bias_by_treatment[[i]], 
    filename = here::here(paste0("results/tbl_bias_treatment_", trt, "_", dt, ".rtf"))
    ) }

```  

## Over/under estimation  

```{r over_underests}
# Replicate-level indicator of underestimation for gamma model
under_over_scen <- all_df_gamma %>%
  group_by(treatment, nobs, prop_extreme, magnitude_level) %>%
  summarise(
    n_under = sum(est < true, na.rm = TRUE), # count of underestimates 
    n_over = sum(est > true, na.rm = TRUE),
    under_rate = mean(est < true, na.rm = TRUE),
    over_rate  = mean(est > true, na.rm = TRUE),
    n_design=n(),
    .groups = "drop"
  ) |> 
  mutate(
    pct_under = scales::percent(under_rate, accuracy = 0.1),
    pct_over = scales::percent(over_rate, accuracy = 0.1)
  ) |> 
  ungroup() |> 
  select(treatment, n_design, nobs, prop_extreme, magnitude_level, n_under, n_over, pct_under, pct_over, under_rate, over_rate) |> 
  mutate(
     # 'consistently under' if majority of reps are < 0 bias in that scenario
    under_majority = under_rate > 0.5,
    over_majority  = over_rate > 0.5
  ) |>
  mutate(
    prop_extreme = as.numeric(prop_extreme),
    magnitude_level = as.numeric(magnitude_level),
    treatment = as.character(treatment)
  )

under_over_scen |> 
  arrange(nobs, prop_extreme, magnitude_level, treatment) |> 
  mutate(
    treatment = factor(
      treatment,
      levels = c("raw","topcode","mean_adj","median_adj","truncate"),
      labels = c("Raw","Top-coding", "Mean-preserved top-coding", "Median-preserved top-coding","Truncation"))
    ) |> 
  select(-c(under_rate, over_rate)) |> 
  gt() |> 
  gt::gtsave(
    here::here("results/tbl_over_under_scen.rtf")
)


# Aggregate to treatment-level “consistency” table
tab_consistency <- summ_gamma |>
  mutate(
    treatment = as.character(treatment)) |>
  left_join( 
    under_over_scen |> 
      mutate(prop_extreme = 
               case_when(prop_extreme == 1 ~ 0.01,
                         prop_extreme == 2 ~ 0.05,
                         prop_extreme == 3 ~ 0.10)),
    by = c("treatment",
      "nobs", 
      "prop_extreme",
      "magnitude_level")
    ) |>
  group_by(treatment) %>%
  summarise(
    n_scen = dplyr::n(),
    
    total_under = sum(n_under, na.rm = TRUE), # total reps underestimating 
    total_over = sum(n_over, na.rm = TRUE), # total reps overestimating 
    total_reps = sum(n_scen, na.rm = TRUE), # total reps across scenarios 
    
    avg_under_per_scen = mean(n_under, na.rm = TRUE), 
    avg_over_per_scen = mean(n_over, na.rm = TRUE),
    
    share_scen_under = mean(bias < 0, na.rm = TRUE),  
    # % scenarios with negative mean bias
    share_scen_over  = mean(bias > 0, na.rm = TRUE),
    share_scen_under_majority = mean(under_majority, na.rm = TRUE),
    .groups = "drop"
  )

gt_consistency <- tab_consistency %>%
  mutate(
    share_scen_under = scales::percent(share_scen_under, accuracy = 0.1),
    share_scen_over  = scales::percent(share_scen_over, accuracy = 0.1),
    share_scen_under_majority = scales::percent(
      share_scen_under_majority, accuracy = 0.1)
   #  mean_cov = scales::percent(mean_cov, accuracy = 0.1),
    # mean_emp_se = scales::number(mean_emp_se, accuracy = 0.0001)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction: Consistency of Under/Over-Estimation by Treatment",
    subtitle = "Share of scenarios with negative mean bias and with majority underestimation"
  )

gt_consistency

gt::gtsave(
  gt_consistency,
    here::here("results/tbl_over_under_tx.rtf")
)
```    

```{r bias_by_scen}
scenario_summary <- under_over_scen |>
  group_by(nobs, prop_extreme, magnitude_level) |>
  summarise(
    n_treatments = n(),   # should equal number of treatments

    # counts of treatments that under/over
    n_treat_under = sum(under_rate > 0.5, na.rm = TRUE),
    n_treat_over  = sum(over_rate  > 0.5, na.rm = TRUE),

    # counts of treatments with majority under/over
    n_treat_under_majority = sum(under_majority, na.rm = TRUE),
    n_treat_over_majority  = sum(over_majority,  na.rm = TRUE),

    # proportions (denominator = number of treatments)
    prop_treat_under = n_treat_under / n_treatments,
    prop_treat_over  = n_treat_over  / n_treatments,
    prop_treat_under_majority = n_treat_under_majority / n_treatments,

    .groups = "drop"
  )

scenario_summary |> 
  gt() |> 
  gtsave(
    here::here("results/tbl_over_under_scen_summary.rtf")
  )

```



## Plots  

### Lollipop  

```{r lolly1}

prep_plot_bias_over_under <- summ_gamma |>
  left_join(
    under_over_scen |>
      mutate(
        prop_extreme = case_when(
          prop_extreme == 1 ~ 0.01,
          prop_extreme == 2 ~ 0.05,
          prop_extreme == 3 ~ 0.10
        )
      ),
    by = c("treatment", "nobs", "prop_extreme", "magnitude_level")
  ) |>
  mutate(
    nobs = factor(nobs, levels = c(5000, 10000, 20000)),
    prop_extreme = factor(prop_extreme, levels = c(0.01, 0.05, 0.10)),
    magnitude_level = factor(magnitude_level, levels = c(1, 2, 3)),
    treatment = factor(treatment),
    scenario = glue::glue("p={prop_extreme}, n={nobs}, m={magnitude_level}")
  ) |>
  arrange(nobs, prop_extreme, magnitude_level, treatment) |>
  mutate(
    scenario = factor(scenario, levels = rev(unique(scenario)))
  )

x_min <- min(prep_plot_bias_over_under$bias, na.rm = TRUE) # -0.024372
x_max <- max(prep_plot_bias_over_under$bias, na.rm = TRUE) # 0.10535



# table 
tab_27 <- prep_plot_bias_over_under |>
  group_by(treatment) |>
  summarise(
    n_scen = n(),   # should be 27

    scen_under = sum(bias < 0, na.rm = TRUE),
    scen_over  = sum(bias > 0, na.rm = TRUE),
    scen_under_majority = sum(under_majority, na.rm = TRUE),

    prop_scen_under = scen_under / 27,
    prop_scen_over  = scen_over  / 27,
    prop_scen_under_majority = scen_under_majority / 27,

    .groups = "drop"
  )

tab_27 |> 
  mutate(
    prop_scen_under = scales::percent(prop_scen_under, accuracy = 0.1),
    prop_scen_over  = scales::percent(prop_scen_over, accuracy = 0.1),
    prop_scen_under_majority = scales::percent(
      prop_scen_under_majority, accuracy = 0.1),
  ) |> 
  gt() |> 
  gtsave(here::here("results/tab_27.rtf"))


plots_bias <- prep_plot_bias_over_under |> 
  group_split(treatment) |> 
  map(~ { trt <- unique(.x$treatment) 
  ggplot(.x, aes(x = bias, y = scenario)) + 
    geom_segment(
      aes(x = 0, xend = bias, y = scenario, yend = scenario), 
      linewidth = 0.6, color = "grey60") + 
    geom_point(size = 3, color = "steelblue") + 
    scale_x_continuous(limits = c(x_min, x_max)) + 
    labs( x = "Bias", y = "Scenario (prop_extreme, nobs, magnitude_level)", 
          title = paste("Lollipop Chart of Bias — Treatment:", trt) ) +
    theme_minimal(base_size = 13) + 
    theme( panel.grid.major.y = element_blank(), 
           panel.grid.minor = element_blank(), 
           axis.text.y = element_text(size = 10), 
           plot.title = element_text(face = "bold"), 
           axis.title.y = element_blank() ) }
  )


plots_bias[[1]]
plots_bias

# df_plot |>
#   group_split(treatment) |>
#   walk(~ {
#     trt <- unique(.x$treatment)
# 
#     p <- ggplot(.x, aes(x = scenario, y = bias)) +
#       geom_segment(aes(x = scenario, xend = scenario, y = 0, yend = bias),
#                    linewidth = 0.6, color = "grey60") +
#       geom_point(size = 3, color = "steelblue") +
#       labs(
#         x = "Scenario",
#         y = "Bias",
#         title = glue::glue("Bias Across Scenarios — Treatment: {trt}")
#       ) +
#       theme_minimal(base_size = 13) +
#       theme(
#         panel.grid.major.x = element_blank(),
#         axis.text.x = element_text(size = 9, angle = 45, hjust = 1)
#       )
# 
#     print(p)
#   })


```


```{r plots_dir}

plot_bias_lollipop <- scenario_stats %>%
  group_by(treatment) %>%
  summarise(
    mean_of_means = mean(bias, na.rm = TRUE),
    sd_of_means   = sd(bias, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(sign = ifelse(mean_of_means < 0, "Underestimation (−)", "Overestimation (+)"),
         treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate")) %>%
  ggplot(aes(x = treatment, y = mean_of_means, color = sign)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_segment(aes(xend = treatment, y = 0, yend = mean_of_means), linewidth = 1.2) +
  geom_point(size = 3) +
  scale_color_manual(values = c("Underestimation (−)" = "#C7372F", "Overestimation (+)" = "#2B6CB0")) +
  labs(
    title = "Gamma Interaction: Average Scenario-Mean Bias by Treatment",
    subtitle = "Positive = overestimation; Negative = underestimation",
    x = NULL, y = "Average of scenario means (bias)"
  ) +
  theme_minimal() +
  theme(legend.position = "top")

plot_bias_lollipop
ggsave(here::here(paste0("figures/gamma_bias_lollipop_", dt, ".png")),
       plot_bias_lollipop, width = 8, height = 5, dpi = 300)
```  

### lollipop x2  
```{r lolli_v2}
# Reuse your scenario-level summary table for the Gamma interaction
summ_gamma <- summ_grid %>%
  dplyr::filter(model == "gamma") %>%
  dplyr::mutate(
    treatment = forcats::fct_relevel(
      treatment, "raw", "topcode", "mean_adj", "median_adj", "truncate"
    ),
    # scenario id string and absolute bias to plot
    scen_id = paste0("prop=", prop_extreme, " | mag=", magnitude_level, " | n=", n),
    abs_bias = abs(bias)
  )

# Option 1: one lollipop per scenario: 

make_lollipop <- function(df_one_scen) {
  scen_lab <- df_one_scen$scen_id[1]
  ggplot(df_one_scen, aes(x = abs_bias, y = treatment)) +
    geom_segment(aes(x = 0, xend = abs_bias, y = treatment, yend = treatment),
                 linewidth = 1.2, color = "grey55") +
    geom_point(size = 3, color = "#2B6CB0") +
    geom_text(aes(label = scales::number(abs_bias, accuracy = 0.0001)),
              nudge_x = 0.002, size = 3.1, hjust = 0) +
    labs(
      title = "Absolute Bias by Treatment (Scenario Lollipop)",
      subtitle = scen_lab,
      x = "Absolute bias |bias| (scenario mean across reps)",
      y = NULL
    ) +
    scale_x_continuous(expand = expansion(mult = c(0, .10))) +
    theme_minimal() +
    theme(panel.grid.major.y = element_blank())
}

# Split by scenario and save each plot
by_scenario <- split(summ_gamma, summ_gamma$scen_id)

for (nm in names(by_scenario)) {
  p <- make_lollipop(by_scenario[[nm]])
  out_path <- here::here(paste0("figures/lollipop_absbias_", gsub("[^A-Za-z0-9]+", "_", nm), "_", dt, ".png"))
  ggsave(out_path, p, width = 7.5, height = 4.5, dpi = 300)
}

```  

### Trend lines for how bias change with mag of extremes, prop of extremes 
```{r trend_lines}
# --- Trend lines including n as a scenario condition ---
# Treat magnitude level as numeric for trend fitting
scenario_stats_num <- scenario_stats %>%
  dplyr::mutate(
    mag = as.numeric(as.character(magnitude_level)),
    treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate"),
    n = as.factor(n)  # factor for clean facet labels
  )

plot_trends <- ggplot(
  scenario_stats_num,
  aes(x = mag, y = bias, color = treatment, group = treatment)
) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  stat_summary(fun = mean, geom = "line", linewidth = 1.1) +
  stat_summary(fun = mean, geom = "point", size = 2) +
  facet_grid(n ~ prop_extreme, labeller = label_both) +
  scale_x_continuous(breaks = c(1, 2, 3), labels = c("1", "2", "3")) +
  labs(
    title = "Gamma Interaction: Trend in Mean Bias Across Magnitude of Extremes",
    subtitle = "Rows = n; Cols = proportion extreme; lines show scenario-means averaged at each magnitude level",
    x = "Magnitude level", y = "Scenario-mean bias"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

plot_trends
ggsave(here::here(paste0("figures/gamma_bias_trends_", dt, ".png")),
       plot_trends, width = 11, height = 7, dpi = 300)
```

2C. Coverage heatmap vs nominal 0.95  
```{r plot_cov_heat}
plot_cov_heat <- summ_gamma %>%
  dplyr::mutate(
    treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate"),
    cell = paste0("prop=", prop_extreme, ", mag=", magnitude_level, ", n=", n)
  ) %>%
  ggplot(aes(x = treatment, y = cell, fill = coverage)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "#C7372F", mid = "white", high = "#2B6CB0",
    midpoint = 0.95, limits = c(0, 1), labels = scales::percent
  ) +
  labs(
    title = "Gamma Interaction: Coverage by Treatment and Scenario",
    subtitle = "Blue ≥ nominal 95%; red shows undercoverage; y-label encodes prop, mag, and n",
    x = "Treatment", y = "Scenario (prop, mag, n)", fill = "Coverage"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

plot_cov_heat
ggsave(here::here(paste0("figures/gamma_coverage_heat_", dt, ".png")),
       plot_cov_heat, width = 11, height = 8, dpi = 300)
```    


2D. Consistency bars: % of scenarios with majority underestimation  
```{r fig_underest}

plot_under_consistency <- scenario_stats %>%
  group_by(treatment) %>%
  summarise(share_under_majority = mean(under_majority, na.rm = TRUE), .groups = "drop") %>%
  mutate(treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate")) %>%
  ggplot(aes(treatment, share_under_majority)) +
  geom_col(fill = "#C7372F") +
  geom_text(aes(label = scales::percent(share_under_majority, accuracy = 0.1)),
            vjust = -0.3) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Gamma Interaction: Consistency of Underestimation by Treatment",
    subtitle = "% of scenarios where >50% of reps underestimated",
    x = NULL, y = "% scenarios"
  ) +
  theme_minimal()

plot_under_consistency
ggsave(here::here(paste0("figures/gamma_under_consistency_", dt, ".png")),
       plot_under_consistency, width = 8, height = 5, dpi = 300)
```  

3. Auto-generate sentences  
Summarize direction, magnitude, reliability per treatment using tables above  
```{r sentences}
sentences <- tab_consistency %>%
  mutate(
    dir = ifelse(as.numeric(avg_mean_bias) < 0, "underestimated", "overestimated"),
    abs_avg = abs(as.numeric(avg_mean_bias)),
    txt = glue::glue(
      "On average across {n_scen} scenarios, the {treatment} method {dir} ",
      "the Gamma interaction by {scales::number(abs_avg, accuracy = 0.0001)}. ",
      "Median scenario-mean bias was {med_mean_bias}. ",
      "{scales::percent(share_scen_under, accuracy = 0.1)} of scenarios had negative mean bias, ",
      "and {scales::percent(share_scen_under_majority, accuracy = 0.1)} showed majority underestimation. ",
      "Mean empirical SE was {mean_emp_se}, and mean coverage was {scales::percent(mean_cov, accuracy = 0.1)}."
    )
  ) %>%
  dplyr::pull(txt)

cat(paste0("- ", sentences, collapse = "\n"))
```  

##4 FULL-FACTORIAL ANOVA (RQ answers)



```{r aov_bias}


# Type III ANOVA with Eta² and Partial Eta² for Gamma Bias
# Get summary statistics for all_df_gamma bias overall . 
summary(all_df_gamma$bias)
sd(all_df_gamma$bias, na.rm = TRUE)
var(all_df_gamma$bias, na.rm = TRUE)

# Plot distribution
hist(all_df_gamma$bias, breaks = 100, main = "Distribution of Bias")

# A) factorial ANOVA on gamma bias (at rep-level, per meeting with Tsai)
# Load required packages
pacman::p_load(car, effectsize, dplyr, tibble, knitr, kableExtra)

# Ensure factors are properly set
all_df_gamma <- all_df_gamma %>%
  mutate(
    treatment = factor(treatment),
    nobs = factor(nobs),
    prop_extreme = factor(prop_extreme),
    magnitude_level = factor(magnitude_level)
  )


# ============================================================
# Type III ANOVA with Eta² and Partial Eta² for Gamma Bias
# ============================================================

# Load required packages
pacman::p_load(car, effectsize, dplyr, tibble, knitr, kableExtra)

# Ensure factors are properly set
all_df_gamma <- all_df_gamma %>%
  mutate(
    treatment = factor(treatment),
    n = factor(n),
    prop_extreme = factor(prop_extreme),
    magnitude_level = factor(magnitude_level)
  )

# Set contrasts for Type III SS (required!)
options(contrasts = c("contr.sum", "contr.poly"))

# ============================================================
# Step 1: Fit the model
# ============================================================

model <- aov(bias ~ treatment * n * prop_extreme * magnitude_level, 
             data = all_df_gamma)

# ============================================================
# Step 2: Type III Sum of Squares ANOVA Table
# ============================================================

type3_anova <- car::Anova(model, type = "III")
print(type3_anova)

# ============================================================
# Step 3: Effect Sizes (Both Eta² and Partial Eta²)
# ============================================================

# Get regular eta²
eta2_regular <- effectsize::eta_squared(model, 
                                        partial = FALSE,
                                        ci = 0.95)
print(eta2_regular)

# Get partial eta²
eta2_partial <- effectsize::eta_squared(model, 
                                        partial = TRUE,
                                        ci = 0.95)
print(eta2_partial)

# ============================================================
# Step 4: Combined Table (Type III SS + Effect Sizes)
# ============================================================

# Extract Type III results
type3_df <- type3_anova %>%
  as.data.frame() %>%
  rownames_to_column("Term") %>%
  filter(Term != "Residuals")

# Extract regular eta²
eta2_reg_df <- eta2_regular %>%
  as.data.frame() %>%
  select(Parameter, Eta2)

# Extract partial eta²
eta2_part_df <- eta2_partial %>%
  as.data.frame() %>%
  select(Parameter, Eta2_partial)

# Combine everything - simplified version (point estimates only)
combined_table <- type3_df %>%
  left_join(eta2_reg_df, by = c("Term" = "Parameter")) %>%
  left_join(eta2_part_df, by = c("Term" = "Parameter")) %>%
  mutate(
    `Sum Sq` = round(`Sum Sq`, 6),
    `F value` = round(`F value`, 2),
    `Pr(>F)` = format.pval(`Pr(>F)`, digits = 3, eps = 0.001),
    Eta2 = round(Eta2, 5),
    Eta2_partial = round(Eta2_partial, 5),
    # Add interpretation column (handle NAs for intercept)
    Interpretation = case_when(
      is.na(Eta2_partial) ~ "N/A",           # Handle NAs first
      Eta2_partial < 0.01 ~ "Negligible",
      Eta2_partial < 0.06 ~ "Small",
      Eta2_partial < 0.14 ~ "Medium",
      TRUE ~ "Large"
    )
  ) %>%
  select(Term, Df, `Sum Sq`, `F value`, `Pr(>F)`, Eta2, Eta2_partial, Interpretation) %>%
  arrange(desc(`F value`))

print(combined_table)

# ============================================================
# Step 5: Export to CSV
# ============================================================

write.csv(combined_table, 
          file = paste0("results/anova_type3_", dt, ".csv"),
          row.names = FALSE)

# ============================================================
# Step 6: Publication-Ready Table (Simple version)
# ============================================================

combined_table %>%
  kable(
    caption = "Type III ANOVA with Effect Sizes: Gamma Model Bias. Note: η² = eta-squared; η²p = partial eta-squared. Effect size benchmarks: small (0.01), medium (0.06), large (0.14).",
    digits = c(0, 0, 6, 2, 4, 5, 5, 0),
    col.names = c("Effect", "df", "Sum Sq", "F", "p", "η²", "η²p", "Interpretation"),
    align = c("l", "r", "r", "r", "r", "r", "r", "l")
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE
  )

# ============================================================
# Step 7: Identify Significant Effects and Large Effect Sizes
# ============================================================

significant_effects <- combined_table %>%
  filter(Term != "(Intercept)") %>%  # Exclude intercept
  filter(`Pr(>F)` < 0.001 | `Pr(>F)` == "<.001") %>%
  arrange(desc(Eta2_partial))

cat("\n=== SIGNIFICANT EFFECTS (p < .001) ===\n")
print(significant_effects)

large_effects <- combined_table %>%
  filter(Term != "(Intercept)") %>%  # Exclude intercept
  filter(Eta2_partial >= 0.01) %>%  # At least "small" effects
  arrange(desc(Eta2_partial))

cat("\n=== SMALL OR LARGER EFFECT SIZES (η²p ≥ .01) ===\n")
print(large_effects)

# ============================================================
# Step 8: Summary Statistics
# ============================================================

# Exclude intercept for summary
combined_no_int <- combined_table %>% filter(Term != "(Intercept)")

cat("\n=== SUMMARY ===\n")
cat("Total effects tested:", nrow(combined_no_int), "\n")
cat("Significant at p < .001:", 
    sum(grepl("<.001", combined_no_int$`Pr(>F)`)), "\n")
cat("Significant at p < .05:", 
    sum(as.numeric(gsub("<.001", "0", combined_no_int$`Pr(>F)`)) < 0.05, na.rm = TRUE), "\n")
cat("Small+ effect sizes (η²p ≥ .01):", 
    sum(combined_no_int$Eta2_partial >= 0.01, na.rm = TRUE), "\n")
cat("Largest partial eta²:", 
    round(max(combined_no_int$Eta2_partial, na.rm = TRUE), 5), 
    "for", combined_no_int$Term[which.max(combined_no_int$Eta2_partial)], "\n")

# Summary interpretation
cat("\n=== INTERPRETATION ===\n")
cat("Mean bias across all conditions:", round(mean(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("SD of bias:", round(sd(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("Range of bias:", round(range(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("\nAll effect sizes are negligible (< .01), indicating that treatment method,\n")
cat("sample size, proportion of extremes, and magnitude have minimal practical\n")
cat("impact on bias. The vast majority of variance in bias (>99%) is due to\n")
cat("random sampling variability, not systematic differences between conditions.\n")

# ============================================================
# OPTIONAL: Post-hoc tests for significant main effects
# ============================================================

library(emmeans)

# Only run post-hoc if effect is significant AND at least small
sig_main_effects <- significant_effects %>%
  filter(!grepl(":", Term)) %>%  # Only main effects, not interactions
  filter(Eta2_partial >= 0.001)  # At least 0.1% variance explained

if ("treatment" %in% sig_main_effects$Term) {
  cat("\n=== POST-HOC: Pairwise Comparisons for Treatment ===\n")
  emm_treatment <- emmeans(model, ~ treatment)
  pairs_treatment <- pairs(emm_treatment, adjust = "tukey")
  print(pairs_treatment)
  
  # Save post-hoc results
  write.csv(as.data.frame(pairs_treatment),
            file = paste0("results/posthoc_treatment_", dt, ".csv"),
            row.names = FALSE)
}

if ("prop_extreme" %in% sig_main_effects$Term) {
  cat("\n=== POST-HOC: Pairwise Comparisons for Proportion Extreme ===\n")
  emm_prop <- emmeans(model, ~ prop_extreme)
  pairs_prop <- pairs(emm_prop, adjust = "tukey")
  print(pairs_prop)
  
  write.csv(as.data.frame(pairs_prop),
            file = paste0("results/posthoc_prop_extreme_", dt, ".csv"),
            row.names = FALSE)
}

if ("magnitude_level" %in% sig_main_effects$Term) {
  cat("\n=== POST-HOC: Pairwise Comparisons for Magnitude Level ===\n")
  emm_mag <- emmeans(model, ~ magnitude_level)
  pairs_mag <- pairs(emm_mag, adjust = "tukey")
  print(pairs_mag)
  
  write.csv(as.data.frame(pairs_mag),
            file = paste0("results/posthoc_magnitude_", dt, ".csv"),
            row.names = FALSE)
}

# ============================================================
# OPTIONAL: Check ANOVA assumptions
# ============================================================

cat("\n=== CHECKING ANOVA ASSUMPTIONS ===\n")

# 1. Normality of residuals (sample if too large)
if (nrow(all_df_gamma) > 5000) {
  shapiro_test <- shapiro.test(sample(residuals(model), 5000))
  cat("Shapiro-Wilk test for normality (n=5000 sample): W =", 
      round(shapiro_test$statistic, 4), 
      ", p =", format.pval(shapiro_test$p.value), "\n")
} else {
  shapiro_test <- shapiro.test(residuals(model))
  cat("Shapiro-Wilk test for normality: W =", 
      round(shapiro_test$statistic, 4), 
      ", p =", format.pval(shapiro_test$p.value), "\n")
}

# 2. Homogeneity of variance (Levene's test)
levene_test <- car::leveneTest(bias ~ treatment * n * prop_extreme * magnitude_level, 
                               data = all_df_gamma)
cat("Levene's test for homogeneity: F =", round(levene_test$`F value`[1], 4),
    ", p =", format.pval(levene_test$`Pr(>F)`[1]), "\n")

# 3. Diagnostic plots
png(paste0("figures/anova_diagnostics_", dt, ".png"), 
    width = 10, height = 8, units = "in", res = 300)
par(mfrow = c(2, 2))
plot(model)
dev.off()

cat("Diagnostic plots saved to figures/anova_diagnostics_", dt, ".png\n")

# ============================================================
# Step 9: Visualize Effect Sizes
# ============================================================

library(ggplot2)

# Plot partial eta² for significant effects
plot_data <- combined_table %>%
  filter(Term != "(Intercept)") %>%
  filter(`Pr(>F)` < 0.05 | `Pr(>F)` == "<.001") %>%
  mutate(
    Term = reorder(Term, Eta2_partial),
    Significant = ifelse(`Pr(>F)` == "<.001" | 
                        as.numeric(gsub("<.001", "0", `Pr(>F)`)) < 0.001,
                        "p < .001", "p < .05")
  )

p_effect_sizes <- ggplot(plot_data, aes(x = Eta2_partial, y = Term, fill = Significant)) +
  geom_col() +
  geom_vline(xintercept = 0.01, linetype = "dashed", color = "red", alpha = 0.5) +
  geom_vline(xintercept = 0.06, linetype = "dashed", color = "orange", alpha = 0.5) +
  geom_vline(xintercept = 0.14, linetype = "dashed", color = "green", alpha = 0.5) +
  scale_fill_manual(values = c("p < .001" = "steelblue", "p < .05" = "lightblue")) +
  labs(
    title = "Partial Eta-Squared for Significant Effects",
    subtitle = "Dashed lines: small (0.01), medium (0.06), large (0.14) benchmarks",
    x = "Partial η²",
    y = "Effect",
    fill = "Significance"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

print(p_effect_sizes)

ggsave(paste0("figures/effect_sizes_", dt, ".png"),
       p_effect_sizes, width = 10, height = 6, dpi = 300)

cat("\n=== COMPLETE ===\n")
cat("All results saved to results/ and figures/ directories.\n")


```    

```{r cov_grid}
# C) coverage will just be descriptive
cov_grid <- all_df_gamma %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(coverage = mean(cover_ind, na.rm = TRUE), .groups = "drop")

fn_save_results(cov_grid)

```  

```{r aov_att_absbias}
# D) Do anova on ATT absolute bias, not bias, at the replicate level.
```






