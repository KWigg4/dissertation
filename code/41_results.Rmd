---
title: "Results"
author: "KW"
date: "`r Sys.Date()`"
output: html_document
---

PURPOSE: Chapters 4 and 5. After DGP is run and executed, tables are created for results. Import these to make display assets and run ANOVAs.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r pkgs}
pacman::p_load(
  broom,
  dplyr,
  effectsize,
  forcats,
  # furrr,
  ggforce,
  ggplot2,
  ggrepel,
  glue,
  gt,
  here,
  lubridate,
  purrr,
  readr,
  scales,
  # tibble,
  tidyr)

dt <- lubridate::today()
#dir.create("results", showWarnings = FALSE)
#dir.create("figures", showWarnings = FALSE)

conflicted::conflicts_prefer(
  dplyr::select(),
  dplyr::filter()
)

# Save csv and RDS to results directory
fn_save_results <- function(df) {
  name <- deparse(substitute(df))
  saveRDS(df, here::here(paste0("results/",name,"_",dt, ".RDS")))
  write.csv(df,here::here(paste0("results/",name,"_",dt, ".csv")))
}

# Reads datasets created on 02-21:
fn_readRDS <- function(ds) {
  ds <- deparse(substitute(ds))
  readRDS(here::here(paste0("results/",ds,"_2026-02-21.RDS")))
}

# Helper for quantiles
q_fun <- function(x, p) stats::quantile(x, probs = p, na.rm = TRUE, type = 7)

```  


```{r get_replicates}

## Used for analysis, the successful gammas at the replicate level:
all_df_gamma <- fn_readRDS(all_df_gamma) |> 
  relocate(nobs_fct, .after = nobs) |> 
  relocate(prop_extreme_fct, .after=prop_extreme) |> 
  relocate(magnitude_fct, .after=magnitude_level) |> 
  relocate(treatment_fct, .after=treatment)
## N=67,371

## All n=67500 expected replicates with failure status:
all_df_gamma_w_fails <- fn_readRDS(all_df_gamma_w_fails)

## Only the failures (N=129): 
all_df_gamma_fails <- fn_readRDS(all_df_gamma_fails)

# ATT
## 
all_df_att <- fn_readRDS(all_df_att)

```   

```{r fails}
failure_log <- read.csv(here::here("results/failure_log_2026-02-21.csv")) %>%
  # n_failures is numeric in real rows and blank/text in notes rows
  filter(!is.na(n_failures), !is.na(magnitude_level)) %>%
  mutate(
    n    = as.numeric(n),
    nobs = n * 2,
    nobs_fct = factor(nobs,
      levels = c(5000, 10000, 20000),
      labels = c("5,000", "10,000", "20,000")),
    magnitude_fct = factor(magnitude_level,
      levels = c(1, 2, 3),
      labels = c("1 ($50K–$1M)", "2 ($50K–$2M)", "3 ($50K–$3M)")),
    prop_extreme_fct = factor(prop_extreme,
      levels = c(0.01, 0.05, 0.10),
      labels = c("0.01", "0.05", "0.10")),
    error_type = case_when(
      grepl("step size",        gamma_error) ~ "Step size truncated",
      grepl("did not converge", gamma_error) ~ "Did not converge",
      grepl("NA/NaN/Inf",       gamma_error) ~ "NA/NaN/Inf in x"
    )
  )
```


```{r get_summ_grid}

# Get design id and n_design from summ_gamma 
design_elements <- fn_readRDS(summ_gamma) |> 
  select(
    nobs, prop_extreme, magnitude_level, treatment, design_id) |> 
  # won't join if you don't change this back to character.
  mutate(treatment=as.character(treatment))
  
summ_grid  <- fn_readRDS(summ_grid) |> 
  left_join(
    design_elements, 
    by = c("treatment", "nobs", "prop_extreme", "magnitude_level")) |> 
  select(design_id, model, 
         nobs, nobs_fct, 
         prop_extreme, prop_extreme_fct,
         magnitude_level, magnitude_fct,
         treatment, treatment_fct,
         everything()) |> 
  mutate(
    scen_id = paste0(
      "prop=", prop_extreme_fct, " | mag=", magnitude_fct, " | n=", nobs_fct),
  )

summ_gamma <- summ_grid |> 
  filter(model == "gamma") 

# Make your own for this (later) because you need abs_bias from all_df_att
# summ_att <- summ_grid |> 
#   filter(model=="ATT")
  
```  

## Failures  

```{r}
# Total N for percentages
total_failures <- sum(failure_log$n_failures)  # 129
total_reps     <- 67500                         # B=500 * 135 scenarios * 1 model

# --- Table 1: By error type ---
tbl_by_error <- failure_log %>%
  group_by(error_type) %>%
  summarise(n = sum(n_failures), .groups = "drop") %>%
  mutate(
    pct_of_failures = scales::percent(n / total_failures, accuracy = 0.1),
    pct_of_all_reps = scales::percent(n / total_reps,     accuracy = 0.2)
  )

# --- Table 2: By condition ---
tbl_by_condition <- failure_log %>%
  group_by(nobs_fct, prop_extreme_fct, magnitude_fct) %>%
  summarise(n = sum(n_failures), .groups = "drop") %>%
  mutate(
    pct_of_failures = scales::percent(n / total_failures, accuracy = 0.1),
    pct_of_500      = scales::percent(n / 500,            accuracy = 0.1)
  ) %>%
  arrange(nobs_fct, prop_extreme_fct, magnitude_fct)

write.csv(tbl_by_condition,
          here::here("results/tbl_failures_condition_2026-02-22.csv"))

# --- Table 3: All -------
tbl_reasons_conditions <- failure_log |> 
  group_by(nobs_fct, prop_extreme_fct, magnitude_fct, error_type) %>%
  summarize(n_fails=sum(n_failures), .groups="drop") |> 
  mutate(
    pct_of_failures = scales::percent(n_fails / total_failures, accuracy = 0.1),
    pct_of_500      = scales::percent(n_fails / 500,            accuracy = 0.1)
  ) %>%
  arrange(error_type, nobs_fct, prop_extreme_fct, magnitude_fct)
write.csv(tbl_reasons_conditions,
          here::here("results/tbl_failures_reason_condition_2026-02-22.csv"))
# --- GT table combining both ---
tbl_by_error %>%
  gt() %>%
  tab_header(
    title    = "Gamma Model Convergence Failures",
    subtitle = glue("Total: {total_failures} failures across 67,500 replications (0.19%)")
  ) %>%
  cols_label(
    error_type      = "Failure Type",
    n               = "N Failures",
    pct_of_failures = "% of Failures",
    pct_of_all_reps = "% of All Reps"
  ) %>%
  tab_source_note(
    "All failures occurred in raw (untreated) condition only. 
     No failures in top-coding, mean-adj, median-adj, or truncation."
  )

tbl_by_condition %>%
  gt() %>%
  tab_header(
    title    = "Failures by Simulation Condition",
    subtitle = "% of 500 reps = failure rate within that condition"
  ) %>%
  cols_label(
    nobs_fct         = "N (obs)",
    prop_extreme_fct = "Prop. Extreme",
    magnitude_fct    = "Magnitude",
    n                = "N Failures",
    pct_of_failures  = "% of All Failures",
    pct_of_500       = "% of 500 Reps"
  )


```  



```{r}
# checking for balance
all_df_gamma |>
  dplyr::group_by(nobs, prop_extreme, magnitude_level, treatment) |>
  dplyr::summarise(n_count=n()) |> 
  View()

all_df_gamma |>
  dplyr::count(nobs, prop_extreme, magnitude_level, treatment) |>
  dplyr::count(nobs)

```  

## 

```{r descr_bias}
# Focus on the Gamma Part-2 interaction (can switch to "ATT" later)

# ---- Bias (overall) ----
# mean_bias is average SIGNED bias; preserves direction of estimator's errors, where neg is systematic underestimation and positive is systematic overestimation and opposing signs are going to cancel each other out. 
# The mean_abs_bias is the average absolute magnitude of the bias, which measures how far the estimator is from the truth on average. Does not allow pos/neg to cancel each other out. Always >=0. Larger values indicate more inconsistent or unstable estimation. 
# Mean_abs_bias captures estimator error magnitude, while mean_bias captures estimator direction. mean_bias answers if treatment method systematically over or under estimates the effect, while mean_abs_bias answers how large are the estimation errors, regardless of direction. A method an have a mean bias of 0 and look good but actually perform poorly when you see a large mean_abs_bias because that means it swings pos in some directions, negative in others. 

tbl_bias_overall <- all_df_gamma %>%
  dplyr::summarise(
    scenarios        = dplyr::n(),
    mean_bias        = mean(bias, na.rm = TRUE),
    sd_bias          = sd(bias, na.rm = TRUE),
    median_bias      = median(bias, na.rm = TRUE),
    mad_bias         = mad(bias, na.rm = TRUE),
    min_bias         = min(bias, na.rm = TRUE),
    q1_bias          = q_fun(bias, 0.25),
    q3_bias          = q_fun(bias, 0.75),
    iqr_bias         = q3_bias - q1_bias,
    max_bias         = max(bias, na.rm = TRUE),
    mean_abs_bias    = mean(abs(bias), na.rm = TRUE),
    share_bias_neg   = mean(bias < 0, na.rm = TRUE),
    share_bias_pos   = mean(bias > 0, na.rm = TRUE),
    .groups = "drop"
  )

print(tbl_bias_overall)

tbl_bias_treatment <- all_df_gamma %>%
  dplyr::group_by(treatment_fct) %>%
  dplyr::summarise(
    scenarios        = dplyr::n(),
    mean_bias        = mean(bias, na.rm = TRUE),
    sd_bias          = sd(bias, na.rm = TRUE),
    median_bias      = median(bias, na.rm = TRUE),
    mad_bias         = mad(bias, na.rm = TRUE),
    min_bias         = min(bias, na.rm = TRUE),
    q1_bias          = q_fun(bias, 0.25),
    q3_bias          = q_fun(bias, 0.75),
    iqr_bias         = q3_bias - q1_bias,
    max_bias         = max(bias, na.rm = TRUE),
    mean_abs_bias    = mean(abs(bias), na.rm = TRUE),
    share_bias_neg   = mean(bias < 0, na.rm = TRUE),
    share_bias_pos   = mean(bias > 0, na.rm = TRUE),
    .groups = "drop"
  )
print(tbl_bias_treatment)

gt_bias_treatment <- tbl_bias_treatment %>%
  dplyr::mutate(
    dplyr::across(
      c(mean_bias, sd_bias, median_bias, mad_bias, min_bias, q1_bias, 
        q3_bias, iqr_bias, max_bias, mean_abs_bias),
      ~ scales::number(.x, accuracy = 0.0001)
    ),
    share_bias_neg = scales::percent(share_bias_neg, accuracy = 0.1),
    share_bias_pos = scales::percent(share_bias_pos, accuracy = 0.1)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Full Descriptive Statistics: Bias",
    subtitle = "Scenario-level bias (mean signed bias per scenario) summarized across scenarios by treatment"
  ) %>%
  gt::cols_label(
    scenarios      = "N scenarios",
    mean_bias      = "Mean",
    sd_bias        = "SD",
    median_bias    = "Median",
    mad_bias       = "MAD",
    min_bias       = "Min",
    q1_bias        = "Q1",
    q3_bias        = "Q3",
    iqr_bias       = "IQR",
    max_bias       = "Max",
    mean_abs_bias  = "Mean |bias|",
    share_bias_neg = "Share bias < 0",
    share_bias_pos = "Share bias > 0"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

gtsave(gt_bias_treatment, here::here("results/tbl_bias_treatment.rtf"))

```  

## Over/under estimation  

```{r over_underests}
# Replicate-level indicator of underestimation for gamma model
tbl_bias_UnderOver_scen <- all_df_gamma %>%
  group_by(treatment_fct, nobs_fct, prop_extreme_fct, magnitude_fct) %>%
  summarise(
    n_under = sum(est < true, na.rm = TRUE), # count of underestimates 
    n_over = sum(est > true, na.rm = TRUE),
    under_rate = mean(est < true, na.rm = TRUE),
    over_rate  = mean(est > true, na.rm = TRUE),
    n_design=n(),
    .groups = "drop"
  ) |> 
  mutate(
    pct_under = scales::percent(under_rate, accuracy = 0.1),
    pct_over = scales::percent(over_rate, accuracy = 0.1)
  ) |> 
  ungroup() |> 
  select(treatment_fct, n_design, nobs_fct, prop_extreme_fct, magnitude_fct, n_under, n_over, pct_under, pct_over, under_rate, over_rate) |> 
  mutate(
     # 'consistently under' if majority of reps are < 0 bias in that scenario
    under_majority = under_rate > 0.5,
    over_majority  = over_rate > 0.5
  )

tbl_bias_UnderOver_scen |> 
  arrange(nobs_fct, prop_extreme_fct, magnitude_fct, treatment_fct) |> 
  select(-c(under_rate, over_rate)) |> 
  gt() |> 
  gt::gtsave(
    here::here("results/tbl_over_under_scen.rtf")
)

# Aggregate to treatment-level “consistency” table
tab_consistency <- summ_gamma |>
  left_join( 
    tbl_bias_UnderOver_scen,
    by = c("treatment_fct", "nobs_fct", "prop_extreme_fct", "magnitude_fct")
    ) |>
  group_by(treatment_fct) %>%
  summarise(
    n_scen = dplyr::n(),
    
    total_under = sum(n_under, na.rm = TRUE), # total reps underestimating 
    total_over = sum(n_over, na.rm = TRUE), # total reps overestimating 
    total_reps = sum(n_scen, na.rm = TRUE), # total reps across scenarios 
    
    avg_under_per_scen = mean(n_under, na.rm = TRUE), 
    avg_over_per_scen = mean(n_over, na.rm = TRUE),
    
    share_scen_under = mean(bias < 0, na.rm = TRUE),  
    # % scenarios with negative mean bias
    share_scen_over  = mean(bias > 0, na.rm = TRUE),
    share_scen_under_majority = mean(under_majority, na.rm = TRUE),
    .groups = "drop"
  )
```    

```{r bias_by_scen}
scenario_summary <- tbl_bias_UnderOver_scen |>
  group_by(nobs_fct, prop_extreme_fct, magnitude_fct) |>
  summarise(
    n_treatments = n(),   # should equal number of treatments

    # counts of treatments that under/over
    n_treat_under = sum(under_rate > 0.5, na.rm = TRUE),
    n_treat_over  = sum(over_rate  > 0.5, na.rm = TRUE),

    # counts of treatments with majority under/over
    n_treat_under_majority = sum(under_majority, na.rm = TRUE),
    n_treat_over_majority  = sum(over_majority,  na.rm = TRUE),

    # proportions (denominator = number of treatments)
    prop_treat_under = n_treat_under / n_treatments,
    prop_treat_over  = n_treat_over  / n_treatments,
    prop_treat_under_majority = n_treat_under_majority / n_treatments,

    .groups = "drop"
  )

scenario_summary |>
  gt() |>
  gtsave(
    here::here("results/tbl_over_under_scen_summary.rtf")
  )

```



## Plots  

### Lollipop  

```{r lolly1}

prep_plot_bias_over_under <- summ_gamma |>
  left_join(
    tbl_bias_UnderOver_scen,
    by = c("treatment_fct", "nobs_fct", "prop_extreme_fct", "magnitude_fct")
  ) |>
  mutate(
    scenario = glue::glue("p={prop_extreme}, n={nobs}, m={magnitude_level}")
  ) |>
  arrange(nobs, prop_extreme, magnitude_level, treatment) |>
  mutate(
    scenario = factor(scenario, levels = rev(unique(scenario)))
  )

x_min <- min(prep_plot_bias_over_under$bias, na.rm = TRUE) # -0.024372
x_max <- max(prep_plot_bias_over_under$bias, na.rm = TRUE) # 0.10535

# table 
tab_27 <- prep_plot_bias_over_under |>
  group_by(treatment_fct) |>
  summarise(
    n_scen = n(),   # should be 27

    scen_under = sum(bias < 0, na.rm = TRUE),
    scen_over  = sum(bias > 0, na.rm = TRUE),
    scen_under_majority = sum(under_majority, na.rm = TRUE),

    prop_scen_under = scen_under / 27,
    prop_scen_over  = scen_over  / 27,
    prop_scen_under_majority = scen_under_majority / 27,

    .groups = "drop"
  )

tab_27 |> 
  mutate(
    prop_scen_under = scales::percent(prop_scen_under, accuracy = 0.1),
    prop_scen_over  = scales::percent(prop_scen_over, accuracy = 0.1),
    prop_scen_under_majority = scales::percent(
      prop_scen_under_majority, accuracy = 0.1),
  ) |> 
  gt() |> 
  gtsave(here::here("results/tab_27.rtf"))

plots_bias <- prep_plot_bias_over_under |> 
  group_split(treatment_fct) |> 
  map(~ { 
    trt <- unique(.x$treatment_fct)

    ggplot(.x, aes(x = bias, y = scenario)) +
      geom_segment(
        aes(x = 0, xend = bias, y = scenario, yend = scenario),
        linewidth = 0.6, color = "grey60"
      ) +
      geom_point(
        aes(color = abs(bias) > 0.04),
        size = 2
      ) +
      scale_color_manual(
        values = c(`TRUE` = "red", `FALSE` = "steelblue"),
        guide = "none"
      ) +
      scale_x_continuous(limits = c(x_min, x_max)) +
      labs(
        x = "Bias",
        y = "Scenario (prop_extreme, nobs, magnitude_level)",
        title = paste("Bias — Treatment:", trt),
        subtitle = "Values >|0.04| are red"
      ) +
      theme_minimal(base_size = 12) +
      theme(
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(size = 10),
        axis.title.y = element_blank(),
        plot.title = element_text(face = "bold", hjust = 0),
        plot.title.position = "plot"   # left-align title with y-axis
      )
  })

plots_bias[[1]]
plots_bias
```


```{r plots_dir}

prep_plot_bias_lollipop2 <- summ_gamma %>%
  group_by(treatment_fct) %>%
  summarise(
    mean_of_means = mean(bias, na.rm = TRUE),
    sd_of_means   = sd(bias, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    sign = ifelse(
      mean_of_means < 0, "Underestimation (−)", "Overestimation (+)")) 
  
plot_bias_lollipop <- prep_plot_bias_lollipop |> 
  ggplot(aes(x = treatment_fct, y = mean_of_means, color = sign)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_segment(
    aes(xend = treatment_fct, y = 0, yend = mean_of_means), linewidth = 1.2) +
  geom_point(size = 3) +
  scale_color_manual(values = c("Underestimation (−)" = "#C7372F", "Overestimation (+)" = "#2B6CB0")) +
  labs(
    title = "Gamma Interaction: Average Scenario-Mean Bias by Treatment",
    subtitle = "Positive = overestimation; Negative = underestimation",
    x = NULL, y = "Average of scenario means (bias)"
  ) +
  theme_minimal() +
  theme(legend.position = "top")

plot_bias_lollipop
ggsave(here::here(paste0("figures/gamma_bias_lollipop_", dt, ".png")),
       plot_bias_lollipop, width = 8, height = 5, dpi = 300)
```  


### Trend lines for how bias change with mag of extremes, prop of extremes 
```{r bias_jitter}
# --- Trend lines including n as a scenario condition ---
# Treat magnitude level as numeric for trend fitting

plot_trends <- ggplot(
  summ_gamma,
  aes(
    x = magnitude_fct,
    y = bias,
    color = treatment_fct
  )
) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_jitter(
    width = 0.2,  
    height = 0,
    size = 3,
    alpha = 0.7
  ) +
  facet_grid(nobs_fct ~ prop_extreme_fct, 
             labeller = labeller(
               nobs_fct = function(x) paste0("N=",x),
               prop_extreme_fct = function(x) paste0(
                 "Prop. Extreme=",x)
               )
             ) +
  scale_color_manual( 
    name = "Data Treatment", 
    values = c(
      "No treatment" = "#0072B2",
      "Top-coding" = "#E69F00",
      "Mean-preserved top-coding" = "#009E73",
      "Median-preserved top-coding" = "#CC79A7",
      "Truncation" = "#D55E00" ) ) +
  labs(
    title = "Gamma Interaction: Scenario-Level Bias Across Magnitude of Extremes",
    subtitle = "Rows = N; Cols = proportion extreme; points show scenario-level bias",
    x = "Magnitude level",
    y = "Bias"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom",
        legend.title = element_text(face = "bold"))

plot_trends
ggsave(here::here(paste0("figures/gamma_bias_trends_", dt, ".png")),
       plot_trends, width = 11, height = 7, dpi = 300)
```

## RQ2: Empirical SE  


```{r descr_empse}

compute_ESE_metrics <- function(df) {

  df |>
    group_by(treatment_fct, nobs_fct, prop_extreme_fct, magnitude_fct) |>
    summarise(
      # Empirical standard error
      ese = sd(est, na.rm = TRUE),

      # Model-based SE summaries
      se_model_mean = mean(se, na.rm = TRUE),
      se_model_median = median(se, na.rm = TRUE),

      # Ratio of empirical to model SE
      ratio_ese_model = ese / se_model_mean,

      # RMSE of SE estimator
      rmse_se = sqrt(mean((se - ese)^2, na.rm = TRUE)),

      # Monte Carlo standard error of ESE
      mcse_ese = sd(est, na.rm = TRUE) / sqrt(n()),

      # Distribution summaries of ESE across reps
      ese_min = min(est, na.rm = TRUE),
      ese_max = max(est, na.rm = TRUE),
      ese_median = median(est, na.rm = TRUE),
      ese_mad = mad(est, na.rm = TRUE),

      # Under/over calibration
      prop_under_se = mean(se < ese, na.rm = TRUE),
      under_majority_se = prop_under_se > 0.5,

      .groups = "drop"
    )
}

ese_results <- compute_ESE_metrics(all_df_gamma) 
# N=135 (all scenarios*treatment)

fn_save_results(ese_results)

ese_by_treatment <-  ese_results |>
  group_by(treatment_fct) |>
  summarise(
    mean_ese = mean(ese),
    median_ese = median(ese),
    sd_ese = sd(ese),
    mad_ese = mad(ese),
    min_ese = min(ese),
    max_ese = max(ese),

    # calibration across treatments
    n_treat_under = sum(under_majority_se),
    prop_treat_under = mean(under_majority_se),

    .groups = "drop"
  )
fn_save_results(ese_by_treatment)

ese_by_treatment_gt <- ese_by_treatment %>%
  dplyr::mutate(
    dplyr::across(
      c(mean_ese, sd_ese, median_ese, mad_ese,
        min_ese, max_ese, prop_treat_under),
      ~ scales::number(.x, accuracy = 0.0001)
    )
  ) |> 
  gt()
ese_by_treatment_gt


ese_by_scenario <- ese_results |>
  group_by(nobs_fct, prop_extreme_fct, magnitude_fct) |>
  summarise(
    mean_ese = mean(ese),
    median_ese = median(ese),
    sd_ese = sd(ese),
    mad_ese = mad(ese),
    min_ese = min(ese),
    max_ese = max(ese),

    # calibration across treatments
    n_treat_under = sum(under_majority_se),
    prop_treat_under = mean(under_majority_se),

    .groups = "drop"
  )

fn_save_results(ese_by_scenario)

```    

```{r ese_plots}

prep_plot_ese <- ese_results |>
  mutate(
    scenario = glue("p={prop_extreme_fct}, n={nobs_fct}, m={magnitude_fct}"),
    scenario = factor(scenario)
  ) |>
  arrange(nobs_fct, prop_extreme_fct, desc(magnitude_fct), treatment_fct)

x_min <- min(prep_plot_ese$ese, na.rm = TRUE)
x_max <- max(prep_plot_ese$ese, na.rm = TRUE)

plots_ese <- prep_plot_ese |>
  mutate(
    color_flag = ifelse(ese > 0.25, "high", "low")
  ) |>
  group_split(treatment_fct) |>
  map(~ {
    trt <- unique(.x$treatment_fct)

    ggplot(.x, aes(x = ese, y = scenario)) +
      geom_segment(
        aes(x = 0, xend = ese, y = scenario, yend = scenario),
        linewidth = 0.6,
        color = "grey80"
      ) +
      geom_point(
        aes(color = color_flag),
        size = 2
      ) +
      scale_color_manual(
        values = c(
          "high" = "red",
          "low"  = "grey40"
        ),
        guide = "none"
      ) +
      scale_x_continuous(limits = c(x_min, x_max)) +
      labs(
        x = "Empirical SE",
        y = "Scenario (prop_extreme, nobs, magnitude_level)",
        title = paste("Lollipop Chart of Empirical SE — Treatment:", trt)
      ) +
      theme_minimal(base_size = 12) +
      theme(
        panel.grid.major.y = element_blank(),
        panel.grid.minor = element_blank(),
        axis.text.y = element_text(size = 10),
        plot.title = element_text(face = "bold"),
        axis.title.y = element_blank()
      )
  })

plots_ese[[1]]
plots_ese[[2]]
plots_ese[[3]]
plots_ese[[4]]
plots_ese[[5]]

```  

```{r ese_ggridge}
library(ggridges)

ggplot(ese_results,
       aes(x = ese, y = treatment_fct, fill = treatment_fct)) +
  geom_density_ridges(alpha = 0.7) +
  facet_grid(prop_extreme_fct ~ magnitude_fct + nobs_fct,
             labeller = label_both) +
  labs(
    title = "Empirical SE Distributions by Treatment",
    x = "Empirical SE",
    y = "Treatment"
  ) +
  theme_minimal(base_size = 12) +
  theme(strip.text = element_text(face = "bold"),
        legend.position = "none")

```



```{r}
# ---- Coverage (overall) ----

# All 135 treatment*conditions
cov_grid <- all_df_gamma %>%
  group_by(treatment_fct, nobs_fct, prop_extreme_fct, magnitude_fct) %>%
  summarise(coverage = mean(cover_ind, na.rm = TRUE), .groups = "drop")

fn_save_results(cov_grid)

# 5 treatments
tab_cov_treatment <- summ_gamma |>
  group_by(treatment_fct) |>
  summarise(
    scenarios = dplyr::n(),
    mean_cov = mean(coverage, na.rm = TRUE),
    sd_cov = sd(coverage, na.rm = TRUE),
    median_cov = median(coverage, na.rm = TRUE),
    mad_cov = mad(coverage, na.rm = TRUE),
    min_cov = min(coverage, na.rm = TRUE),
    # q1_cov = quantile(coverage, 0.25, na.rm = TRUE),
    # q3_cov = quantile(coverage, 0.75, na.rm = TRUE),
    # iqr_cov = q3_cov - q1_cov,
    max_cov = max(coverage, na.rm = TRUE),
    n_below_95 = sum(coverage < 0.95),
    prop_below_95 = mean(coverage < 0.95),
    .groups = "drop"
  )
write.csv(
  tab_cov_treatment,
  here::here("results/tab_cov_treatment_2026-02-17.csv")
)

# coverage by scenarios (N=27)
tab_cov_scenario <- summ_gamma |>
  group_by(nobs_fct, prop_extreme_fct, magnitude_fct) |>
  summarise(
    scenarios = dplyr::n(),
    mean_cov = mean(coverage),
    min_cov = min(coverage),
    max_cov = max(coverage),
    n_cov_below_95  = sum(if_else(coverage<0.95,1,0)),
    p_cov_below_95  = mean(coverage < 0.95, na.rm = TRUE),
    n_cov_ge_95     = sum(if_else(coverage>=0.95, 1, 0)),
    p_cov_ge_95     = mean(coverage >= 0.95, na.rm=TRUE),
    .groups = "drop"
  )
write.csv(
  tab_cov_scenario,
  here::here("results/tab_cov_scenario_2026-02-17.csv")
)

# Pass/fail table
tab_cov_passfail <- summ_gamma |>
  group_by(treatment_fct) |>
  summarise(
    scenarios = dplyr::n(),
    n_pass = sum(coverage >= 0.95),
    n_fail = sum(coverage < 0.95),
    prop_pass = mean(coverage >= 0.95),
    prop_fail = mean(coverage < 0.95),
    .groups = "drop"
  )

# reshape to long format for plotting
df_long <- tab_cov_passfail |> 
  select(treatment_fct, prop_pass, prop_fail) |> 
  pivot_longer( 
    cols = c(prop_pass, prop_fail), 
    names_to = "status", values_to = "prop" ) |> 
  mutate( status = factor( 
    status, 
    levels = c("prop_pass", "prop_fail"), 
    labels = c("Pass (≥95%)", "Fail (<95%)") ), 
    label = scales::percent(prop, accuracy = 1) )

df_plot <- ggplot(
  df_long, 
  aes(x = treatment_fct, y = prop, fill = status)) + 
  geom_col(width = 0.7, color = "white") + 
  geom_text( aes(label = label), 
             position = position_stack(vjust = 0.5), 
             color = "white", size = 4.2 ) + 
  scale_fill_manual(
    values = c("Pass (≥95%)" = "steelblue", "Fail (<95%)" = "firebrick")) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) + 
  labs( title = "Coverage Performance by Treatment", 
        subtitle = "Percent of scenarios meeting nominal 95% coverage", 
        x = "Treatment", 
        y = "Proportion of Scenarios", 
        fill = "Coverage Status" ) + 
  theme_minimal(base_size = 13) + 
  theme( axis.text.x = element_text(angle = 25, hjust = 1), 
         plot.title = element_text(face = "bold") )

# Line plot for means by scenario: 

cov_mean_plot <- tab_cov_scenario |>
  mutate(
    status = ifelse(mean_cov >= 0.95, "≥95%", "<95%"),
    status = factor(status, levels = c("<95%", "≥95%"))
  )

ggplot(cov_mean_plot, 
       aes(x = magnitude_fct, y = mean_cov, color = status)) +
  geom_point(size = 3) +
  scale_color_manual(values = c("<95%" = "firebrick", "≥95%" = "steelblue")) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  facet_grid(nobs_fct ~ prop_extreme_fct) +
  labs(
    title = "Mean Coverage Across Scenarios",
    x = "Magnitude",
    y = "Mean Coverage",
    color = "Coverage Status"
  ) +
  theme_minimal(base_size = 13) +
  theme(
    plot.title = element_text(face = "bold"),
    strip.text = element_text(face = "bold")
  )



cov_plot_scen_prep <- cov_mean_plot |> 
  select(
    nobs_fct, prop_extreme_fct, magnitude_fct, p_cov_below_95, p_cov_ge_95
  ) |> 
  pivot_longer(
    cols = c(p_cov_ge_95, p_cov_below_95), 
    names_to = "status", values_to = "prop"
  ) |> 
  mutate(
    status = factor(
      status,
      levels = c("p_cov_below_95", "p_cov_ge_95"),
      labels = c("Fail (<95%)", "Pass (>=95%)")
    ),
    label = scales::percent(prop, accuracy = 1)
  )

cov_plot_scen_prep <- cov_plot_scen_prep |>
  mutate(
    status = forcats::fct_relevel(
      status,"Pass (>=95%)", "Fail (<95%)")
  )

ggplot(
  cov_plot_scen_prep, aes(x = magnitude_fct, y = prop, fill = status)
) +
  geom_col(width = 0.7, color = "white") +
  geom_text(
    aes(label = ifelse(prop == 0, "", label)),
    position = position_stack(vjust = 0.5),
    color = "white",
    size = 2.8
  ) +
  scale_fill_manual(
    values = setNames(
      c("steelblue", "firebrick"),
      levels(cov_plot_scen_prep$status)
    )
  ) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)) +
  facet_grid(nobs_fct ~ prop_extreme_fct) +
  labs(
    title = "Proportion of Scenarios Meeting Nominal 95% Coverage",
    x = "Magnitude",
    y = "Proportion of Scenarios",
    fill = "Coverage Status"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    plot.title = element_text(face = "bold"),
    strip.text = element_text(face = "bold"),
    axis.text.x = element_text(angle = 25, hjust = 1)
  )

```




2C. Coverage heatmap vs nominal 0.95  
```{r plot_cov_heat}
plot_cov_heat <- summ_gamma %>%
  dplyr::mutate(
    treatment = forcats::fct_relevel(
      treatment, "raw","topcode","mean_adj","median_adj","truncate"),
    cell = paste0("prop=", prop_extreme, ", mag=", magnitude_level, ", n=", n)
  ) %>%
  ggplot(aes(x = treatment, y = cell, fill = coverage)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(
    low = "#C7372F", mid = "white", high = "#2B6CB0",
    midpoint = 0.95, limits = c(0, 1), labels = scales::percent
  ) +
  labs(
    title = "Gamma Interaction: Coverage by Treatment and Scenario",
    subtitle = "Blue ≥ nominal 95%; red shows undercoverage; y-label encodes prop, mag, and n",
    x = "Treatment", y = "Scenario (prop, mag, n)", fill = "Coverage"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

plot_cov_heat
ggsave(here::here(paste0("figures/gamma_coverage_heat_", dt, ".png")),
       plot_cov_heat, width = 11, height = 8, dpi = 300)
```    


2D. Consistency bars: % of scenarios with majority underestimation  
```{r fig_underest}

plot_under_consistency <- scenario_stats %>%
  group_by(treatment) %>%
  summarise(share_under_majority = mean(under_majority, na.rm = TRUE), .groups = "drop") %>%
  mutate(treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate")) %>%
  ggplot(aes(treatment, share_under_majority)) +
  geom_col(fill = "#C7372F") +
  geom_text(aes(label = scales::percent(share_under_majority, accuracy = 0.1)),
            vjust = -0.3) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Gamma Interaction: Consistency of Underestimation by Treatment",
    subtitle = "% of scenarios where >50% of reps underestimated",
    x = NULL, y = "% scenarios"
  ) +
  theme_minimal()

plot_under_consistency
ggsave(here::here(paste0("figures/gamma_under_consistency_", dt, ".png")),
       plot_under_consistency, width = 8, height = 5, dpi = 300)
```  

3. Auto-generate sentences  
Summarize direction, magnitude, reliability per treatment using tables above  
```{r sentences}
sentences <- tab_consistency %>%
  mutate(
    dir = ifelse(as.numeric(avg_mean_bias) < 0, "underestimated", "overestimated"),
    abs_avg = abs(as.numeric(avg_mean_bias)),
    txt = glue::glue(
      "On average across {n_scen} scenarios, the {treatment} method {dir} ",
      "the Gamma interaction by {scales::number(abs_avg, accuracy = 0.0001)}. ",
      "Median scenario-mean bias was {med_mean_bias}. ",
      "{scales::percent(share_scen_under, accuracy = 0.1)} of scenarios had negative mean bias, ",
      "and {scales::percent(share_scen_under_majority, accuracy = 0.1)} showed majority underestimation. ",
      "Mean empirical SE was {mean_emp_se}, and mean coverage was {scales::percent(mean_cov, accuracy = 0.1)}."
    )
  ) %>%
  dplyr::pull(txt)

cat(paste0("- ", sentences, collapse = "\n"))
```   

## ATT descr  
```{r fn_att_descr}

fn_att_descr <- function(data, dv, group_var = NULL) {

  data |>
    group_by(across(any_of(group_var))) |>
    summarise(
      scenarios   = dplyr::n(),
      mean        = mean({{ dv }}, na.rm = TRUE),
      sd          = sd({{ dv }}, na.rm = TRUE),
      median      = median({{ dv }}, na.rm = TRUE),
      mad         = mad({{ dv }}, na.rm = TRUE),
      min         = min({{ dv }}, na.rm = TRUE),
      q1          = quantile({{ dv }}, 0.25, na.rm = TRUE),
      q3          = quantile({{ dv }}, 0.75, na.rm = TRUE),
      iqr         = q3 - q1,
      max         = max({{ dv }}, na.rm = TRUE),
      mean_abs    = mean(abs({{ dv }}), na.rm = TRUE),
      n_neg       = sum({{ dv }}  < 0, na.rm=TRUE),
      share_neg   = mean({{ dv }} < 0, na.rm = TRUE),
      n_pos       = sum({{ dv }}  > 0, na.rm=TRUE),
      share_pos   = mean({{ dv }} > 0, na.rm = TRUE),
      n_neg_fmt   = paste0(scales::comma(n_neg, accuracy=1),
                           " (",
                           scales::percent(share_neg, accuracy=0.1),
                           ")"),
      n_pos_fmt   = paste0(scales::comma(n_pos, accuracy=1),
                           " (",
                           scales::percent(share_pos, accuracy=0.1),
                           ")"),
      .groups = "drop"
    )
}


```  

```{r att_est_descrs}
att_est_descr <- fn_att_descr(all_df_att, dv=est)

att_est_descr_treat <- fn_att_descr(
  all_df_att, dv=est, group_var = "treatment_fct")

att_est_descr_cond <- fn_att_descr(
  all_df_att, dv=est, group_var = c("nobs_fct","prop_extreme_fct", "magnitude_fct")
)

att_est_desc_scenario <- fn_att_descr(
  all_df_att, dv=est, group_var = c("treatment_fct","nobs_fct","prop_extreme_fct", "magnitude_fct")
)

fn_save_results(att_est_descr)
fn_save_results(att_est_descr_treat)
fn_save_results(att_est_descr_cond)
fn_save_results(att_est_desc_scenario)
```

```{r att_bias_descrs}
att_bias_descr <- fn_att_descr(all_df_att, dv=bias)

att_bias_descr_treat <- fn_att_descr(
  all_df_att, dv=bias, group_var = "treatment_fct")

att_bias_descr_cond <- fn_att_descr(
  all_df_att, dv=bias, group_var = c("nobs_fct","prop_extreme_fct", "magnitude_fct")
)

att_bias_desc_scenario <- fn_att_descr(
  all_df_att, dv=bias, group_var = c("treatment_fct","nobs_fct","prop_extreme_fct", "magnitude_fct")
)

fn_save_results(att_bias_descr)
fn_save_results(att_bias_descr_treat)
fn_save_results(att_bias_descr_cond)
fn_save_results(att_bias_desc_scenario)
```

##4 FULL-FACTORIAL ANOVA (RQ answers)



```{r aov_bias}


# Type III ANOVA with Eta² and Partial Eta² for Gamma Bias


# A) factorial ANOVA on gamma bias (at rep-level, per meeting with Tsai)
# Load required packages
pacman::p_load(car, effectsize, dplyr, tibble, knitr, kableExtra)

# Ensure factors are properly set

# Set contrasts for Type III SS (m!)
options(contrasts = c("contr.sum", "contr.poly"))


# 1: Fit the model

model <- aov(
  bias ~ treatment_fct * nobs_fct * prop_extreme_fct * magnitude_fct, 
  data = all_df_gamma)


# Step 2: Type III Sum of Squares ANOVA Table
type3_anova <- car::Anova(model, type = "III")


# 3: Comb. table ===================================================
# Type III SS + Effect Sizes

# Extract Type III results
type3_df <- type3_anova %>%
  as.data.frame() %>%
  rownames_to_column("Term") %>%
  filter(Term != "Residuals")

# Extract regular eta²
eta2_reg_df <- eta2_regular %>%
  as.data.frame() %>%
  select(Parameter, Eta2)

# Extract partial eta²
eta2_part_df <- eta2_partial %>%
  as.data.frame() %>%
  select(Parameter, Eta2_partial)

# Tried both of these below, came out the same.
# eta2_lsr <- lsr::etaSquared(model, type=3)
# eta2_descTools <- DescTools::EtaSq(model, type=3)

# Combine everything - simplified version (point estimates only)
combined_table <- type3_df %>%
  left_join(eta2_reg_df, by = c("Term" = "Parameter")) %>%
  left_join(eta2_part_df, by = c("Term" = "Parameter")) %>%
  mutate(
    `Sum Sq` = round(`Sum Sq`, 6),
    `F value` = round(`F value`, 2),
    `Pr(>F)` = format.pval(`Pr(>F)`, digits = 3, eps = 0.001),
    Eta2 = round(Eta2, 5),
    Eta2_partial = round(Eta2_partial, 5),
    # Add interpretation column (handle NAs for intercept)
    Interpretation = case_when(
      is.na(Eta2_partial) ~ "N/A",           # Handle NAs first
      Eta2_partial < 0.01 ~ "Negligible",
      Eta2_partial < 0.06 ~ "Small",
      Eta2_partial < 0.14 ~ "Medium",
      TRUE ~ "Large"
    )
  ) %>%
  select(Term, Df, `Sum Sq`, `F value`, `Pr(>F)`, Eta2, Eta2_partial, Interpretation) %>%
  arrange(desc(`F value`))

print(combined_table)

# 4: Export ===================================================
write.csv(combined_table, 
          here::here(paste0("results/aov_bias_type3_", dt, ".csv")),
          row.names = FALSE)

# 6: Pub ready tbl ===========================================
# (Simple version)

combined_table %>%
  kable(
    caption = "Type III ANOVA with Effect Sizes: Gamma Model Bias. Note: η² = eta-squared; η²p = partial eta-squared. Effect size benchmarks: small (0.01), medium (0.06), large (0.14).",
    digits = c(0, 0, 6, 2, 4, 5, 5, 0),
    col.names = c("Effect", "df", "Sum Sq", "F", "p", "η²", "η²p", "Interpretation"),
    align = c("l", "r", "r", "r", "r", "r", "r", "l")
  ) %>%
  kable_styling(
    bootstrap_options = c("striped", "hover", "condensed"),
    full_width = FALSE
  )

# 7: id sig, large es =========================================
# Identify Significant Effects and Large Effect Sizes

significant_effects <- combined_table %>%
  filter(Term != "(Intercept)") %>%  # Exclude intercept
  filter(`Pr(>F)` < 0.001 | `Pr(>F)` == "<.001") %>%
  arrange(desc(Eta2_partial))

cat("\n=== SIGNIFICANT EFFECTS (p < .001) ===\n")
print(significant_effects)

large_effects <- combined_table %>%
  filter(Term != "(Intercept)") %>%  # Exclude intercept
  filter(Eta2_partial >= 0.01) %>%  # At least "small" effects
  arrange(desc(Eta2_partial))

cat("\n=== SMALL OR LARGER EFFECT SIZES (η²p ≥ .01) ===\n")
print(large_effects)

# 8: Summary stats ===========================================

# Exclude intercept for summary
combined_no_int <- combined_table %>% filter(Term != "(Intercept)")

cat("\n=== SUMMARY ===\n")
cat("Total effects tested:", nrow(combined_no_int), "\n")
cat("Significant at p < .001:", 
    sum(grepl("<.001", combined_no_int$`Pr(>F)`)), "\n")
cat("Significant at p < .05:", 
    sum(as.numeric(gsub("<.001", "0", combined_no_int$`Pr(>F)`)) < 0.05, na.rm = TRUE), "\n")
cat("Small+ effect sizes (η²p ≥ .01):", 
    sum(combined_no_int$Eta2_partial >= 0.01, na.rm = TRUE), "\n")
cat("Largest partial eta²:", 
    round(max(combined_no_int$Eta2_partial, na.rm = TRUE), 5), 
    "for", combined_no_int$Term[which.max(combined_no_int$Eta2_partial)], "\n")

# Summary interpretation
cat("\n=== INTERPRETATION ===\n")
cat("Mean bias across all conditions:", round(mean(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("SD of bias:", round(sd(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("Range of bias:", round(range(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("\nAll effect sizes are negligible (< .01), indicating that treatment method,\n")
cat("sample size, proportion of extremes, and magnitude have minimal practical\n")
cat("impact on bias. The vast majority of variance in bias (>99%) is due to\n")
cat("random sampling variability, not systematic differences between conditions.\n")

# Opt: Post hocs ==============================================
# OPTIONAL: Post-hoc tests for significant main effects

library(emmeans)

# Only run post-hoc if effect is significant AND at least small
sig_main_effects <- significant_effects %>%
  filter(!grepl(":", Term)) %>%  # Only main effects, not interactions
  filter(Eta2_partial >= 0.001)  # At least 0.1% variance explained

if ("treatment" %in% sig_main_effects$Term) {
  cat("\n=== POST-HOC: Pairwise Comparisons for Treatment ===\n")
  emm_treatment <- emmeans(model, ~ treatment)
  pairs_treatment <- pairs(emm_treatment, adjust = "tukey")
  print(pairs_treatment)
  
  # Save post-hoc results
  write.csv(as.data.frame(pairs_treatment),
            file = paste0("results/posthoc_treatment_", dt, ".csv"),
            row.names = FALSE)
}

if ("prop_extreme" %in% sig_main_effects$Term) {
  cat("\n=== POST-HOC: Pairwise Comparisons for Proportion Extreme ===\n")
  emm_prop <- emmeans(model, ~ prop_extreme)
  pairs_prop <- pairs(emm_prop, adjust = "tukey")
  print(pairs_prop)
  
  write.csv(as.data.frame(pairs_prop),
            file = paste0("results/posthoc_prop_extreme_", dt, ".csv"),
            row.names = FALSE)
}

if ("magnitude_level" %in% sig_main_effects$Term) {
  cat("\n=== POST-HOC: Pairwise Comparisons for Magnitude Level ===\n")
  emm_mag <- emmeans(model, ~ magnitude_level)
  pairs_mag <- pairs(emm_mag, adjust = "tukey")
  print(pairs_mag)
  
  write.csv(as.data.frame(pairs_mag),
            file = paste0("results/posthoc_magnitude_", dt, ".csv"),
            row.names = FALSE)
}

# Opt: Check assumptions =====================================
# OPTIONAL: Check ANOVA assumptions

cat("\n=== CHECKING ANOVA ASSUMPTIONS ===\n")

# 1. Normality of residuals (sample if too large)
if (nrow(all_df_gamma) > 5000) {
  shapiro_test <- shapiro.test(sample(residuals(model), 5000))
  cat("Shapiro-Wilk test for normality (n=5000 sample): W =", 
      round(shapiro_test$statistic, 4), 
      ", p =", format.pval(shapiro_test$p.value), "\n")
} else {
  shapiro_test <- shapiro.test(residuals(model))
  cat("Shapiro-Wilk test for normality: W =", 
      round(shapiro_test$statistic, 4), 
      ", p =", format.pval(shapiro_test$p.value), "\n")
}

# 2. Homogeneity of variance (Levene's test)
levene_test <- car::leveneTest(bias ~ treatment * n * prop_extreme * magnitude_level, 
                               data = all_df_gamma)
cat("Levene's test for homogeneity: F =", round(levene_test$`F value`[1], 4),
    ", p =", format.pval(levene_test$`Pr(>F)`[1]), "\n")

# 3. Diagnostic plots
png(paste0("figures/anova_diagnostics_", dt, ".png"), 
    width = 10, height = 8, units = "in", res = 300)
par(mfrow = c(2, 2))
plot(model)
dev.off()

cat("Diagnostic plots saved to figures/anova_diagnostics_", dt, ".png\n")


# Plot partial eta² for significant effects
# plot pes ===================================================
# Step 9: Visualize Effect Sizes (CORRECTED)

library(ggplot2)

# Need to go back to BEFORE formatting p-values
plot_data <- type3_df %>%
  left_join(eta2_part_df, by = c("Term" = "Parameter")) %>%
  filter(Term != "(Intercept)") %>%
  filter(`Pr(>F)` < 0.05) %>%  # Use numeric p-values BEFORE formatting
  mutate(
    Term = reorder(Term, Eta2_partial),
    Significant = case_when(
      `Pr(>F)` < 0.001 ~ "p < .001",
      `Pr(>F)` < 0.01 ~ "p < .01",
      `Pr(>F)` < 0.05 ~ "p < .05",
      TRUE ~ "ns"
    )
  )

library(patchwork)  # For combining plots

# Zoomed-in version (what you have now)
p_zoomed <- ggplot(
  plot_data, aes(x = Eta2_partial, y = Term, fill = Significant)) +
  geom_col() +
  scale_fill_manual(
    values = c("p < .001" = "steelblue", 
               "p < .01" = "cornflowerblue",
               "p < .05" = "lightblue"),
    name = "Significance"
  ) +
  labs(
    title = "A) Zoomed View",
    x = "Partial η²",
    y = "Effect"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Full scale version (shows context)
p_full <- ggplot(
  plot_data, aes(x = Eta2_partial, y = Term, fill = Significant)) +
  geom_col() +
  geom_vline(
    xintercept = 0.01, linetype = "dashed", color = "red", alpha = 0.7) +
  geom_vline(
    xintercept = 0.06, linetype = "dashed", color = "orange", alpha = 0.7) +
  geom_vline(
    xintercept = 0.14, linetype = "dashed", color = "green", alpha = 0.7) +
  annotate(
    "text", x = 0.01, y = 6.5, label = "Small", size = 3, color = "red") +
  annotate(
    "text", x = 0.06, y = 6.5, label = "Med", size = 3, color = "orange") +
  annotate(
    "text", x = 0.14, y = 6.5, label = "Large", size = 3, color = "green") +
  scale_fill_manual(
    values = c("p < .001" = "steelblue", 
               "p < .01" = "cornflowerblue",
               "p < .05" = "lightblue"),
    name = "Significance"
  ) +
  scale_x_continuous(
    limits = c(0, 0.15),
    breaks = seq(0, 0.15, 0.03)
  ) +
  labs(
    title = "B) Full Scale (with benchmarks)",
    x = "Partial η²",
    y = NULL
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.y = element_blank()  # Remove duplicate y-axis labels
  )

# Combine side by side
p_combined <- p_zoomed + p_full +
  plot_annotation(
    title = "Partial Eta-Squared for Significant Effects: Gamma Model Bias",
    subtitle = "All effects are negligible - even the largest (0.0027) is far below the 'small' benchmark (0.01)",
    theme = theme(
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(size = 11, color = "gray30")
    )
  )

print(p_combined)

ggsave(here::here(paste0("figures/effect_sizes_combined_", dt, ".png")),
       p_combined, width = 14, height = 6, dpi = 300)

ggsave(here::here(paste0("figures/effect_sizes_", dt, ".png")),
       p_effect_sizes, width = 10, height = 6, dpi = 300)


```    



```{r aov_att_absbias}
# D) Do anova on ATT absolute bias, not bias, at the replicate level.
```






