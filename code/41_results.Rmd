---
title: "Results"
author: "KW"
date: "`r Sys.Date()`"
output: html_document
---

PURPOSE: Chapters 4 and 5. After DGP is run and executed, tables are created for results. Import these to make display assets and run ANOVAs.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r pkgs}
pacman::p_load(
  broom,
  dplyr,
  effectsize,
  forcats,
  # furrr,
  ggforce,
  ggplot2,
  ggrepel,
  glue,
  gt,
  here,
  lubridate,
  purrr,
  readr,
  scales,
  # tibble,
  tidyr)

dt <- lubridate::today()
#dir.create("results", showWarnings = FALSE)
#dir.create("figures", showWarnings = FALSE)

conflicted::conflicts_prefer(
  dplyr::select(),
  dplyr::filter()
)

# Save csv and RDS to results directory
fn_save_results <- function(df) {
  name <- deparse(substitute(df))
  saveRDS(df, here::here(paste0("results/",name,"_",dt, ".RDS")))
  write.csv(df,here::here(paste0("results/",name,"_",dt, ".csv")))
}

# Reads datasets created on 02-25:
fn_readRDS <- function(ds) {
  ds <- deparse(substitute(ds))
  readRDS(here::here(paste0("results/",ds,"_2026-02-25.RDS")))
}

# Helper for quantiles
q_fun <- function(x, p) stats::quantile(x, probs = p, na.rm = TRUE, type = 7)

```  


```{r get_replicates}
# all_df_treatment: summarized at the treatment level only (N=13500 per)
# all_df_2026-02-21 is unformatted/ unchanged from MC sim, DO NOT REMOVE from files. 
# all_df_2026-02-25 is transformed. 

all_df_w_fails <- fn_readRDS(all_df_w_fails) # nrow 202500
all_df_gamma_w_fails <- fn_readRDS(all_df_gamma_w_fails) 
# FAILURES ONLY: 
all_df_gamma_fails <- fn_readRDS(all_df_gamma_fails) # nrow 129
all_df_gamma_fails_tbl <- fn_readRDS(all_df_gamma_fails_tbl) # nrow 9

# all_df_gamma only, failures removed. 
# # # ANALYSIS DATASET for gamma bias ANOVA# # #
all_df_gamma <- fn_readRDS(all_df_gamma) # nrow 67,371

# use for treatment descriptives, RQs 1-3: 
gamma_by_treatment <- fn_readRDS(gamma_by_treatment) # nrow=5

# use for scenario descriptives, RQs 1-3: 
gamma_by_scenario <- fn_readRDS(gamma_by_scenario) # nrow 135

## Used for analysis, the successful att's at the replicate level:
all_df_att <- fn_readRDS(all_df_att) # 67,371

```   

```{r fails}
failure_log <- read.csv(here::here("results/failure_log_2026-02-21.csv")) %>%
  # n_failures is numeric in real rows and blank/text in notes rows
  filter(!is.na(n_failures), !is.na(magnitude_level)) %>%
  mutate(
    n    = as.numeric(n),
    nobs = n * 2,
    nobs_fct = factor(nobs,
      levels = c(5000, 10000, 20000),
      labels = c("5,000", "10,000", "20,000")),
    magnitude_fct = factor(magnitude_level,
      levels = c(1, 2, 3),
      labels = c("1 ($50K–$1M)", "2 ($50K–$2M)", "3 ($50K–$3M)")),
    prop_extreme_fct = factor(prop_extreme,
      levels = c(0.01, 0.05, 0.10),
      labels = c("0.01", "0.05", "0.10")),
    error_type = case_when(
      grepl("step size",        gamma_error) ~ "Step size truncated",
      grepl("did not converge", gamma_error) ~ "Did not converge",
      grepl("NA/NaN/Inf",       gamma_error) ~ "NA/NaN/Inf in x"
    )
  )
```


```{r get_summ_grid, eval=FALSE}

# Get design id and n_design from summ_gamma 
design_elements <- fn_readRDS(summ_gamma) |> 
  select(
    nobs, prop_extreme, magnitude_level, treatment, design_id) |> 
  # won't join if you don't change this back to character.
  mutate(treatment=as.character(treatment))
  
summ_grid  <- fn_readRDS(summ_grid) |> 
  left_join(
    design_elements, 
    by = c("treatment", "nobs", "prop_extreme", "magnitude_level")) |> 
  select(design_id, model, 
         nobs, nobs_fct, 
         prop_extreme, prop_extreme_fct,
         magnitude_level, magnitude_fct,
         treatment, treatment_fct,
         everything()) |> 
  mutate(
    scen_id = paste0(
      "prop=", prop_extreme_fct, " | mag=", magnitude_fct, " | n=", nobs_fct),
  )

summ_gamma <- summ_grid |> 
  filter(model == "gamma") 

# Make your own for this (later) because you need abs_bias from all_df_att
# summ_att <- summ_grid |> 
#   filter(model=="ATT")
  
```  

## Failures  

```{r}
# Total N for percentages
total_failures <- sum(failure_log$n_failures)  # 129
total_reps     <- 67500                         # B=500 * 135 scenarios * 1 model

# --- Table 1: By error type ---
tbl_by_error <- failure_log %>%
  group_by(error_type) %>%
  summarise(n = sum(n_failures), .groups = "drop") %>%
  mutate(
    pct_of_failures = scales::percent(n / total_failures, accuracy = 0.1),
    pct_of_all_reps = scales::percent(n / total_reps,     accuracy = 0.2)
  )

# --- Table 2: By condition ---
tbl_by_condition <- failure_log %>%
  group_by(nobs_fct, prop_extreme_fct, magnitude_fct) %>%
  summarise(n = sum(n_failures), .groups = "drop") %>%
  mutate(
    pct_of_failures = scales::percent(n / total_failures, accuracy = 0.1),
    pct_of_500      = scales::percent(n / 500,            accuracy = 0.1)
  ) %>%
  arrange(nobs_fct, prop_extreme_fct, magnitude_fct)

write.csv(tbl_by_condition,
          here::here("results/tbl_failures_condition_2026-02-22.csv"))

# --- Table 3: All -------
tbl_reasons_conditions <- failure_log |> 
  group_by(nobs_fct, prop_extreme_fct, magnitude_fct, error_type) %>%
  summarize(n_fails=sum(n_failures), .groups="drop") |> 
  mutate(
    pct_of_failures = scales::percent(n_fails / total_failures, accuracy = 0.1),
    pct_of_500      = scales::percent(n_fails / 500,            accuracy = 0.1)
  ) %>%
  arrange(error_type, nobs_fct, prop_extreme_fct, magnitude_fct)
write.csv(tbl_reasons_conditions,
          here::here("results/tbl_failures_reason_condition_2026-02-22.csv"))
# --- GT table combining both ---
tbl_by_error %>%
  gt() %>%
  tab_header(
    title    = "Gamma Model Convergence Failures",
    subtitle = glue("Total: {total_failures} failures across 67,500 replications (0.19%)")
  ) %>%
  cols_label(
    error_type      = "Failure Type",
    n               = "N Failures",
    pct_of_failures = "% of Failures",
    pct_of_all_reps = "% of All Reps"
  ) %>%
  tab_source_note(
    "All failures occurred in raw (untreated) condition only. 
     No failures in top-coding, mean-adj, median-adj, or truncation."
  )

tbl_by_condition %>%
  gt() %>%
  tab_header(
    title    = "Failures by Simulation Condition",
    subtitle = "% of 500 reps = failure rate within that condition"
  ) %>%
  cols_label(
    nobs_fct         = "N (obs)",
    prop_extreme_fct = "Prop. Extreme",
    magnitude_fct    = "Magnitude",
    n                = "N Failures",
    pct_of_failures  = "% of All Failures",
    pct_of_500       = "% of 500 Reps"
  )


```  



```{r}
# checking for balance
all_df_gamma |>
  dplyr::group_by(nobs_fct, prop_extreme_fct, magnitude_fct, treatment_fct) |>
  dplyr::summarise(n_count=n()) |> 
  View()

```  

## Descr bias on interaction  


```{r descr_bias}
# Focus on the Gamma Part-2 interaction (can switch to "ATT" later)

# ---- Bias (overall) ----
# mean_bias is average SIGNED bias; preserves direction of estimator's errors, where neg is systematic underestimation and positive is systematic overestimation and opposing signs are going to cancel each other out. 
# The mean_abs_bias is the average absolute magnitude of the bias, which measures how far the estimator is from the truth on average. Does not allow pos/neg to cancel each other out. Always >=0. Larger values indicate more inconsistent or unstable estimation. 
# Mean_abs_bias captures estimator error magnitude, while mean_bias captures estimator direction. mean_bias answers if treatment method systematically over or under estimates the effect, while mean_abs_bias answers how large are the estimation errors, regardless of direction. A method an have a mean bias of 0 and look good but actually perform poorly when you see a large mean_abs_bias because that means it swings pos in some directions, negative in others. 

tbl_bias_overall <- all_df_gamma %>%
  dplyr::summarise(
    scenarios        = dplyr::n(),
    mean_bias        = mean(bias, na.rm = TRUE),
    sd_bias          = sd(bias, na.rm = TRUE),
    var_bias         = var(bias, na.rm=TRUE),
    median_bias      = median(bias, na.rm = TRUE),
    mad_bias         = mad(bias, na.rm = TRUE),
    min_bias         = min(bias, na.rm = TRUE),
    q1_bias          = q_fun(bias, 0.25),
    q3_bias          = q_fun(bias, 0.75),
    iqr_bias         = q3_bias - q1_bias,
    max_bias         = max(bias, na.rm = TRUE),
    mean_abs_bias    = mean(abs(bias), na.rm = TRUE),
    share_bias_neg   = mean(bias < 0, na.rm = TRUE),
    share_bias_pos   = mean(bias > 0, na.rm = TRUE),
    .groups = "drop"
  )

print(tbl_bias_overall)
write.csv(tbl_bias_overall, 
          here::here("results/tbl_bias_overall_2026-02-25.csv"))

tbl_bias_treatment <- all_df_gamma %>%
  dplyr::group_by(treatment_fct) %>%
  dplyr::summarise(
    scenarios        = dplyr::n(),
    mean_bias        = mean(bias, na.rm = TRUE),
    sd_bias          = sd(bias, na.rm = TRUE),
    median_bias      = median(bias, na.rm = TRUE),
    mad_bias         = mad(bias, na.rm = TRUE),
    min_bias         = min(bias, na.rm = TRUE),
    q1_bias          = q_fun(bias, 0.25),
    q3_bias          = q_fun(bias, 0.75),
    iqr_bias         = q3_bias - q1_bias,
    max_bias         = max(bias, na.rm = TRUE),
    mean_abs_bias    = mean(abs(bias), na.rm = TRUE),
    share_bias_neg   = mean(bias < 0, na.rm = TRUE),
    share_bias_pos   = mean(bias > 0, na.rm = TRUE),
    .groups = "drop"
  )
print(tbl_bias_treatment)
write.csv(tbl_bias_treatment, 
          here::here("results/tbl_bias_treatment_2026-02-25.csv"))

tbl_bias_scen <- all_df_gamma %>%
  dplyr::group_by(treatment_fct, nobs_fct, prop_extreme_fct, magnitude_fct) %>%
  dplyr::summarise(
    scenarios        = dplyr::n(),
    mean_bias        = mean(bias, na.rm = TRUE),
    sd_bias          = sd(bias, na.rm = TRUE),
    median_bias      = median(bias, na.rm = TRUE),
    mad_bias         = mad(bias, na.rm = TRUE),
    min_bias         = min(bias, na.rm = TRUE),
    q1_bias          = q_fun(bias, 0.25),
    q3_bias          = q_fun(bias, 0.75),
    iqr_bias         = q3_bias - q1_bias,
    max_bias         = max(bias, na.rm = TRUE),
    mean_abs_bias    = mean(abs(bias), na.rm = TRUE),
    share_bias_neg   = mean(bias < 0, na.rm = TRUE),
    share_bias_pos   = mean(bias > 0, na.rm = TRUE),
    .groups = "drop"
  ) |> 
  arrange(nobs_fct, prop_extreme_fct, magnitude_fct, treatment_fct)
print(tbl_bias_scen)

write.csv(tbl_bias_scen, 
          here::here("results/tbl_bias_scen_2026-02-25.csv"))

gt_bias_treatment <- tbl_bias_treatment %>%
  dplyr::mutate(
    dplyr::across(
      c(mean_bias, sd_bias, median_bias, mad_bias, min_bias, q1_bias, 
        q3_bias, iqr_bias, max_bias, mean_abs_bias),
      ~ scales::number(.x, accuracy = 0.01)
    ),
    share_bias_neg = scales::percent(share_bias_neg, accuracy = 0.1),
    share_bias_pos = scales::percent(share_bias_pos, accuracy = 0.1)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction — Full Descriptive Statistics: Bias",
    subtitle = "Scenario-level bias (mean signed bias per scenario) summarized across scenarios by treatment"
  ) %>%
  gt::cols_label(
    scenarios      = "N scenarios",
    mean_bias      = "Mean",
    sd_bias        = "SD",
    median_bias    = "Median",
    mad_bias       = "MAD",
    min_bias       = "Min",
    q1_bias        = "Q1",
    q3_bias        = "Q3",
    iqr_bias       = "IQR",
    max_bias       = "Max",
    mean_abs_bias  = "Mean |bias|",
    share_bias_neg = "Share bias < 0",
    share_bias_pos = "Share bias > 0"
  ) %>%
  gt::tab_options(data_row.padding = gt::px(1))

gtsave(gt_bias_treatment, here::here("results/tbl_bias_treatment.rtf"))



```  

## Over/under estimation  

```{r over_underests}
# Replicate-level indicator of underestimation for gamma model
tbl_bias_UnderOver_scen <- all_df_gamma %>%
  group_by(treatment_fct, nobs_fct, prop_extreme_fct, magnitude_fct) %>%
  summarise(
    n_under = sum(est < true, na.rm = TRUE), # count of underestimates 
    n_over = sum(est > true, na.rm = TRUE),
    under_rate = mean(est < true, na.rm = TRUE),
    over_rate  = mean(est > true, na.rm = TRUE),
    n_design=n(),
    .groups = "drop"
  ) |> 
  mutate(
    pct_under = scales::percent(under_rate, accuracy = 0.1),
    pct_over = scales::percent(over_rate, accuracy = 0.1)
  ) |> 
  ungroup() |> 
  select(treatment_fct, n_design, nobs_fct, prop_extreme_fct, magnitude_fct, n_under, n_over, pct_under, pct_over, under_rate, over_rate) |> 
  mutate(
     # 'consistently under' if majority of reps are < 0 bias in that scenario
    under_majority = under_rate > 0.5,
    over_majority  = over_rate > 0.5
  )

# Not including, per meeting with Tsai 
tbl_bias_UnderOver_scen |> 
  arrange(nobs_fct, prop_extreme_fct, magnitude_fct, treatment_fct) |> 
  select(-c(under_rate, over_rate)) |> 
  gt() |> 
  gt::gtsave(
    here::here("results/tbl_over_under_scen.rtf")
)

# Aggregate to treatment-level “consistency” table
# tab_consistency <- summ_gamma |>
#   left_join( 
#     tbl_bias_UnderOver_scen,
#     by = c("treatment_fct", "nobs_fct", "prop_extreme_fct", "magnitude_fct")
#     ) |>
#   group_by(treatment_fct) %>%
#   summarise(
#     n_scen = dplyr::n(),
#     
#     total_under = sum(n_under, na.rm = TRUE), # total reps underestimating 
#     total_over = sum(n_over, na.rm = TRUE), # total reps overestimating 
#     total_reps = sum(n_scen, na.rm = TRUE), # total reps across scenarios 
#     
#     avg_under_per_scen = mean(n_under, na.rm = TRUE), 
#     avg_over_per_scen = mean(n_over, na.rm = TRUE),
#     
#     share_scen_under = mean(bias < 0, na.rm = TRUE),  
#     # % scenarios with negative mean bias
#     share_scen_over  = mean(bias > 0, na.rm = TRUE),
#     share_scen_under_majority = mean(under_majority, na.rm = TRUE),
#     .groups = "drop"
#   )
```    

```{r bias_by_scen}
scenario_summary <- tbl_bias_UnderOver_scen |>
  group_by(nobs_fct, prop_extreme_fct, magnitude_fct) |>
  summarise(
    n_treatments = n(),   # should equal number of treatments

    # counts of treatments that under/over
    n_treat_under = sum(under_rate > 0.5, na.rm = TRUE),
    n_treat_over  = sum(over_rate  > 0.5, na.rm = TRUE),

    # counts of treatments with majority under/over
    n_treat_under_majority = sum(under_majority, na.rm = TRUE),
    n_treat_over_majority  = sum(over_majority,  na.rm = TRUE),

    # proportions (denominator = number of treatments)
    prop_treat_under = n_treat_under / n_treatments,
    prop_treat_over  = n_treat_over  / n_treatments,
    prop_treat_under_majority = n_treat_under_majority / n_treatments,

    .groups = "drop"
  )

# Not using per Tsai
scenario_summary |>
  gt() |>
  gtsave(
    here::here("results/tbl_over_under_scen_summary.rtf")
  )

```



## Plots  

### Lollipop  

```{r lolly1}

prep_plot_bias_over_under <- summ_gamma |>
  left_join(
    tbl_bias_UnderOver_scen,
    by = c("treatment_fct", "nobs_fct", "prop_extreme_fct", "magnitude_fct")
  ) |>
  mutate(
    scenario = glue::glue("p={prop_extreme}, n={nobs}, m={magnitude_level}")
  ) |>
  arrange(nobs, prop_extreme, magnitude_level, treatment) |>
  mutate(
    scenario = factor(scenario, levels = rev(unique(scenario)))
  )

x_min <- min(prep_plot_bias_over_under$bias, na.rm = TRUE) # -0.024372
x_max <- max(prep_plot_bias_over_under$bias, na.rm = TRUE) # 0.095811

# table 
tab_27 <- prep_plot_bias_over_under |>
  group_by(treatment_fct) |>
  summarise(
    n_scen = n(),   # should be 27

    scen_under = sum(bias < 0, na.rm = TRUE),
    scen_over  = sum(bias > 0, na.rm = TRUE),
    scen_under_majority = sum(under_majority, na.rm = TRUE),

    prop_scen_under = scen_under / 27,
    prop_scen_over  = scen_over  / 27,
    prop_scen_under_majority = scen_under_majority / 27,

    .groups = "drop"
  )

tab_27 |> 
  mutate(
    prop_scen_under = scales::percent(prop_scen_under, accuracy = 0.1),
    prop_scen_over  = scales::percent(prop_scen_over, accuracy = 0.1),
    prop_scen_under_majority = scales::percent(
      prop_scen_under_majority, accuracy = 0.1),
  ) |> 
  gt() |> 
  gtsave(here::here("results/tab_27.rtf"))
```  

```{r scenario_lolli_2}
plot_bias_facet <- prep_plot_bias_over_under |>
  ggplot(aes(x = bias, y = scenario)) +
  geom_segment(
    aes(x = 0, xend = bias, y = scenario, yend = scenario),
    linewidth = 0.5, color = "grey60"
  ) +
  geom_point(
    aes(color = abs(bias) > 0.04),
    size = 1.8
  ) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey30", linewidth = 0.4) +
  scale_color_manual(
    values = c(`TRUE` = "red", `FALSE` = "steelblue"),
    labels = c("≤ 0.04", "> 0.04"),
    name   = "|Bias|"
  ) +
  scale_x_continuous(limits = c(x_min, x_max)) +
  facet_wrap(~ treatment_fct, nrow = 1) +
  labs(
    title    = "Gamma Interaction: Scenario-Level Bias by Treatment",
    subtitle = "Red points indicate |bias| > 0.04",
    x        = "Bias",
    y        = "Scenario"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    panel.grid.major.y  = element_blank(),
    panel.grid.minor    = element_blank(),
    axis.text.y         = element_text(size = 7),
    strip.text          = element_text(face = "bold", size = 9),
    legend.position     = "bottom",
    plot.title          = element_text(face = "bold"),
    plot.title.position = "plot"
  )

plot_bias_facet

ggsave(here::here(paste0("figures/gamma_bias_lollipop_facet_", dt, ".png")),
       plot_bias_facet, width = 16, height = 8, dpi = 300)
```


```{r lolli3}
# --- Step 0: rebuild scenario_short as single-line FIRST ---
prep_plot_bias_over_under <- prep_plot_bias_over_under |>
  mutate(
    scenario_short = glue::glue("p={prop_extreme} n={nobs} m={magnitude_level}")
  )

# --- Step 1: order scenarios by frequency of |bias| > 0.02 across all treatments ---
scenario_order <- prep_plot_bias_over_under |>
  group_by(scenario_short) |>
  summarise(n_large_bias = sum(abs(bias) > 0.02, na.rm = TRUE), .groups = "drop") |>
  arrange(desc(n_large_bias)) |>
  pull(scenario_short)

# --- Step 2: order treatments by frequency of |bias| > 0.04 (worst to best) ---
treatment_order <- prep_plot_bias_over_under |>
  group_by(treatment_fct) |>
  summarise(n_large_bias = sum(abs(bias) > 0.04, na.rm = TRUE), .groups = "drop") |>
  arrange(desc(n_large_bias)) |>
  pull(treatment_fct)

# --- Step 3: apply ordering and bias tiers ---
prep_plot_bias_ordered <- prep_plot_bias_over_under |>
  mutate(
    scenario_short = factor(scenario_short, levels = scenario_order),
    treatment_fct  = factor(treatment_fct,  levels = treatment_order),
    bias_tier = case_when(
      abs(bias) > 0.05 ~ ">|0.05|",
      abs(bias) > 0.04 ~ ">|0.04|",
      TRUE             ~ "≤|0.04|"
    ),
    bias_tier = factor(bias_tier, levels = c("≤|0.04|", ">|0.04|", ">|0.05|"))
  )

# --- Step 4: plot ---
plot_bias_facet4 <- prep_plot_bias_ordered |>
  ggplot(aes(x = scenario_short, y = bias)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey30", linewidth = 0.4) +
  geom_segment(
    aes(x = scenario_short, xend = scenario_short, y = 0, yend = bias),
    linewidth = 0.5, color = "grey60"
  ) +
  geom_point(
    aes(color = bias_tier),
    size = 2
  ) +
  scale_color_manual(
    name   = "|Bias| threshold",
    values = c(
      "≤|0.04|" = "steelblue",
      ">|0.04|" = "orange",
      ">|0.05|" = "red"
    )
  ) +
  scale_y_continuous(limits = c(x_min, x_max)) +
  facet_wrap(
    ~ treatment_fct, nrow = 2,
    labeller = labeller(treatment_fct = label_wrap_gen(width = 15))
  ) +
  labs(
    title    = "Gamma Interaction: Scenario-Level Bias by Treatment",
    subtitle = "Scenarios ordered by frequency of |bias| > 0.02; treatments ordered worst to best (left to right, top to bottom)",
    x        = NULL,
    y        = "Bias"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    panel.grid.major.x  = element_blank(),
    panel.grid.minor    = element_blank(),
    axis.text.x         = element_text(angle = 90, hjust = 1, size = 7),
    strip.text          = element_text(face = "bold", size = 9),
    legend.position     = "bottom",
    plot.title          = element_text(face = "bold"),
    plot.title.position = "plot"
  )

plot_bias_facet4

ggsave(here::here(paste0("figures/gamma_bias_lollipop_facet4_", dt, ".png")),
       plot_bias_facet4, width = 14, height = 9, dpi = 300)
```

```{r plots_dir}
# did from all_df_gamma and summ_gamma and got exact same plot
prep_plot_bias_lollipop <- all_df_gamma %>%
  group_by(treatment_fct) %>%
  summarise(
    mean_of_means = mean(bias, na.rm = TRUE),
    sd_of_means   = sd(bias, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    sign = ifelse(
      mean_of_means < 0, "Underestimation (−)", "Overestimation (+)")) 

plot_bias_lollipop <- prep_plot_bias_lollipop |> 
  ggplot(aes(x = treatment_fct, y = mean_of_means, color = sign)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_segment(
    aes(xend = treatment_fct, y = 0, yend = mean_of_means), linewidth = 1.2) +
  geom_point(size = 3) +
  scale_color_manual(values = c("Underestimation (−)" = "#C7372F", "Overestimation (+)" = "#2B6CB0")) +
  scale_x_discrete(labels = scales::label_wrap(15))+
  labs(
    title = "Gamma Interaction: Average Scenario-Mean Bias by Treatment",
    subtitle = "Positive = overestimation; Negative = underestimation",
    x = NULL, y = "Average of scenario means (bias)"
  ) +
  theme_minimal() +
  theme(legend.position = "top",
        axis.text.x = element_text(size=9, lineheight=0.9))

plot_bias_lollipop
ggsave(here::here(paste0("figures/gamma_bias_lollipop_", dt, ".png")),
       plot_bias_lollipop, width = 8, height = 5, dpi = 300)
```  


### Jitter plot for how bias changes across conditions  

```{r bias_jitter}
# --- Trend lines including n as a scenario condition ---
# Treat magnitude level as numeric for trend fitting

plot_trends <- ggplot(
  summ_gamma,
  aes(
    x = magnitude_fct,
    y = bias,
    color = treatment_fct
  )
) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_jitter(
    width = 0.2,  
    height = 0,
    size = 3,
    alpha = 0.7
  ) +
  facet_grid(nobs_fct ~ prop_extreme_fct, 
             labeller = labeller(
               nobs_fct = function(x) paste0("N=",x),
               prop_extreme_fct = function(x) paste0(
                 "Prop. Extreme=",x)
               )
             ) +
  scale_color_manual( 
    name = "Data Treatment", 
    values = c(
      "No treatment" = "#0072B2",
      "Top-coding" = "#E69F00",
      "Mean-preserved top-coding" = "#009E73",
      "Median-preserved top-coding" = "#CC79A7",
      "Truncation" = "#D55E00" ) ) +
  labs(
    title = "Gamma Interaction: Scenario-Level Bias Across Magnitude of Extremes",
    subtitle = "Rows = N; Cols = proportion extreme; points show scenario-level bias",
    x = "Magnitude level",
    y = "Bias"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom",
        legend.title = element_text(face = "bold"))

plot_trends
ggsave(here::here(paste0("figures/gamma_bias_trends_", dt, ".png")),
       plot_trends, width = 11, height = 7, dpi = 300)


```

## RQ2: Empirical SE  

```{r}
# ============================================================
# compute_ESE_metrics: flexible grouping, always from all_df_gamma
# ============================================================
compute_ESE_metrics <- function(
    group_vars = c(
      "treatment_fct", "nobs_fct", "prop_extreme_fct", "magnitude_fct")) {
  all_df_gamma |>
    group_by(across(all_of(group_vars))) |>
    summarise(
      n_reps            = n(),
      # Core ESE
      ese               = sd(est, na.rm = TRUE),
      mcse_ese          = sd(est, na.rm = TRUE) / sqrt(n()),
      # Model SE summaries
      se_model_mean     = mean(se, na.rm = TRUE),
      se_model_median   = median(se, na.rm = TRUE),
      # Morris (2019) calibration
      ratio_modse_emp   = se_model_mean / ese,
      rel_error_modse   = 100 * (se_model_mean / ese - 1),
      rmse_se           = sqrt(mean((se - ese)^2, na.rm = TRUE)),
      # Rep-level SE calibration flag
      prop_under_se     = mean(se < ese, na.rm = TRUE),
      under_majority_se = prop_under_se > 0.5,
      # RMSE of estimator
      rmse              = sqrt(mean((est - true)^2, na.rm = TRUE)),
      .groups = "drop"
    )
}

# ============================================================
# Three direct calls on all_df_gamma
# ============================================================

# 1 row: overall
ese_overall      <- compute_ESE_metrics(group_vars = character(0))

# 5 rows: one ESE per treatment, computed from ~13,500 reps each
ese_by_treatment <- compute_ESE_metrics(group_vars = "treatment_fct")

# 135 rows: one ESE per treatment*scenario cell, computed from ~500 reps each
ese_full         <- compute_ESE_metrics(
  group_vars = c("treatment_fct", "nobs_fct","prop_extreme_fct", "magnitude_fct"))

# ============================================================
# Descriptives of the 27 scenario-level ESEs per treatment
# Requires ese_full because you need 27 ESE values per treatment to summarise
# This is a SEPARATE question from ese_by_treatment above
# ============================================================
ese_by_treatment_scen_descr <- ese_full |>
  group_by(treatment_fct) |>
  summarise(
    n_scen                   = n(),
    # ESE descriptives across 27 scenarios
    mean_ese                 = mean(ese, na.rm = TRUE),
    sd_ese                   = sd(ese, na.rm = TRUE),
    median_ese               = median(ese, na.rm = TRUE),
    mad_ese                  = mad(ese, na.rm = TRUE),
    min_ese                  = min(ese, na.rm = TRUE),
    max_ese                  = max(ese, na.rm = TRUE),
    # Morris calibration descriptives across 27 scenarios
    mean_ratio_modse_emp     = mean(ratio_modse_emp, na.rm = TRUE),
    mean_rel_error_modse     = mean(rel_error_modse, na.rm = TRUE),
    sd_rel_error_modse       = sd(rel_error_modse, na.rm = TRUE),
    mean_rmse_se             = mean(rmse_se, na.rm = TRUE),
    # Scenario-level underestimation counts
    n_scen_underest          = sum(ratio_modse_emp < 1, na.rm = TRUE),
    prop_scen_underest       = mean(ratio_modse_emp < 1, na.rm = TRUE),
    n_scen_under_majority    = sum(under_majority_se, na.rm = TRUE),
    prop_scen_under_majority = mean(under_majority_se, na.rm = TRUE),
    # RMSE descriptives
    mean_rmse                = mean(rmse, na.rm = TRUE),
    sd_rmse                  = sd(rmse, na.rm = TRUE),
    .groups = "drop"
  )

# ============================================================
# Save all
# ============================================================
fn_save_results(ese_overall)
fn_save_results(ese_by_treatment)
fn_save_results(ese_full)
fn_save_results(ese_by_treatment_scen_descr)

```



```{r descr_empse}

compute_ESE_metrics <- function(df, group_vars = c("treatment_fct","nobs_fct","prop_extreme_fct","magnitude_fct")) {
  
  df |>
    group_by(across(all_of(group_vars))) |>
    summarise(

      # --- Core ESE (one value per scenario-treatment cell) ---
      ese             = sd(est, na.rm = TRUE),
      mcse_ese        = sd(est, na.rm = TRUE) / sqrt(n()),  # MC uncertainty of ESE itself

      # --- Model SE summaries (averaged across reps in cell) ---
      se_model_mean   = mean(se, na.rm = TRUE),
      se_model_median = median(se, na.rm = TRUE),

      # --- Morris (2019) calibration metrics ---
      ratio_modse_emp  = se_model_mean / ese,   # <1 = underest; >1 = overest
      rel_error_modse  = 100 * (se_model_mean / ese - 1),   
       
      rmse_se          = sqrt(mean((se - ese)^2, na.rm = TRUE)),

      # --- Replicate-level SE calibration flag ---
      prop_under_se     = mean(se < ese, na.rm = TRUE),    
        
      under_majority_se = prop_under_se > 0.5,

      # --- Descriptives of the ESTIMATE distribution (not ESE) ---
      # Renamed clearly so they're not confused with ESE summaries
      est_mean   = mean(est, na.rm = TRUE),
      est_median = median(est, na.rm = TRUE),
      est_sd     = sd(est, na.rm = TRUE),       # same as ese, kept for clarity
      est_mad    = mad(est, na.rm = TRUE),
      est_min    = min(est, na.rm = TRUE),
      est_max    = max(est, na.rm = TRUE),

      .groups = "drop"
    )
}

# Overall
ese_results <- compute_ESE_metrics(all_df_gamma, group_vars = character(0))
fn_save_results(ese_results)

# ---- ese_by_treatment: ----
ese_by_treatment <- 
  group_by(treatment_fct) |>
  summarise(
    n_scen = n(),   # should be 27 for each treatment

    # --- ESE summaries across 27 scenarios ---
    mean_ese   = mean(ese),
    median_ese = median(ese),
    sd_ese     = sd(ese),
    mad_ese    = mad(ese),
    min_ese    = min(ese),
    max_ese    = max(ese),
    
     # RMSE of model SE (avgd across 27 scenarios)
    mean_rmse_se = mean(rmse_se, na.rm = TRUE),
    sd_rmse_se   = sd(rmse_se, na.rm = TRUE),
    min_rmse_se  = min(rmse_se, na.rm = TRUE),
    max_rmse_se  = max(rmse_se, na.rm = TRUE),

    # --- Morris calibration metrics across 27 scenarios ---
    
    mean_ratio_modse_emp = mean(ratio_modse_emp),
    # ratio: avg ModSE/EmpSE; close to 1 = well calibrated
    # ratio: avg ModSE/EmpSE; <1 = underest → undercoverage
      # if close to 1.0 across treatments, model SEs are well-calibrated. Values below 1 mean model is underestimating variability > CIs too narrow > undercoverage (links to RQ3)
    
    mean_rel_error_modse = mean(rel_error_modse),
    # % avg error: negative = model underestimates SE → CIs too narrow → undercoverage (RQ3 link)
    # % by which model SE misses EmpSE on average: e.g. 5% means model SE is 5% too small on average. Neg values directly explain undercoverage in RQ3
    
    sd_rel_error_modse   = sd(rel_error_modse),   
    # consistency of miscalibration
    
    n_scen_underest      = sum(ratio_modse_emp < 1),
    # how many of 27 scenarios have ModSE < ESE (underestimation)
    prop_scen_underest   = mean(ratio_modse_emp < 1),

    # --- Majority-underestimation flag ---
    # "in how many scenarios did the model underestimate SE in >50% of reps?"
    n_scen_under_majority  = sum(under_majority_se),
    prop_scen_under_majority = mean(under_majority_se),

    .groups = "drop"
  )

fn_save_results(ese_by_treatment)

```    

```{r ese_plots}
# --- Step 0: build scenario_short ---
prep_plot_ese <- ese_results |>
  mutate(
    scenario_short = glue::glue("p={prop_extreme_fct} n={nobs_fct} m={magnitude_fct}")
  )

# --- Step 1: order scenarios by frequency of ESE > 0.25 across all treatments ---
scenario_order_ese <- prep_plot_ese |>
  group_by(scenario_short) |>
  summarise(n_large_ese = sum(ese > 0.25, na.rm = TRUE), .groups = "drop") |>
  arrange(desc(n_large_ese)) |>
  pull(scenario_short)

# --- Step 2: order treatments by frequency of ESE > 0.25 (worst to best) ---
treatment_order_ese <- prep_plot_ese |>
  group_by(treatment_fct) |>
  summarise(n_large_ese = sum(ese > 0.25, na.rm = TRUE), .groups = "drop") |>
  arrange(desc(n_large_ese)) |>
  pull(treatment_fct)

# --- Step 3: apply ordering and ESE tiers ---
prep_plot_ese_ordered <- prep_plot_ese |>
  mutate(
    scenario_short = factor(scenario_short, levels = scenario_order_ese),
    treatment_fct  = factor(treatment_fct,  levels = treatment_order_ese),
    ese_tier = case_when(
      ese > 0.50 ~ ">0.50",
      ese > 0.25 ~ ">0.25",
      TRUE       ~ "≤0.25"
    ),
    ese_tier = factor(ese_tier, levels = c("≤0.25", ">0.25", ">0.50"))
  )

ese_y_min <- min(prep_plot_ese_ordered$ese, na.rm = TRUE)
ese_y_max <- max(prep_plot_ese_ordered$ese, na.rm = TRUE)

# --- Step 4: plot ---
plot_ese_facet <- prep_plot_ese_ordered |>
  ggplot(aes(x = scenario_short, y = ese)) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey30", linewidth = 0.4) +
  geom_segment(
    aes(x = scenario_short, xend = scenario_short, y = 0, yend = ese),
    linewidth = 0.5, color = "grey60"
  ) +
  geom_point(
    aes(color = ese_tier),
    size = 2
  ) +
  scale_color_manual(
    name   = "ESE threshold",
    values = c(
      "≤0.25" = "steelblue",
      ">0.25" = "orange",
      ">0.50" = "red"
    )
  ) +
  scale_y_continuous(limits = c(ese_y_min, ese_y_max)) +
  facet_wrap(
    ~ treatment_fct, nrow = 2,
    labeller = labeller(treatment_fct = label_wrap_gen(width = 15))
  ) +
  labs(
    title    = "Gamma Interaction: Scenario-Level Empirical SE by Treatment",
    subtitle = "Scenarios ordered by frequency of ESE > 0.25; treatments ordered worst to best (left to right, top to bottom)",
    x        = NULL,
    y        = "Empirical SE"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    panel.grid.major.x  = element_blank(),
    panel.grid.minor    = element_blank(),
    axis.text.x         = element_text(angle = 90, hjust = 1, size = 7),
    strip.text          = element_text(face = "bold", size = 9),
    legend.position     = "bottom",
    plot.title          = element_text(face = "bold"),
    plot.title.position = "plot"
  )

plot_ese_facet
ggsave(here::here(paste0("figures/gamma_ese_lollipop_facet_", dt, ".png")),
       plot_ese_facet, width = 16, height = 8, dpi = 300)

```  


```{r cov_tables}
# Overall (N = 67,371 reps)
tab_cov_overall <- all_df_gamma |>
  summarise(
    n_reps      = n(),
    mean_cov    = mean(cover_ind, na.rm = TRUE),
    n_covered   = sum(cover_ind == 1, na.rm = TRUE),
    n_uncovered = sum(cover_ind == 0, na.rm = TRUE)
  )

# By treatment, rep-level (N ~13,500 per treatment)
# This tells you: of all reps under this treatment, what fraction covered?
tab_cov_by_treatment_reps <- all_df_gamma |>
  group_by(treatment_fct) |>
  summarise(
    n_reps      = n(),
    mean_cov    = mean(cover_ind, na.rm = TRUE),
    n_covered   = sum(cover_ind == 1, na.rm = TRUE),
    n_uncovered = sum(cover_ind == 0, na.rm = TRUE),
    .groups = "drop"
  )

# Collapse to scenario-level rates (N = 135)
# Do this once and reuse below
cov_by_scenario <- all_df_gamma |>
  group_by(treatment_fct, nobs_fct, prop_extreme_fct, magnitude_fct) |>
  summarise(
    n_reps   = n(),
    coverage = mean(cover_ind, na.rm = TRUE),
    .groups  = "drop"
  )

# All 135 scenarios with pass/fail flag
tab_cov_scenarios <- cov_by_scenario |>
  mutate(
    meets_95 = coverage >= 0.95
  )

# Summarise scenarios by treatment (N = 5, each summarising 27 scenarios)
# This tells you: across the 27 scenarios for this treatment, how did coverage rates behave?
tab_cov_by_treatment_scen <- cov_by_scenario |>
  group_by(treatment_fct) |>
  summarise(
    n_scenarios  = n(),
    mean_cov     = mean(coverage),
    sd_cov       = sd(coverage),
    median_cov   = median(coverage),
    min_cov      = min(coverage),
    max_cov      = max(coverage),
    n_pass       = sum(coverage >= 0.95),
    n_fail       = sum(coverage < 0.95),
    prop_pass    = mean(coverage >= 0.95),
    prop_fail    = mean(coverage < 0.95),
    .groups = "drop"
  )

fn_save_results(tab_cov_overall)
fn_save_results(tab_cov_by_treatment_reps)
fn_save_results(cov_by_scenario)
fn_save_results(tab_cov_scenarios)
fn_save_results(tab_cov_by_treatment_scen)
```  

```{r cov_scen_freqs}
janitor::tabyl(tab_cov_scenario$meets_95)
 # tab_cov_scenario$meets_95  n   percent
 #                     FALSE 91 0.6740741
 #                      TRUE 44 0.3259259

janitor::tabyl(tab_cov_scenario, treatment_fct, meets_95) |> 
  janitor::adorn_percentages() |> 
  janitor::adorn_pct_formatting() |> 
  janitor::adorn_ns()

 #       treatment_fct      FALSE       TRUE
 #                No treatment 77.8% (21) 22.2%  (6)
 #                  Top-coding 59.3% (16) 40.7% (11)
 #   Mean-preserved top-coding 63.0% (17) 37.0% (10)
 # Median-preserved top-coding 63.0% (17) 37.0% (10)
 #                  Truncation 74.1% (20) 25.9%  (7)
```




```{r cov_lolli_plot}
# Step 1: Build scenario label
prep_plot_cov <- cov_by_scenario |>
  mutate(
    scenario_short = glue::glue("p={prop_extreme_fct} n={nobs_fct} m={magnitude_fct}")
  )

# Step 2: Order scenarios by mean coverage across treatments (worst to best)
scenario_order_cov <- prep_plot_cov |>
  group_by(scenario_short) |>
  summarise(mean_cov = mean(coverage, na.rm = TRUE), .groups = "drop") |>
  arrange(mean_cov) |>
  pull(scenario_short)

# Step 3: Order treatments by number of scenarios below 0.95 (worst to best left to right)
treatment_order_cov <- tab_cov_by_treatment_scen |>
  arrange(desc(n_fail)) |>
  pull(treatment_fct)

# Step 4: Apply ordering and flag
prep_plot_cov_ordered <- prep_plot_cov |>
  mutate(
    scenario_short = factor(scenario_short, levels = scenario_order_cov),
    treatment_fct  = factor(treatment_fct,  levels = treatment_order_cov),
    cov_flag       = if_else(coverage < 0.95, "Below 95%", "At/Above 95%"),
    cov_flag       = factor(cov_flag, levels = c("At/Above 95%", "Below 95%"))
  )

# Step 5: Plot
y_lower <- min(0.85, min(prep_plot_cov_ordered$coverage, na.rm = TRUE) - 0.01)

plot_cov_facet <- prep_plot_cov_ordered |>
  ggplot(aes(x = scenario_short, y = coverage)) +
  geom_hline(
    yintercept = 0.95, linetype = "dashed",
    color = "grey30", linewidth = 0.5
  ) +
  geom_segment(
    aes(
      x = scenario_short, xend = scenario_short,
      y = 0.95, yend = coverage,
      color = cov_flag
    ),
    linewidth = 0.5
  ) +
  geom_point(aes(color = cov_flag), size = 2) +
  scale_color_manual(
    name   = "Coverage status",
    values = c("At/Above 95%" = "#2ca02c", "Below 95%" = "#d62728")
  ) +
  scale_y_continuous(
    limits = c(y_lower, 1.0),
    labels = scales::percent_format(accuracy = 1),
    breaks = seq(0.85, 1.0, by = 0.05)
  ) +
  facet_wrap(
    ~ treatment_fct, nrow = 2,
    labeller = labeller(treatment_fct = label_wrap_gen(width = 15))
  ) +
  labs(
    title    = "Gamma Interaction: CI Coverage by Treatment and Scenario",
    subtitle = "Dashed line = nominal 95%; scenarios ordered worst to best; treatments ordered worst to best left to right",
    x        = NULL,
    y        = "Coverage"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    panel.grid.major.x  = element_blank(),
    panel.grid.minor    = element_blank(),
    axis.text.x         = element_text(angle = 90, hjust = 1, size = 7),
    strip.text          = element_text(face = "bold", size = 9),
    legend.position     = "bottom",
    plot.title          = element_text(face = "bold"),
    plot.title.position = "plot"
  )

plot_cov_facet

ggsave(
  here::here(paste0("figures/gamma_coverage_lollipop_facet_", dt, ".png")),
  plot_cov_facet, width = 16, height = 8, dpi = 300
)
```




2C. Coverage heatmap vs nominal 0.95  
```{r plot_cov_heat}
# get actual range to set tight limits
cov_min <- floor(min(tab_cov_scenario$coverage, na.rm = TRUE) * 100) / 100
cov_max <- ceiling(max(tab_cov_scenario$coverage, na.rm = TRUE) * 100) / 100

plot_cov_heat2 <- tab_cov_scenario %>%
  dplyr::mutate(
    cell = glue::glue("p={prop_extreme_fct}  mag={magnitude_fct}  n={nobs_fct}"),
    # label: percent format, flag below-95 with asterisk
    cov_label = paste0(
      scales::number(coverage * 100, accuracy = 0.1), "%",
      ifelse(coverage < 0.95, "*", "")
    )
  ) %>%
  ggplot(aes(x = treatment_fct, y = cell, fill = coverage)) +
  geom_tile(color = "white", linewidth = 0.8) +
  geom_text(
    aes(
      label = cov_label,
      color = ifelse(coverage < 0.92 | coverage > 0.98, "light", "dark")
    ),
    size = 2.8
  ) +
  scale_color_manual(
    values = c("light" = "grey20", "dark" = "grey20"),
    guide  = "none"
  ) +
  scale_fill_gradient2(
    low      = "#C7372F",
    mid      = "white",
    high     = "#2ca02c",
    midpoint = 0.95,
    limits   = c(cov_min, cov_max),   # tight limits = full color range used
    labels   = scales::percent_format(accuracy = 1)
  ) +
  scale_x_discrete(labels = label_wrap_gen(width = 12)) +
  labs(
    title    = "Gamma Interaction: Coverage by Treatment and Scenario",
    subtitle = "Green ≥ 95% (nominal); red = undercoverage; * = below 95%; values are coverage rates",
    x        = NULL,
    y        = "Scenario",
    fill     = "Coverage"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    axis.text.x         = element_text(angle = 30, hjust = 1, size = 9),
    axis.text.y         = element_text(size = 8),
    panel.grid          = element_blank(),
    plot.title          = element_text(face = "bold"),
    plot.title.position = "plot",
    legend.position     = "right"
  )

plot_cov_heat2
ggsave(here::here(paste0("figures/gamma_coverage_heat2_", dt, ".png")),
       plot_cov_heat2, width = 13, height = 10, dpi = 300)
```   



3. Auto-generate sentences  
Summarize direction, magnitude, reliability per treatment using tables above  
```{r sentences, eval=FALSE}
sentences <- tab_consistency %>%
  mutate(
    dir = ifelse(as.numeric(avg_mean_bias) < 0, "underestimated", "overestimated"),
    abs_avg = abs(as.numeric(avg_mean_bias)),
    txt = glue::glue(
      "On average across {n_scen} scenarios, the {treatment} method {dir} ",
      "the Gamma interaction by {scales::number(abs_avg, accuracy = 0.0001)}. ",
      "Median scenario-mean bias was {med_mean_bias}. ",
      "{scales::percent(share_scen_under, accuracy = 0.1)} of scenarios had negative mean bias, ",
      "and {scales::percent(share_scen_under_majority, accuracy = 0.1)} showed majority underestimation. ",
      "Mean empirical SE was {mean_emp_se}, and mean coverage was {scales::percent(mean_cov, accuracy = 0.1)}."
    )
  ) %>%
  dplyr::pull(txt)

cat(paste0("- ", sentences, collapse = "\n"))
```   

## ATT descr  
```{r fn_att_descr}


# ---- ATT descriptives by treatment: estimates and bias ----

# Helper for clean number formatting
fmt <- function(x) scales::number(x, accuracy = 0.01, big.mark = ",")
fmt_pct <- function(x) scales::percent(x, accuracy = 0.1)


# Overall 
# --- Table 0: mean_est overall ------------------
att_est_overall <- all_df_att |>
  summarise(
    n_scen        = n(),
    est_mean   = mean(est, na.rm = TRUE),
    est_sd     = sd(est, na.rm = TRUE),
    est_median = median(est, na.rm = TRUE),
    est_mad    = mad(est, na.rm = TRUE),
    est_min    = min(est, na.rm = TRUE),
    est_max    = max(est, na.rm = TRUE),
    mean_true       = mean(true, na.rm = TRUE),  # should be ~158 for all
    .groups = "drop"
  )
fn_save_results(att_est_overall)

# --- Table 1: mean_est descriptives by treatment ---
att_est_by_treatment <- all_df_att |>
  group_by(treatment_fct) |>
  summarise(
    n_scen        = n(),
    est_mean   = mean(est, na.rm = TRUE),
    est_sd     = sd(est, na.rm = TRUE),
    est_median = median(est, na.rm = TRUE),
    est_mad    = mad(est, na.rm = TRUE),
    est_min    = min(est, na.rm = TRUE),
    est_max    = max(est, na.rm = TRUE),
    mean_true       = mean(true, na.rm = TRUE),  # should be ~158 for all
    .groups = "drop"
  )
fn_save_results(att_est_by_treatment)

# --- Table 1: mean_est descriptives by scenario ---
att_est_by_scenario <- all_df_att |>
  group_by(treatment_fct, nobs_fct, prop_extreme_fct, magnitude_fct) |>
  summarise(
    n_scen        = n(),
    est_mean   = mean(est, na.rm = TRUE),
    est_sd     = sd(est, na.rm = TRUE),
    est_median = median(est, na.rm = TRUE),
    est_mad    = mad(est, na.rm = TRUE),
    est_min    = min(est, na.rm = TRUE),
    est_max    = max(est, na.rm = TRUE),
    mean_true       = mean(true, na.rm = TRUE),  # should be ~158 for all
    .groups = "drop"
  )
fn_save_results(att_est_by_scenario)


# --- Table 2a: ATT bias overall descriptives --- 
att_bias_overall <- all_df_att |>
  summarise(
    n_scen          = n(),
    mean_bias       = mean(bias, na.rm = TRUE),
    sd_bias         = sd(bias, na.rm = TRUE),
    median_bias     = median(bias, na.rm = TRUE),
    mad_bias        = mad(bias, na.rm = TRUE),
    min_bias        = min(bias, na.rm = TRUE),
    max_bias        = max(bias, na.rm = TRUE),
    mean_abs_bias   = mean(abs_bias, na.rm = TRUE),
    median_abs_bias = median(abs_bias, na.rm = TRUE),
    n_neg_bias      = sum(bias < 0),
    prop_neg_bias   = mean(bias < 0)
  )

fn_save_results(att_bias_overall)

# --- Table 2: bias descriptives by treatment ---
att_bias_by_treatment <- all_df_att |>
  group_by(treatment_fct) |>
  summarise(
    n_scen          = n(),
    mean_bias       = mean(bias, na.rm = TRUE),
    sd_bias         = sd(bias, na.rm = TRUE),
    median_bias     = median(bias, na.rm = TRUE),
    mad_bias        = mad(bias, na.rm = TRUE),
    min_bias        = min(bias, na.rm = TRUE),
    max_bias        = max(bias, na.rm = TRUE),
    mean_abs_bias   = mean(abs_bias, na.rm = TRUE),
    median_abs_bias = median(abs_bias, na.rm = TRUE),
    n_neg_bias      = sum(bias < 0),
    prop_neg_bias   = mean(bias < 0),
    .groups = "drop"
  )

fn_save_results(att_bias_by_treatment)

att_bias_by_scenario <- all_df_att |>
  group_by(treatment_fct, nobs_fct, prop_extreme_fct, magnitude_fct) |>
  summarise(
    n_scen          = n(),
    mean_bias       = mean(bias, na.rm = TRUE),
    sd_bias         = sd(bias, na.rm = TRUE),
    median_bias     = median(bias, na.rm = TRUE),
    mad_bias        = mad(bias, na.rm = TRUE),
    min_bias        = min(bias, na.rm = TRUE),
    max_bias        = max(bias, na.rm = TRUE),
    mean_abs_bias   = mean(abs_bias, na.rm = TRUE),
    median_abs_bias = median(abs_bias, na.rm = TRUE),
    n_neg_bias      = sum(bias < 0),
    prop_neg_bias   = mean(bias < 0),
    .groups = "drop"
  )

fn_save_results(att_bias_by_scenario)

```  

```{r plot_att_est_bias}
# ================================================================
# ATT ESTIMATE: trends plot
# ================================================================
summ_att <- summ_grid |> 
  filter(model=="ATT") |> 
  select(-c(mean_model_se, rmse, coverage))

plot_att_est_trends <- ggplot(
  summ_att,
  aes(
    x     = magnitude_fct,
    y     = mean_est,
    color = treatment_fct
  )
) +
  geom_hline(
    aes(yintercept = mean_true),
    linetype = "dashed", color = "grey30", linewidth = 0.4
  ) +
  geom_jitter(
    width = 0.2,
    height = 0,
    size = 3,
    alpha = 0.7
  ) +
  facet_grid(
    nobs_fct ~ prop_extreme_fct,
    labeller = labeller(
      nobs_fct         = function(x) paste0("N = ", x),
      prop_extreme_fct = function(x) paste0("Prop. Extreme = ", x)
    )
  ) +
  scale_color_manual(
    name   = "Data Treatment",
    values = c(
      "No treatment"                = "#0072B2",
      "Top-coding"                  = "#E69F00",
      "Mean-preserved top-coding"   = "#009E73",
      "Median-preserved top-coding" = "#CC79A7",
      "Truncation"                  = "#D55E00"
    ),
    labels = label_wrap_gen(width = 20)   # wraps legend text
  ) +
  labs(
    title    = "ATT: Scenario-Level Estimates Across Magnitude of Extremes",
    subtitle = stringr::str_wrap(
      "Rows = N; Cols = proportion extreme; dashed line = zero bias; points show scenario-level bias",
      width = 90   # adjust to match your plot width
    ),
    x = "Magnitude level",
    y = "Bias (ATT scale)"
  ) +
  theme_minimal() +
  theme(
    legend.position  = "bottom",
    legend.title     = element_text(face = "bold"),
    plot.subtitle    = element_text(color = "grey40", size = 9)  # optional styling
  )

plot_att_est_trends
ggsave(here::here(paste0("figures/att_est_trends_", dt, ".png")),
       plot_att_est_trends, width = 11, height = 7, dpi = 300)


# ================================================================
# ATT BIAS: trends plot
# ================================================================

plot_att_bias_trends <- ggplot(
  summ_att,
  aes(
    x     = magnitude_fct,
    y     = bias,
    color = treatment_fct
  )
) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey30", linewidth = 0.4) +
  geom_jitter(
    width  = 0.2,
    height = 0,
    size   = 3,
    alpha  = 0.7
  ) +
  facet_grid(
    nobs_fct ~ prop_extreme_fct,
    labeller = labeller(
      nobs_fct         = function(x) paste0("N = ", x),
      prop_extreme_fct = function(x) paste0("Prop. Extreme = ", x)
    )
  ) +
  scale_color_manual(
    name   = "Data Treatment",
    values = c(
      "No treatment"                = "#0072B2",
      "Top-coding"                  = "#E69F00",
      "Mean-preserved top-coding"   = "#009E73",
      "Median-preserved top-coding" = "#CC79A7",
      "Truncation"                  = "#D55E00"
    ),
    labels = label_wrap_gen(width = 20)   # wraps legend text
  ) +
  labs(
    title    = "ATT: Scenario-Level Bias Across Magnitude of Extremes",
    subtitle = stringr::str_wrap(
      "Rows = N; Cols = proportion extreme; dashed line = zero bias; points show scenario-level bias",
      width = 90   # adjust to match your plot width
    ),
    x = "Magnitude level",
    y = "Bias (ATT scale)"
  ) +
  theme_minimal() +
  theme(
    legend.position  = "bottom",
    legend.title     = element_text(face = "bold"),
    plot.subtitle    = element_text(color = "grey40", size = 9)  # optional styling
  )

plot_att_bias_trends
ggsave(here::here(paste0("figures/att_bias_trends_", dt, ".png")),
       plot_att_bias_trends, width = 11, height = 7, dpi = 300)

```




##4 FULL-FACTORIAL ANOVA (RQ answers)



```{r aov_bias}
# Type III ANOVA with Eta² and Partial Eta² for Gamma Bias

# A) factorial ANOVA on gamma bias (at rep-level, per meeting with Tsai)
# Load required packages
pacman::p_load(car, effectsize, dplyr, tibble, knitr, kableExtra)

# Ensure factors are properly set

# Set contrasts for Type III SS (m!)
options(contrasts = c("contr.sum", "contr.poly"))


# 1: Fit the model

model <- aov(
  bias ~ treatment_fct * nobs_fct * prop_extreme_fct * magnitude_fct, 
  data = all_df_gamma)


# Step 2: Type III Sum of Squares ANOVA Table
type3_anova <- car::Anova(model, type = "III")


# 3: Comb. table ===================================================
# Type III SS + Effect Sizes

# Extract Type III results
type3_df <- type3_anova %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Term") %>%
  filter(Term != "Residuals")

eta2_regular <- effectsize::eta_squared(type3_anova, partial=FALSE)
eta2_partial <- effectsize::eta_squared(type3_anova, partial=TRUE)

# Extract regular eta²
eta2_reg_df <- eta2_regular %>%
  as.data.frame() %>%
  select(Parameter, Eta2)

# Extract partial eta²
eta2_part_df <- eta2_partial %>%
  as.data.frame() %>%
  select(Parameter, Eta2_partial)

# Tried both of these below, came out the same.
# eta2_lsr <- lsr::etaSquared(model, type=3)
# eta2_descTools <- DescTools::EtaSq(model, type=3)

# Combine everything - simplified version (point estimates only)
combined_table <- type3_df %>%
  left_join(eta2_reg_df, by = c("Term" = "Parameter")) %>%
  left_join(eta2_part_df, by = c("Term" = "Parameter")) %>%
  mutate(
    `Sum Sq` = round(`Sum Sq`, 6),
    `F value` = round(`F value`, 2),
    `Pr(>F)` = format.pval(`Pr(>F)`, digits = 3, eps = 0.001),
    Eta2 = round(Eta2, 5),
    Eta2_partial = round(Eta2_partial, 5),
    # Add interpretation column (handle NAs for intercept)
    Interpretation = case_when(
      is.na(Eta2_partial) ~ "N/A",           # Handle NAs first
      Eta2_partial < 0.01 ~ "Negligible",
      Eta2_partial < 0.06 ~ "Small",
      Eta2_partial < 0.14 ~ "Medium",
      TRUE ~ "Large"
    )
  ) %>%
  select(Term, Df, `Sum Sq`, `F value`, `Pr(>F)`, Eta2, Eta2_partial, Interpretation) %>%
  arrange(desc(`F value`))

print(combined_table)

# 4: Export ===================================================
write.csv(combined_table, 
          here::here(paste0("results/aov_bias_type3_", dt, ".csv")),
          row.names = FALSE)


# id sig, large es =========================================
# Identify Significant Effects and Large Effect Sizes

significant_effects <- combined_table %>%
  filter(Term != "(Intercept)") %>%  # Exclude intercept
  filter(`Pr(>F)` < 0.001 | `Pr(>F)` == "<.001") %>%
  arrange(desc(Eta2_partial))

cat("\n=== SIGNIFICANT EFFECTS (p < .001) ===\n")
print(significant_effects)

large_effects <- combined_table %>%
  filter(Term != "(Intercept)") %>%  # Exclude intercept
  filter(Eta2_partial >= 0.01) %>%  # At least "small" effects
  arrange(desc(Eta2_partial))

cat("\n=== SMALL OR LARGER EFFECT SIZES (η²p ≥ .01) ===\n")
print(large_effects)

# 8: Summary stats ===========================================

# Exclude intercept for summary
combined_no_int <- combined_table %>% filter(Term != "(Intercept)")

cat("\n=== SUMMARY ===\n")
cat("Total effects tested:", nrow(combined_no_int), "\n")
cat("Significant at p < .001:", 
    sum(grepl("<.001", combined_no_int$`Pr(>F)`)), "\n")
cat("Significant at p < .05:", 
    sum(as.numeric(gsub("<.001", "0", combined_no_int$`Pr(>F)`)) < 0.05, na.rm = TRUE), "\n")
cat("Small+ effect sizes (η²p ≥ .01):", 
    sum(combined_no_int$Eta2_partial >= 0.01, na.rm = TRUE), "\n")
cat("Largest partial eta²:", 
    round(max(combined_no_int$Eta2_partial, na.rm = TRUE), 5), 
    "for", combined_no_int$Term[which.max(combined_no_int$Eta2_partial)], "\n")

# Summary interpretation
cat("\n=== INTERPRETATION ===\n")
cat("Mean bias across all conditions:", round(mean(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("SD of bias:", round(sd(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("Range of bias:", round(range(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("\nAll effect sizes are negligible (< .01), indicating that treatment method,\n")
cat("sample size, proportion of extremes, and magnitude have minimal practical\n")
cat("impact on bias. The vast majority of variance in bias (>99%) is due to\n")
cat("random sampling variability, not systematic differences between conditions.\n")

# Opt: Post hocs ==============================================
# OPTIONAL: Post-hoc tests for significant main effects

# library(emmeans)
# 
# # Only run post-hoc if effect is significant AND at least small
# sig_main_effects <- significant_effects %>%
#   filter(!grepl(":", Term)) %>%  # Only main effects, not interactions
#   filter(Eta2_partial >= 0.001)  # At least 0.1% variance explained
# 
# if ("treatment" %in% sig_main_effects$Term) {
#   cat("\n=== POST-HOC: Pairwise Comparisons for Treatment ===\n")
#   emm_treatment <- emmeans(model, ~ treatment)
#   pairs_treatment <- pairs(emm_treatment, adjust = "tukey")
#   print(pairs_treatment)
#   
#   # Save post-hoc results
#   write.csv(as.data.frame(pairs_treatment),
#             file = paste0("results/posthoc_treatment_", dt, ".csv"),
#             row.names = FALSE)
# }
# 
# if ("prop_extreme" %in% sig_main_effects$Term) {
#   cat("\n=== POST-HOC: Pairwise Comparisons for Proportion Extreme ===\n")
#   emm_prop <- emmeans(model, ~ prop_extreme)
#   pairs_prop <- pairs(emm_prop, adjust = "tukey")
#   print(pairs_prop)
#   
#   write.csv(as.data.frame(pairs_prop),
#             file = paste0("results/posthoc_prop_extreme_", dt, ".csv"),
#             row.names = FALSE)
# }
# 
# if ("magnitude_level" %in% sig_main_effects$Term) {
#   cat("\n=== POST-HOC: Pairwise Comparisons for Magnitude Level ===\n")
#   emm_mag <- emmeans(model, ~ magnitude_level)
#   pairs_mag <- pairs(emm_mag, adjust = "tukey")
#   print(pairs_mag)
#   
#   write.csv(as.data.frame(pairs_mag),
#             file = paste0("results/posthoc_magnitude_", dt, ".csv"),
#             row.names = FALSE)
# }
# 
# # Opt: Check assumptions =====================================
# # OPTIONAL: Check ANOVA assumptions
# 
# cat("\n=== CHECKING ANOVA ASSUMPTIONS ===\n")
# 
# # 1. Normality of residuals (sample if too large)
# if (nrow(all_df_gamma) > 5000) {
#   shapiro_test <- shapiro.test(sample(residuals(model), 5000))
#   cat("Shapiro-Wilk test for normality (n=5000 sample): W =", 
#       round(shapiro_test$statistic, 4), 
#       ", p =", format.pval(shapiro_test$p.value), "\n")
# } else {
#   shapiro_test <- shapiro.test(residuals(model))
#   cat("Shapiro-Wilk test for normality: W =", 
#       round(shapiro_test$statistic, 4), 
#       ", p =", format.pval(shapiro_test$p.value), "\n")
# }
# 
# # 2. Homogeneity of variance (Levene's test)
# levene_test <- car::leveneTest(bias ~ treatment * n * prop_extreme * magnitude_level, 
#                                data = all_df_gamma)
# cat("Levene's test for homogeneity: F =", round(levene_test$`F value`[1], 4),
#     ", p =", format.pval(levene_test$`Pr(>F)`[1]), "\n")
# 
# # 3. Diagnostic plots
# png(paste0("figures/anova_diagnostics_", dt, ".png"), 
#     width = 10, height = 8, units = "in", res = 300)
# par(mfrow = c(2, 2))
# plot(model)
# dev.off()

# cat("Diagnostic plots saved to figures/anova_diagnostics_", dt, ".png\n")

# Plot significant interactions: 
# --- Shared theme and color scale for both plots ---
trt_colors <- c(
  "No treatment"                = "#0072B2",
  "Top-coding"                  = "#E69F00",
  "Mean-preserved top-coding"   = "#009E73",
  "Median-preserved top-coding" = "#CC79A7",
  "Truncation"                  = "#D55E00"
)

base_theme <- theme_minimal(base_size = 11) +
  theme(
    legend.position     = "bottom",
    legend.title        = element_text(face = "bold"),
    strip.text          = element_text(face = "bold"),
    plot.title          = element_text(face = "bold"),
    plot.title.position = "plot",
    plot.subtitle       = element_text(color = "grey40", size = 9),
    panel.grid.minor    = element_blank()
  )

# ---- Shared mean + SE summaries ----
means_trt_nobs <- all_df_gamma |>
  group_by(treatment_fct, nobs_fct) |>
  summarise(
    mean_bias = mean(bias, na.rm = TRUE),
    se_bias   = sd(bias, na.rm = TRUE) / sqrt(n()),
    .groups   = "drop"
  )

means_trt_prop <- all_df_gamma |>
  group_by(treatment_fct, prop_extreme_fct) |>
  summarise(
    mean_bias = mean(bias, na.rm = TRUE),
    se_bias   = sd(bias, na.rm = TRUE) / sqrt(n()),
    .groups   = "drop"
  )

# ================================================================
# MEANS-ONLY INTERACTION PLOTS
# ================================================================

# ---- Means-only: faceted by treatment ----

plot_means_trt_nobs_facet <- means_trt_nobs |>
  ggplot(aes(x = nobs_fct, y = mean_bias, group = 1)) +
  geom_hline(yintercept = 0, linetype = "dashed",
             color = "grey30", linewidth = 0.4) +
  geom_line(linewidth = 0.9, color = "steelblue") +
  geom_errorbar(
    aes(ymin = mean_bias - 1.96*se_bias,
        ymax = mean_bias + 1.96*se_bias),
    width = 0.15, linewidth = 0.6, color = "steelblue"
  ) +
  geom_point(size = 3.5, shape = 18, color = "steelblue") +
  facet_wrap(~ treatment_fct, nrow = 1,
             labeller = labeller(treatment_fct = label_wrap_gen(width = 15))) +
  labs(
    title    = "Gamma Interaction Bias: Treatment × Sample Size",
    subtitle = expression(paste(
      "Type III F(8) = 3.50, p < .001, ", eta[p]^2,
      " = .0004 (negligible). Means ± 95% CI.")),
    x = "Sample size (N obs)",
    y = "Mean bias"
  ) +
  base_theme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

plot_means_trt_prop_facet <- means_trt_prop |>
  ggplot(aes(x = prop_extreme_fct, y = mean_bias, group = 1)) +
  geom_hline(yintercept = 0, linetype = "dashed",
             color = "grey30", linewidth = 0.4) +
  geom_line(linewidth = 0.9, color = "steelblue") +
  geom_errorbar(
    aes(ymin = mean_bias - 1.96*se_bias,
        ymax = mean_bias + 1.96*se_bias),
    width = 0.15, linewidth = 0.6, color = "steelblue"
  ) +
  geom_point(size = 3.5, shape = 18, color = "steelblue") +
  facet_wrap(~ treatment_fct, nrow = 1,
             labeller = labeller(treatment_fct = label_wrap_gen(width = 15))) +
  labs(
    title    = "Gamma Interaction Bias: Treatment × Proportion Extreme",
    subtitle = expression(paste(
      "Type III F(8) = 22.52, p < .001, ", eta[p]^2,
      " = .0027 (negligible). Means ± 95% CI.")),
    x = "Proportion of extreme values",
    y = "Mean bias"
  ) +
  base_theme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

plot_means_trt_nobs_facet
plot_means_trt_prop_facet

ggsave(here::here(paste0("figures/anova_means_trt_nobs_facet_", dt, ".png")),
       plot_means_trt_nobs_facet, width = 13, height = 5, dpi = 300)
ggsave(here::here(paste0("figures/anova_means_trt_prop_facet_", dt, ".png")),
       plot_means_trt_prop_facet, width = 13, height = 5, dpi = 300)
```  



```{r bias_es}
# Plot partial eta² for significant effects
# plot pes ===================================================
# Step 9: Visualize Effect Sizes (CORRECTED)

library(ggplot2)

# Need to go back to BEFORE formatting p-values
plot_data <- type3_df %>%
  left_join(eta2_part_df, by = c("Term" = "Parameter")) %>%
  filter(Term != "(Intercept)") %>%
  filter(`Pr(>F)` < 0.05) %>%  # Use numeric p-values BEFORE formatting
  mutate(
    Term = reorder(Term, Eta2_partial),
    Significant = case_when(
      `Pr(>F)` < 0.001 ~ "p < .001",
      `Pr(>F)` < 0.01 ~ "p < .01",
      `Pr(>F)` < 0.05 ~ "p < .05",
      TRUE ~ "ns"
    )
  )

library(patchwork)  # For combining plots

# Zoomed-in version (what you have now)
p_zoomed <- ggplot(
  plot_data, aes(x = Eta2_partial, y = Term, fill = Significant)) +
  geom_col() +
  scale_fill_manual(
    values = c("p < .001" = "steelblue", 
               "p < .01" = "cornflowerblue",
               "p < .05" = "lightblue"),
    name = "Significance"
  ) +
  labs(
    title = "A) Zoomed View",
    x = "Partial η²",
    y = "Effect"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Full scale version (shows context)
p_full <- ggplot(
  plot_data, aes(x = Eta2_partial, y = Term, fill = Significant)) +
  geom_col() +
  geom_vline(
    xintercept = 0.01, linetype = "dashed", color = "red", alpha = 0.7) +
  geom_vline(
    xintercept = 0.06, linetype = "dashed", color = "orange", alpha = 0.7) +
  geom_vline(
    xintercept = 0.14, linetype = "dashed", color = "green", alpha = 0.7) +
  annotate(
    "text", x = 0.01, y = 6.5, label = "Small", size = 3, color = "red") +
  annotate(
    "text", x = 0.06, y = 6.5, label = "Med", size = 3, color = "orange") +
  annotate(
    "text", x = 0.14, y = 6.5, label = "Large", size = 3, color = "green") +
  scale_fill_manual(
    values = c("p < .001" = "steelblue", 
               "p < .01" = "cornflowerblue",
               "p < .05" = "lightblue"),
    name = "Significance"
  ) +
  scale_x_continuous(
    limits = c(0, 0.15),
    breaks = seq(0, 0.15, 0.03)
  ) +
  labs(
    title = "B) Full Scale (with benchmarks)",
    x = "Partial η²",
    y = NULL
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom",
    axis.text.y = element_blank()  # Remove duplicate y-axis labels
  )

# Combine side by side
p_combined <- p_zoomed + p_full +
  plot_annotation(
    title = "Partial Eta-Squared for Significant Effects: Gamma Model Bias",
    subtitle = "All effects are negligible - even the largest (0.0027) is far below the 'small' benchmark (0.01)",
    theme = theme(
      plot.title = element_text(face = "bold", size = 14),
      plot.subtitle = element_text(size = 11, color = "gray30")
    )
  )

print(p_combined)

ggsave(here::here(paste0("figures/effect_sizes_combined_", dt, ".png")),
       p_combined, width = 14, height = 6, dpi = 300)

ggsave(here::here(paste0("figures/effect_sizes_", dt, ".png")),
       p_effect_sizes, width = 10, height = 6, dpi = 300)


```    



```{r aov_att_absbias}
# D) Do anova on ATT absolute bias, not bias, at the replicate level.
# Type III ANOVA with Eta² and Partial Eta² for Gamma Bias

# A) factorial ANOVA on gamma bias (at rep-level, per meeting with Tsai)

# Set contrasts for Type III SS (m!)
all_df_att <- all_df_att |> 
  rename(c(
    "Treatment" = treatment_fct,
    "Proportion" = prop_extreme_fct,
    "Magnitude" = magnitude_fct,
    "N" = nobs_fct))
options(contrasts = c("contr.sum", "contr.poly"))

# 1: Fit the model

model_att <- aov(
  abs_bias ~ Treatment * N * Proportion * Magnitude, 
  data = all_df_att)


# Step 2: Type III Sum of Squares ANOVA Table
type3_anova_att <- car::Anova(model_att, type = "III")


# 3: Comb. table ===================================================
# Type III SS + Effect Sizes

# Extract Type III results
type3_df_att <- type3_anova_att %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Term") %>%
  filter(Term != "Residuals")

eta2_regular_att <- effectsize::eta_squared(type3_anova_att, partial=FALSE)
eta2_partial_att <- effectsize::eta_squared(type3_anova_att, partial=TRUE)

# Extract regular eta²
eta2_reg_df_att <- eta2_regular_att %>%
  as.data.frame() %>%
  select(Parameter, Eta2)

# Extract partial eta²
eta2_part_df_att <- eta2_partial_att %>%
  as.data.frame() %>%
  select(Parameter, Eta2_partial)

# Combine everything - simplified version (point estimates only)
options(scipen=999)
combined_table_att <- type3_df_att %>%
  left_join(eta2_reg_df_att, by = c("Term" = "Parameter")) %>%
  left_join(eta2_part_df_att, by = c("Term" = "Parameter")) %>%
  mutate(
    `Sum Sq` = round(`Sum Sq`, 6),
    `F value` = round(`F value`, 2),
    `Pr(>F)` = format.pval(`Pr(>F)`, digits = 3, eps = 0.001),
    Eta2 = round(Eta2, 5),
    Eta2_partial = round(Eta2_partial, 5),
    # Add interpretation column (handle NAs for intercept)
    Interp_pes = case_when(
      is.na(Eta2_partial) ~ "N/A",           # Handle NAs first
      Eta2_partial < 0.01 ~ "Negligible",
      Eta2_partial < 0.06 ~ "Small",
      Eta2_partial < 0.14 ~ "Medium",
      TRUE ~ "Large"
    ),
    Interp_es = case_when(
      is.na(Eta2) ~ "N/A",           # Handle NAs first
      Eta2 < 0.01 ~ "Negligible",
      Eta2 < 0.06 ~ "Small",
      Eta2 < 0.14 ~ "Medium",
      TRUE ~ "Large")
  ) %>%
  select(Term, Df, `Sum Sq`, `F value`, `Pr(>F)`, Eta2, Interp_es, Eta2_partial, Interp_pes)  %>%
  arrange(desc(`F value`))

print(combined_table_att)

# 4: Export ===================================================
# avoid .csv having scientific notation: 
combined_table_att_export <- combined_table_att |>
  mutate(
    `Sum Sq`     = formatC(`Sum Sq`,     format = "f", digits = 6, big.mark = ","),
    `F value`    = formatC(`F value`,    format = "f", digits = 2),
    Eta2         = formatC(Eta2,         format = "f", digits = 5),
    Eta2_partial = formatC(Eta2_partial, format = "f", digits = 5)
  )

write.csv(combined_table_att_export,
          here::here(paste0("results/aov_att_type3_", dt, ".csv")),
          row.names = FALSE)
```

```{r att_anova_plot}
# Build plot data from ATT ANOVA results
# Use the numeric versions of columns BEFORE any formatting

plot_data_att <- type3_df_att |>
  left_join(eta2_reg_df_att, by = c("Term" = "Parameter")) |>
  filter(Term != "(Intercept)") |>
  filter(`Pr(>F)` < 0.05) |>
  mutate(
    Term = reorder(Term, Eta2),
    Significant = case_when(
      `Pr(>F)` < 0.001 ~ "p < .001",
      `Pr(>F)` < 0.01  ~ "p < .01",
      `Pr(>F)` < 0.05  ~ "p < .05",
      TRUE             ~ "ns"
    )
  )

n_terms <- nrow(plot_data_att)

p_zoomed_att <- ggplot(
  plot_data_att, aes(x = Eta2, y = Term, fill = Significant)) +
  geom_col() +
  scale_fill_manual(
    values = c("p < .001" = "steelblue",
               "p < .01"  = "cornflowerblue",
               "p < .05"  = "lightblue"),
    name = "Significance"
  ) +
  scale_x_continuous(
    limits = c(0, 0.25),
    breaks = seq(0, 0.25, 0.05)
  ) +
  labs(
    title = "A) Zoomed View",
    x     = "η²",
    y     = "Effect"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

p_full_att <- ggplot(
  plot_data_att, aes(x = Eta2, y = Term, fill = Significant)) +
  geom_col() +
  geom_vline(xintercept = 0.01, linetype = "dashed", color = "red",     alpha = 0.7) +
  geom_vline(xintercept = 0.06, linetype = "dashed", color = "orange",  alpha = 0.7) +
  geom_vline(xintercept = 0.14, linetype = "dashed", color = "#1a7a1a", alpha = 0.7) +
  annotate("text", x = 0.01, y = 1, label = "Small", size = 3, color = "red",     hjust = -0.1, vjust = -0.3) +
  annotate("text", x = 0.06, y = 1, label = "Med",   size = 3, color = "orange",  hjust = -0.1, vjust = -0.3) +
  annotate("text", x = 0.14, y = 1, label = "Large", size = 3, color = "#1a7a1a", hjust = -0.1, vjust = -0.3) +
  scale_fill_manual(
    values = c("p < .001" = "steelblue",
               "p < .01"  = "cornflowerblue",
               "p < .05"  = "lightblue"),
    name = "Significance"
  ) +
  scale_x_continuous(
    limits = c(0, 0.25),
    breaks = seq(0, 0.25, 0.05)
  ) +
  labs(
    title    = "Eta-Squared for Significant Effects: ATT Absolute Bias",
    subtitle = "Treatment has the largest effect (η² = 0.222, Large); all effects significant at p < .001",
    x        = "η²",
    y        = "Effect"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom",
        plot.title = element_text(face="bold"),
        plot.title.position = "plot")

print(p_full_att)

ggsave(
  here::here(paste0("figures/effect_sizes_att_absbias_", dt, ".png")),
  p_full_att, width = 10, height = 7, dpi = 300
)

#library(patchwork)
#p_combined_att <- p_zoomed_att + p_full_att +
  # plot_annotation(
  #   title    = "Eta-Squared for Significant Effects: ATT Absolute Bias",
  #   subtitle = "Treatment has the largest effect (η² = 0.222, Large); all effects significant at p < .001"
  # ) *
  # theme(
  #   plot.title    = element_text(face = "bold", size = 14),
  #   plot.subtitle = element_text(size = 11, color = "gray30")
  # )

# print(p_full_att)
# 
# ggsave(
#   here::here(paste0("figures/effect_sizes_att_absbias_combined_", dt, ".png")),
#   p_combined_att, width = 14, height = 7, dpi = 300
# )  

```  

```{r}
# Compute mean absolute bias for each cell of the 4-way interaction
foursway_att <- all_df_att |>
  group_by(Treatment, N, Proportion, Magnitude) |>
  summarise(
    mean_abs_bias = mean(abs_bias, na.rm = TRUE),
    .groups = "drop"
  ) 

pd <- position_dodge(width=0.3) 

plot_4way_att <- ggplot(
  foursway_att,
  aes(x = Magnitude, y = mean_abs_bias, color = Treatment, group = Treatment)
) +
  # geom_line(linewidth = 0.8, position = pd, alpha = 0.6) +
  geom_point(size = 2, position = pd) +
  facet_grid(
    N ~ Proportion,
    labeller = labeller(
      N          = function(x) paste0("N = ", x),
      Proportion = function(x) paste0("Prop = ", x)
    )
  ) +
  scale_color_manual(
    name   = "Treatment",
    values = c(
      "No treatment"                = "#0072B2",
      "Top-coding"                  = "#E69F00",
      "Mean-preserved top-coding"   = "#009E73",
      "Median-preserved top-coding" = "#CC79A7",
      "Truncation"                  = "#D55E00"
    )
  ) +
  guides(color = guide_legend(nrow=2))+
  labs(
    title    = "Four-Way Interaction: ATT Absolute Bias",
    subtitle = "Mean absolute bias by treatment, magnitude, proportion of extremes, and sample size",
    x        = "Magnitude level",
    y        = "Mean absolute bias"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    legend.position     = "bottom",
    strip.text          = element_text(face = "bold"),
    plot.title          = element_text(face = "bold"),
    plot.title.position = "plot"
  )

plot_4way_att

ggsave(
  here::here(paste0("figures/att_absbias_4way_interaction_", dt, ".png")),
  plot_4way_att, width = 12, height = 9, dpi = 300
)

```






