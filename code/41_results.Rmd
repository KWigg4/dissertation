---
title: "Results"
author: "KW"
date: "`r Sys.Date()`"
output: html_document
---

PURPOSE: Chapters 4 and 5. After DGP is run and executed, tables are created for results. Import these to make display assets and run ANOVAs.  

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

```{r pkgs}
pacman::p_load(
  broom,
  cowplot,
  dplyr,
  effectsize,
  forcats,
  # furrr,
  ggforce,
  ggplot2,
  ggrepel,
  glue,
  gt,
  here,
  lubridate,
  patchwork,
  purrr,
  readr,
  scales,
  # tibble,
  tidyr)

dt <- lubridate::today()
#dir.create("results", showWarnings = FALSE)
#dir.create("figures", showWarnings = FALSE)

conflicted::conflicts_prefer(
  dplyr::select(),
  dplyr::filter()
)

# Save csv and RDS to results directory
fn_save_results <- function(df) {
  name <- deparse(substitute(df))
  saveRDS(df, here::here(paste0("results/",name,"_",dt, ".RDS")))
  write.csv(df,here::here(paste0("results/",name,"_",dt, ".csv")))
}

# Reads datasets created on 02-25:
fn_readRDS <- function(ds) {
  ds <- deparse(substitute(ds))
  readRDS(here::here(paste0("results/",ds,"_2026-02-25.RDS")))
}

# Helper for quantiles
q_fun <- function(x, p) stats::quantile(x, probs = p, na.rm = TRUE, type = 7)

```  


```{r get_replicates}
# all_df_treatment: summarized at the treatment level only (N=13500 per)
# all_df_2026-02-21 is unformatted/ unchanged from MC sim, DO NOT REMOVE from files. 
# all_df_2026-02-25 is transformed. 

all_df_w_fails <- fn_readRDS(all_df_w_fails) # nrow 202500
all_df_gamma_w_fails <- fn_readRDS(all_df_gamma_w_fails) 
# FAILURES ONLY: 
all_df_gamma_fails <- fn_readRDS(all_df_gamma_fails) # nrow 129
all_df_gamma_fails_tbl <- fn_readRDS(all_df_gamma_fails_tbl) # nrow 9

# all_df_gamma only, failures removed. 
# # # ANALYSIS DATASET for gamma bias ANOVA# # #
all_df_gamma <- fn_readRDS(all_df_gamma) |>  # nrow 67,371
  rename("Treatment"=treatment_fct,
         "N" = nobs_fct,
         "Proportion"=prop_extreme_fct,
         "Magnitude" = magnitude_fct)

# use for treatment descriptives, RQs 1-3: 
gamma_by_treatment <- fn_readRDS(gamma_by_treatment) # nrow=5

# use for scenario descriptives, RQs 1-3: 
gamma_by_scenario <- fn_readRDS(gamma_by_scenario) # nrow 135

## Used for analysis, the successful att's at the replicate level:
all_df_att <- fn_readRDS(all_df_att) |> # 67,371
  rename("Treatment"=treatment_fct,
         "N" = nobs_fct,
         "Proportion"=prop_extreme_fct,
         "Magnitude" = magnitude_fct)

```    

```{r scenario_key}
# Build the canonical 27-row scenario key (nobs → prop → magnitude)
scenario_key <- all_df_gamma |>
  distinct(N, Proportion, Magnitude) |>
  # recover numeric versions for sorting
  mutate(
    nobs_num  = as.numeric(gsub(",", "", as.character(N))),
    prop_num  = as.numeric(as.character(Proportion)),
    mag_num   = as.numeric(as.character(Magnitude))
  ) |>
  arrange(nobs_num, prop_num, mag_num) |>
  mutate(scenario_id = row_number()) |>
  select(scenario_id, N, Proportion, Magnitude)

# Factor levels for scenario_id (1 → 27, left to right on x-axis)
scenario_id_levels <- as.character(1:27)

# Fixed treatment order (position in the 3-row grid) for lollis
treatment_order_3row <- c(
  "No treatment",
  "Mean-preserved top-coding", "Median-preserved top-coding",
  "Top-coding", "Truncation"
)
```    

```{r make_lolli_panel}

# Single-panel builder shared by both bias and ESE chunks
# yvar2: optional second numeric column (unquoted) plotted as small grey dots
#        on top of the lollipop — used for model SE on ESE panels. (for modse)
# put crosses in front of dots so you can see them (when they're behind they're not visible)
make_lolly_panel <- function(
    data,
    yvar,
    tier_var,
    y_limits,
    tier_colors,
    tier_name,
    panel_title,
    show_x_axis,
    show_y_axis,
    y_label = "",
    hline = 0,
    yvar2 = NULL
) {
  p <- ggplot(data, aes(x = scenario_id, y = {{ yvar }})) +
    geom_hline(yintercept = hline, linetype = "dashed",
               color = "grey30", linewidth = 0.4) +
    geom_segment(
      aes(xend = scenario_id, y = hline, yend = {{ yvar }}),
      linewidth = 0.5, color = "grey65"
    ) +
    # ESE colored dot FIRST (behind)
    geom_point(aes(color = {{ tier_var }}), size = 2.2) +
    # Model SE cross on TOP (in front), now grey instead of black
    { if (!is.null(substitute(yvar2)))
        geom_point(aes(y = {{ yvar2 }}),
                   shape = 3, size = 2.0,
                   color = "grey40", stroke = 0.8)
      else
        geom_blank()
    }

  p +
    scale_color_manual(name = tier_name, values = tier_colors) +
    scale_y_continuous(limits = y_limits) +
    scale_x_discrete(breaks = scenario_id_levels,
                     limits = scenario_id_levels) +
    ggtitle(panel_title) +
    labs(y = if (show_y_axis) y_label else "") +
    theme_minimal(base_size = 11) +
    theme(
      panel.grid.major.x  = element_blank(),
      panel.grid.minor    = element_blank(),
      plot.title          = element_text(face = "bold", size = 10, hjust = 0.5),
      legend.position     = "none",
      axis.text.x  = if (show_x_axis) element_text(size = 8) else element_blank(),
      axis.ticks.x = if (show_x_axis) element_line() else element_blank(),
      axis.title.x = element_blank(),
      axis.title.y = if (show_y_axis) element_text(size = 9) else element_blank(),
      axis.text.y  = element_text(size = 8)
    )
}
```


```{r scenario_key_table}

scenario_key_gt <- scenario_key |>
  gt() |>
  tab_header(
    title    = "Scenario Key: Bias and ESE Lollipop Plots",
    subtitle = "Scenarios ordered by sample size, proportion of extremes, then magnitude level"
  ) |>
  cols_label(
    scenario_id = "ID",
    N           = "Sample Size (N)",
    Proportion  = "Prop. Extreme",
    Magnitude   = "Magnitude Level"
  ) |>
  tab_style(
    style     = cell_text(weight = "bold"),
    locations = cells_column_labels()
  ) |>
  tab_footnote(
    footnote  = "Magnitude: 1 = $50K–$1M; 2 = $50K–$2M; 3 = $50K–$3M",
    locations = cells_column_labels(columns = Magnitude)
  ) |>
  tab_options(data_row.padding = px(2))

scenario_key_gt

gtsave(scenario_key_gt,
       here::here(paste0("results/scenario_key_table_", dt, ".rtf")))
gtsave(scenario_key_gt,
       here::here(paste0("results/scenario_key_table_", dt, ".html")))
write.csv(scenario_key,
          here::here(paste0("results/scenario_key_", dt, ".csv")),
          row.names = FALSE)
```



```{r fails}
failure_log <- read.csv(here::here("results/failure_log_2026-02-21.csv")) %>%
  # n_failures is numeric in real rows and blank/text in notes rows
  filter(!is.na(n_failures), !is.na(magnitude_level)) %>%
  mutate(
    n    = as.numeric(n),
    nobs = n * 2,
    N = factor(nobs,
      levels = c(5000, 10000, 20000),
      labels = c("5,000", "10,000", "20,000")),
    Magnitude = factor(magnitude_level,
      levels = c(1, 2, 3),
      labels = c("1 ($50K–$1M)", "2 ($50K–$2M)", "3 ($50K–$3M)")),
    Proportion = factor(prop_extreme,
      levels = c(0.01, 0.05, 0.10),
      labels = c("0.01", "0.05", "0.10")),
    error_type = case_when(
      grepl("step size",        gamma_error) ~ "Step size truncated",
      grepl("did not converge", gamma_error) ~ "Did not converge",
      grepl("NA/NaN/Inf",       gamma_error) ~ "NA/NaN/Inf in x"
    )
  )
```



## Failures  

```{r}
# Total N for percentages
total_failures <- sum(failure_log$n_failures)  # 129
total_reps     <- 67500                         # B=500 * 135 scenarios * 1 model

# --- Table 1: By error type ---
tbl_by_error <- failure_log %>%
  group_by(error_type) %>%
  summarise(n = sum(n_failures), .groups = "drop") %>%
  mutate(
    pct_of_failures = scales::percent(n / total_failures, accuracy = 0.1),
    pct_of_all_reps = scales::percent(n / total_reps,     accuracy = 0.2)
  )

# --- Table 2: By condition ---
tbl_by_condition <- failure_log %>%
  group_by(N, Proportion, Magnitude) %>%
  summarise(n = sum(n_failures), .groups = "drop") %>%
  mutate(
    pct_of_failures = scales::percent(n / total_failures, accuracy = 0.1),
    pct_of_500      = scales::percent(n / 500,            accuracy = 0.1)
  ) %>%
  arrange(N, Proportion, Magnitude)

write.csv(tbl_by_condition,
          here::here("results/tbl_failures_condition_2026-02-22.csv"))

# --- Table 3: All -------
tbl_reasons_conditions <- failure_log |> 
  group_by(N, Proportion, Magnitude, error_type) %>%
  summarize(n_fails=sum(n_failures), .groups="drop") |> 
  mutate(
    pct_of_failures = scales::percent(n_fails / total_failures, accuracy = 0.1),
    pct_of_500      = scales::percent(n_fails / 500,            accuracy = 0.1)
  ) %>%
  arrange(error_type, N, Proportion, Magnitude)
write.csv(tbl_reasons_conditions,
          here::here("results/tbl_failures_reason_condition_2026-02-22.csv"))
# --- GT table combining both ---
tbl_by_error %>%
  gt() %>%
  tab_header(
    title    = "Gamma Model Convergence Failures",
    subtitle = glue("Total: {total_failures} failures across 67,500 replications (0.19%)")
  ) %>%
  cols_label(
    error_type      = "Failure Type",
    n               = "N Failures",
    pct_of_failures = "% of Failures",
    pct_of_all_reps = "% of All Reps"
  ) %>%
  tab_source_note(
    "All failures occurred in raw (untreated) condition only. 
     No failures in top-coding, mean-adj, median-adj, or truncation."
  )

tbl_by_condition %>%
  gt() %>%
  tab_header(
    title    = "Failures by Simulation Condition",
    subtitle = "% of 500 reps = failure rate within that condition"
  ) %>%
  cols_label(
    N         = "N (obs)",
    Proportion = "Prop. Extreme",
    Magnitude    = "Magnitude",
    n                = "N Failures",
    pct_of_failures  = "% of All Failures",
    pct_of_500       = "% of 500 Reps"
  )


```  



```{r}
# checking for balance
all_df_gamma |>
  dplyr::group_by(Treatment, N, Proportion, Magnitude) |>
  dplyr::summarise(n_count=n()) |> 
  View()

```  

## Bias

### Descriptives  


```{r descr_bias}
# Focus on the Gamma Part-2 interaction (can switch to "ATT" later)

# ---- Bias (overall) ----
# mean_bias is average SIGNED bias; preserves direction of estimator's errors, where neg is systematic underestimation and positive is systematic overestimation and opposing signs are going to cancel each other out. 
# The mean_abs_bias is the average absolute magnitude of the bias, which measures how far the estimator is from the truth on average. Does not allow pos/neg to cancel each other out. Always >=0. Larger values indicate more inconsistent or unstable estimation. 
# Mean_abs_bias captures estimator error magnitude, while mean_bias captures estimator direction. mean_bias answers if treatment method systematically over or under estimates the effect, while mean_abs_bias answers how large are the estimation errors, regardless of direction. A method an have a mean bias of 0 and look good but actually perform poorly when you see a large mean_abs_bias because that means it swings pos in some directions, negative in others. 

tbl_bias_overall <- all_df_gamma %>%
  dplyr::summarise(
    scenarios        = dplyr::n(),
    mean_bias        = mean(bias, na.rm = TRUE),
    sd_bias          = sd(bias, na.rm = TRUE),
    var_bias         = var(bias, na.rm=TRUE),
    median_bias      = median(bias, na.rm = TRUE),
    mad_bias         = mad(bias, na.rm = TRUE),
    min_bias         = min(bias, na.rm = TRUE),
    q1_bias          = q_fun(bias, 0.25),
    q3_bias          = q_fun(bias, 0.75),
    iqr_bias         = q3_bias - q1_bias,
    max_bias         = max(bias, na.rm = TRUE),
    mean_abs_bias    = mean(abs(bias), na.rm = TRUE),
    share_bias_neg   = mean(bias < 0, na.rm = TRUE),
    share_bias_pos   = mean(bias > 0, na.rm = TRUE),
    .groups = "drop"
  )

print(tbl_bias_overall)
write.csv(tbl_bias_overall, 
          here::here("results/tbl_bias_overall_2026-02-25.csv"))

tbl_bias_treatment <- all_df_gamma %>%
  dplyr::group_by(Treatment) %>%
  dplyr::summarise(
    scenarios        = dplyr::n(),
    mean_bias        = mean(bias, na.rm = TRUE),
    sd_bias          = sd(bias, na.rm = TRUE),
    median_bias      = median(bias, na.rm = TRUE),
    mad_bias         = mad(bias, na.rm = TRUE),
    min_bias         = min(bias, na.rm = TRUE),
    q1_bias          = q_fun(bias, 0.25),
    q3_bias          = q_fun(bias, 0.75),
    iqr_bias         = q3_bias - q1_bias,
    max_bias         = max(bias, na.rm = TRUE),
    mean_abs_bias    = mean(abs(bias), na.rm = TRUE),
    share_bias_neg   = mean(bias < 0, na.rm = TRUE),
    share_bias_pos   = mean(bias > 0, na.rm = TRUE),
    .groups = "drop"
  )
print(tbl_bias_treatment)
write.csv(tbl_bias_treatment, 
          here::here("results/tbl_bias_treatment_2026-02-25.csv"))

tbl_bias_scen <- all_df_gamma %>%
  dplyr::group_by(Treatment, N, Proportion, Magnitude) %>%
  dplyr::summarise(
    scenarios        = dplyr::n(),
    mean_bias        = mean(bias, na.rm = TRUE),
    sd_bias          = sd(bias, na.rm = TRUE),
    median_bias      = median(bias, na.rm = TRUE),
    mad_bias         = mad(bias, na.rm = TRUE),
    min_bias         = min(bias, na.rm = TRUE),
    q1_bias          = q_fun(bias, 0.25),
    q3_bias          = q_fun(bias, 0.75),
    iqr_bias         = q3_bias - q1_bias,
    max_bias         = max(bias, na.rm = TRUE),
    mean_abs_bias    = mean(abs(bias), na.rm = TRUE),
    share_bias_neg   = mean(bias < 0, na.rm = TRUE),
    share_bias_pos   = mean(bias > 0, na.rm = TRUE),
    .groups = "drop"
  ) |> 
  arrange(N, Proportion, Magnitude, Treatment)
print(tbl_bias_scen)

write.csv(tbl_bias_scen, 
          here::here("results/tbl_bias_scen_2026-02-25.csv"))

```  

### Over/under estimation  

```{r over_underests}
tbl_bias_UnderOver_scen <- all_df_gamma %>%
  group_by(Treatment, N, Proportion, Magnitude) %>%
  summarise(
    n_under = sum(est < true, na.rm = TRUE),
    n_over = sum(est > true, na.rm = TRUE),
    under_rate = mean(est < true, na.rm = TRUE),
    over_rate  = mean(est > true, na.rm = TRUE),
    n_design=n(),
    .groups = "drop"
  ) |> 
  mutate(
    pct_under = scales::percent(under_rate, accuracy = 0.1),
    pct_over = scales::percent(over_rate, accuracy = 0.1)
  ) |> 
  ungroup() |> 
  select(Treatment, n_design, N, Proportion, Magnitude, n_under, n_over, pct_under, pct_over, under_rate, over_rate) |> 
  mutate(
    under_majority = under_rate > 0.5,
    over_majority  = over_rate > 0.5
  )

tbl_bias_UnderOver_scen |> 
  arrange(N, Proportion, Magnitude, Treatment) |> 
  select(-c(under_rate, over_rate)) |> 
  gt() |> 
  gt::gtsave(here::here("results/tbl_over_under_scen.rtf"))

```    

```{r bias_by_scen}
scenario_summary <- tbl_bias_UnderOver_scen |>
  group_by(N, Proportion, Magnitude) |>
  summarise(
    n_treatments = n(),
    n_treat_under = sum(under_rate > 0.5, na.rm = TRUE),
    n_treat_over  = sum(over_rate  > 0.5, na.rm = TRUE),
    n_treat_under_majority = sum(under_majority, na.rm = TRUE),
    n_treat_over_majority  = sum(over_majority,  na.rm = TRUE),
    prop_treat_under = n_treat_under / n_treatments,
    prop_treat_over  = n_treat_over  / n_treatments,
    prop_treat_under_majority = n_treat_under_majority / n_treatments,
    .groups = "drop"
  )

scenario_summary |>
  gt() |>
  gtsave(here::here("results/tbl_over_under_scen_summary.rtf"))

```



### Plots  

#### Lollipop  

```{r prep_lolli}

prep_plot_bias_over_under <- all_df_gamma |>
  group_by(Treatment, N, Proportion, Magnitude) |> 
  summarise(
    bias = mean(bias, na.rm = TRUE),
    .groups = "drop"
  ) |>
  left_join(
    tbl_bias_UnderOver_scen,
    by = c("Treatment", "N", "Proportion", "Magnitude")
  ) |>
  mutate(
    scenario = glue::glue("p={Proportion} n={N} m={Magnitude}")
  ) |>
  arrange(N, Proportion, Magnitude, Treatment) |>
  mutate(
    scenario = factor(scenario, levels = rev(unique(scenario)))
  )

x_min <- min(prep_plot_bias_over_under$bias, na.rm = TRUE)
x_max <- max(prep_plot_bias_over_under$bias, na.rm = TRUE)

# Investigate discrepancy: positive mean bias but majority of reps underestimating
check_discrepancy <- prep_plot_bias_over_under |>
  filter(bias > 0 & under_majority == TRUE) |>
  select(Treatment, N, Proportion, Magnitude, bias, n_under, n_over, under_rate, scenario)

check_discrepancy |>
  ggplot(aes(x = bias, y = under_rate, label = scenario)) +
  geom_point() +
  ggrepel::geom_text_repel(size = 3) +
  facet_wrap(~Treatment) +
  geom_vline(xintercept = 0, linetype = "dashed") +
  geom_hline(yintercept = 0.5, linetype = "dashed") +
  labs(x = "Mean bias", y = "Proportion of reps underestimating",
       title = "Scenarios with positive mean bias but majority of reps underestimating")

# tab_27 - now consistent: scen_under uses under_majority to match scen_under_majority
tab_27 <- prep_plot_bias_over_under |>
  group_by(Treatment) |>
  summarise(
    n_scen = n(),
    scen_under = sum(under_majority, na.rm = TRUE),
    scen_over  = sum(over_majority, na.rm = TRUE),
    scen_under_majority = sum(under_majority, na.rm = TRUE),
    prop_scen_under = scen_under / 27,
    prop_scen_over  = scen_over  / 27,
    prop_scen_under_majority = scen_under_majority / 27,
    .groups = "drop"
  )
```  



```{r lolli_scen}

# Attach scenario IDs and tiers
bias_plot_data <- prep_plot_bias_over_under |>
  left_join(scenario_key, by = c("N", "Proportion", "Magnitude")) |>
  mutate(
    scenario_id = factor(scenario_id, levels = scenario_id_levels),
    Treatment   = factor(Treatment,   levels = treatment_order_3row),
    bias_tier   = case_when(
      abs(bias) > 0.05 ~ ">|0.05|",
      abs(bias) > 0.04 ~ ">|0.04|",
      TRUE             ~ "<=|0.04|"
    ),
    bias_tier = factor(bias_tier, levels = c("<=|0.04|", ">|0.04|", ">|0.05|"))
  )

bias_colors <- c("<=|0.04|" = "steelblue", ">|0.04|" = "orange", ">|0.05|" = "red")
bias_y_lims <- c(x_min, x_max)   # x_min / x_max defined in lolly1 chunk

# Convenience wrapper
make_bias <- function(trt, show_x, show_y) {
  make_lolly_panel(
    data        = bias_plot_data |> dplyr::filter(Treatment == trt),
    yvar        = bias,
    tier_var    = bias_tier,
    y_limits    = bias_y_lims,
    tier_colors = bias_colors,
    tier_name   = "|Bias| threshold",
    panel_title = trt,
    show_x_axis = show_x,
    show_y_axis = show_y,
    y_label     = "Mean Bias"
  )
}

# 5 panels: x-axis only on bottom row, y-axis only on left column
p_b1 <- make_bias("No treatment",                show_x = FALSE, show_y = TRUE)
p_b2 <- make_bias("Mean-preserved top-coding",   show_x = FALSE, show_y = TRUE)
p_b3 <- make_bias("Median-preserved top-coding", show_x = FALSE, show_y = FALSE)
p_b4 <- make_bias("Top-coding",                  show_x = TRUE,  show_y = TRUE)
p_b5 <- make_bias("Truncation",                  show_x = TRUE,  show_y = FALSE)

# Extract shared legend via gtable
tmp_bias <- p_b1 +
  theme(legend.position = "bottom",
        legend.title = element_text(size = 9),
        legend.text  = element_text(size = 9))
shared_bias_legend <- gtable::gtable_filter(
  ggplot2::ggplotGrob(tmp_bias), "guide-box"
)

# Compose: top-right slot = plot_spacer()
bias_patch <- (
    p_b1 + plot_spacer() +
    p_b2 + p_b3 +
    p_b4 + p_b5
  ) +
  plot_layout(nrow = 3, ncol = 2, byrow = TRUE)

# Title/subtitle added via cowplot below (avoids patchwork theme conflict)
bias_title    <- "Gamma Interaction: Scenario-Level Mean Bias by Treatment"
bias_subtitle <- "X-axis: scenario ID 1-27*. Dashed line = zero bias."

# Attach shared x-axis label and legend beneath
x_label_bias <- cowplot::ggdraw() +
  cowplot::draw_label("Scenario ID", size = 10, hjust = 0.5)

plot_bias_3row <- cowplot::plot_grid(
  cowplot::plot_grid(
    cowplot::ggdraw() + cowplot::draw_label(bias_title,    fontface = "bold", size = 13, hjust = 0.5),
    cowplot::ggdraw() + cowplot::draw_label(bias_subtitle, size = 10, colour = "grey40", hjust = 0.5),
    ncol = 1, rel_heights = c(0.6, 0.4)
  ),
  bias_patch,
  cowplot::plot_grid(x_label_bias, shared_bias_legend,
                     ncol = 1, rel_heights = c(0.35, 0.65)),
  ncol = 1, rel_heights = c(0.1, 1, 0.15)
)

plot_bias_3row

ggsave(
  here::here(paste0("figures/gamma_bias_lollipop_3row_", dt, ".png")),
  plot_bias_3row, width = 13, height = 13, dpi = 300
)

```
#### Lolli treatment

```{r lolli_treat}

prep_plot_bias_lollipop <- all_df_gamma %>%
  group_by(Treatment) %>%
  summarise(
    mean_of_means = mean(bias, na.rm = TRUE),
    sd_of_means   = sd(bias, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    sign = ifelse(
      mean_of_means < 0, "Underestimation (−)", "Overestimation (+)")) 

plot_bias_lollipop <- prep_plot_bias_lollipop |> 
  ggplot(aes(x = Treatment, y = mean_of_means, color = sign)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_segment(
    aes(xend = Treatment, y = 0, yend = mean_of_means), linewidth = 1.2) +
  geom_point(size = 3) +
  scale_color_manual(values = c("Underestimation (−)" = "#C7372F", "Overestimation (+)" = "#2B6CB0")) +
  scale_x_discrete(labels = scales::label_wrap(15))+
  labs(
    title = "Average Bias by Data Treatment Method",
    subtitle = "Positive = overestimation (>0); Negative = underestimation (<0)",
    x = NULL, 
    y = "Average bias") +
  theme_minimal() +
  theme(legend.position = "top",
        axis.text.x = element_text(size=9, lineheight=0.9))

plot_bias_lollipop
ggsave(here::here(paste0("figures/gamma_bias_lollipop_", dt, ".png")),
       plot_bias_lollipop, width = 8, height = 5, dpi = 300)
```  


#### Jitter (4-way)     

```{r bias_jitter}
# --- Trend lines including n as a scenario condition ---
# Treat magnitude level as numeric for trend fitting

plot_trends <- ggplot(
  tbl_bias_scen,
  aes(
    x = Magnitude,
    y = mean_bias,
    color = Treatment
  )
) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_jitter(
    width = 0.2,  
    height = 0,
    size = 3,
    alpha = 0.7
  ) +
  facet_grid(N ~ Proportion, 
             labeller = labeller(
               N = function(x) paste0("N=",x),
               Proportion = function(x) paste0(
                 "Prop. Extreme=",x)
               )
             ) +
  scale_color_manual( 
    name = "Data Treatment", 
    values = c(
      "No treatment" = "#0072B2",
      "Top-coding" = "#E69F00",
      "Mean-preserved top-coding" = "#009E73",
      "Median-preserved top-coding" = "#CC79A7",
      "Truncation" = "#D55E00" ) ) +
  labs(
    title = "Gamma Interaction: Scenario-Level Bias Across Magnitude of Extremes",
    subtitle = "Rows = N; Cols = proportion extreme; points show scenario-level bias",
    x = "Magnitude level",
    y = "Bias"
  ) +
  guides(color = guide_legend(nrow=2))+
  theme_minimal() +
  theme(legend.position = "bottom",
        legend.title = element_text(face = "bold"))

plot_trends
ggsave(here::here(paste0("figures/gamma_bias_trends_", dt, ".png")),
       plot_trends, width = 11, height = 7, dpi = 300)


```  

#### plot dist

```{r}
plot_est_dist <- all_df_gamma |>
  mutate(
    Magnitude = factor(Magnitude),
    Treatment = factor(Treatment, levels = rev(c(
      "No treatment",
      "Top-coding",
      "Mean-preserved top-coding",
      "Median-preserved top-coding",
      "Truncation"
    )))
  ) |>
  mutate(dist_from_zero = abs(est)) |>
  ggplot(aes(x = est, y = Treatment, color = dist_from_zero)) +
  geom_jitter(height = 0.2, size = 1.2, alpha = 0.4) +
  stat_summary(
    fun = mean, geom = "point", shape = "|",
    size = 5, color = "goldenrod"
  ) +
  #geom_vline(xintercept = 0, linetype = "dashed", color = "grey30") +
  scale_color_gradient(low = "steelblue", high = "red", name = "Distance from 0") +
  facet_grid(N + Magnitude ~ Proportion,
             labeller = labeller(
               N          = function(x) paste0("N=", x),
               Proportion = function(x) paste0("Prop=", x),
               Magnitude  = function(x) paste0("Mag=", x)
             )) +
  labs(
    title    = "Distribution of Gamma Interaction Estimates by Treatment and Scenario",
    subtitle = "Each point = one replication; gold bar = mean",
    x        = "Estimate",
    y        = "Data treatment method"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    plot.title = element_text(face = "bold"),
    plot.title.position = "plot",
    strip.text = element_text(face = "bold", size = 7),
    legend.position = "none",
    plot.margin = margin(t=5, r=40, b=5, l=5, unit="pt")
  )+
  coord_cartesian(clip="off")

plot_est_dist

ggsave(
  here::here(paste0("figures/gamma_est_distribution_", dt, ".png")),
  plot_est_dist, width = 14, height = 20, dpi = 300
)
```



## ESE   

### Descriptives

```{r ESE}

# compute_ESE_metrics: flexible grouping, always from all_df_gamma

compute_ESE_metrics <- function(
    group_vars = c(
      "Treatment", "N", "Proportion", "Magnitude")) {
  all_df_gamma |>
    group_by(across(all_of(group_vars))) |>
    summarise(
      n_reps            = n(),
      # Core ESE
      ese               = sd(est, na.rm = TRUE),
      mcse_ese          = sd(est, na.rm = TRUE) / sqrt(n()),
      # Model SE summaries
      se_model_mean     = mean(se, na.rm = TRUE),
      se_model_median   = median(se, na.rm = TRUE),
      # Morris (2019) calibration
      ratio_modse_emp   = se_model_mean / ese,
      rel_error_modse   = 100 * (se_model_mean / ese - 1),
      rmse_se           = sqrt(mean((se - ese)^2, na.rm = TRUE)),
      # Rep-level SE calibration flag
      prop_under_se     = mean(se < ese, na.rm = TRUE),
      under_majority_se = prop_under_se > 0.5,
      # RMSE of estimator
      rmse              = sqrt(mean((est - true)^2, na.rm = TRUE)),
      .groups = "drop"
    )
}


# Three direct calls on all_df_gamma

# 1 row: overall
ese_overall      <- compute_ESE_metrics(group_vars = character(0))

# 5 rows: one ESE per treatment, computed from ~13,500 reps each
ese_by_treatment <- compute_ESE_metrics(group_vars = "Treatment")

# 135 rows: one ESE per treatment*scenario cell, computed from ~500 reps each
ese_full         <- compute_ESE_metrics(
  group_vars = c("Treatment", "N","Proportion", "Magnitude"))


# Descriptives of the 27 scenario-level ESEs per treatment
# Requires ese_full because you need 27 ESE values per treatment to summarise
# This is a SEPARATE question from ese_by_treatment above

ese_by_treatment_scen_descr <- ese_full |>
  group_by(Treatment) |>
  summarise(
    n_scen                   = n(),
    # ESE descriptives across 27 scenarios
    mean_ese                 = mean(ese, na.rm = TRUE),
    sd_ese                   = sd(ese, na.rm = TRUE),
    median_ese               = median(ese, na.rm = TRUE),
    mad_ese                  = mad(ese, na.rm = TRUE),
    min_ese                  = min(ese, na.rm = TRUE),
    max_ese                  = max(ese, na.rm = TRUE),
    # Morris calibration descriptives across 27 scenarios
    mean_ratio_modse_emp     = mean(ratio_modse_emp, na.rm = TRUE),
    mean_rel_error_modse     = mean(rel_error_modse, na.rm = TRUE),
    sd_rel_error_modse       = sd(rel_error_modse, na.rm = TRUE),
    mean_rmse_se             = mean(rmse_se, na.rm = TRUE),
    # Scenario-level underestimation counts
    n_scen_underest          = sum(ratio_modse_emp < 1, na.rm = TRUE),
    prop_scen_underest       = mean(ratio_modse_emp < 1, na.rm = TRUE),
    n_scen_under_majority    = sum(under_majority_se, na.rm = TRUE),
    prop_scen_under_majority = mean(under_majority_se, na.rm = TRUE),
    # RMSE descriptives
    mean_rmse                = mean(rmse, na.rm = TRUE),
    sd_rmse                  = sd(rmse, na.rm = TRUE),
    .groups = "drop"
  )


# Save all
fn_save_results(ese_overall)
fn_save_results(ese_by_treatment)
fn_save_results(ese_full)
fn_save_results(ese_by_treatment_scen_descr)

```

### Lollipop  

```{r ese_plots}

# Attach scenario IDs and tiers
ese_plot_data <- ese_full |>
  left_join(scenario_key, by = c("N", "Proportion", "Magnitude")) |>
  mutate(
    scenario_id = factor(scenario_id, levels = scenario_id_levels),
    Treatment   = factor(Treatment,   levels = treatment_order_3row),
    ese_tier    = case_when(
      ese > 0.50 ~ ">0.50",
      ese > 0.25 ~ ">0.25",
      TRUE       ~ "<=0.25"
    ),
    ese_tier = factor(ese_tier, levels = c("<=0.25", ">0.25", ">0.50"))
  )

ese_colors <- c("<=0.25" = "steelblue", ">0.25" = "orange", ">0.50" = "red")
ese_y_lims <- c(0, max(ese_plot_data$ese, na.rm = TRUE) * 1.05)

make_ese <- function(trt, show_x, show_y) {
  make_lolly_panel(
    data        = ese_plot_data |> dplyr::filter(Treatment == trt),
    yvar        = ese,
    yvar2       = se_model_mean,   # grey open circles = mean model SE
    tier_var    = ese_tier,
    y_limits    = ese_y_lims,
    tier_colors = ese_colors,
    tier_name   = "ESE threshold",
    panel_title = trt,
    show_x_axis = show_x,
    show_y_axis = show_y,
    y_label     = "Empirical SE"
  )
}

p_e1 <- make_ese("No treatment",                show_x = FALSE, show_y = TRUE)
p_e2 <- make_ese("Mean-preserved top-coding",   show_x = FALSE, show_y = TRUE)
p_e3 <- make_ese("Median-preserved top-coding", show_x = FALSE, show_y = FALSE)
p_e4 <- make_ese("Top-coding",                  show_x = TRUE,  show_y = TRUE)
p_e5 <- make_ese("Truncation",                  show_x = TRUE,  show_y = FALSE)

tmp_ese <- p_e1 +
  theme(legend.position = "bottom",
        legend.title = element_text(size = 9),
        legend.text  = element_text(size = 9))

shared_ese_legend <- gtable::gtable_filter(
  ggplot2::ggplotGrob(tmp_ese), "guide-box"
)

ese_patch <- (
    p_e1 + plot_spacer() +
    p_e2 + p_e3 +
    p_e4 + p_e5
  ) +
  plot_layout(nrow = 3, ncol = 2, byrow = TRUE)

ese_title    <- "Gamma Interaction: Scenario-Level Empirical SE by Treatment"
ese_subtitle <- "X-axis: scenario ID 1-27 (see companion table). Filled dots = empirical SE (coloured by threshold); black crosses = mean model SE."

x_label_ese <- cowplot::ggdraw() +
  cowplot::draw_label("Scenario ID", size = 10, hjust = 0.5)

plot_ese_3row <- cowplot::plot_grid(
  cowplot::plot_grid(
    cowplot::ggdraw() + cowplot::draw_label(ese_title,    fontface = "bold", size = 13, hjust = 0.5),
    cowplot::ggdraw() + cowplot::draw_label(ese_subtitle, size = 10, colour = "grey40", hjust = 0.5),
    ncol = 1, rel_heights = c(0.6, 0.4)
  ),
  ese_patch,
  cowplot::plot_grid(x_label_ese, shared_ese_legend,
                     ncol = 1, rel_heights = c(0.35, 0.65)),
  ncol = 1, rel_heights = c(0.10, 1, 0.15)
)

plot_ese_3row

ggsave(
  here::here(paste0("figures/gamma_ese_lollipop_3row_", dt, ".png")),
  plot_ese_3row, width = 13, height = 13, dpi = 300
)

```  
## Coverage  

### Descriptives

```{r cov_tables}
# Overall (N = 67,371 reps)
tab_cov_overall <- all_df_gamma |>
  summarise(
    n_reps      = n(),
    mean_cov    = mean(cover_ind, na.rm = TRUE),
    n_covered   = sum(cover_ind == 1, na.rm = TRUE),
    n_uncovered = sum(cover_ind == 0, na.rm = TRUE)
  )

# By treatment, rep-level (N ~13,500 per treatment)
# This tells you: of all reps under this treatment, what fraction covered?
tab_cov_by_treatment_reps <- all_df_gamma |>
  group_by(Treatment) |>
  summarise(
    n_reps      = n(),
    mean_cov    = mean(cover_ind, na.rm = TRUE),
    n_covered   = sum(cover_ind == 1, na.rm = TRUE),
    n_uncovered = sum(cover_ind == 0, na.rm = TRUE),
    .groups = "drop"
  )

# Collapse to scenario-level rates (N = 135)
# Do this once and reuse below
cov_by_scenario <- all_df_gamma |>
  group_by(Treatment, N, Proportion, Magnitude) |>
  summarise(
    n_reps   = n(),
    coverage = mean(cover_ind, na.rm = TRUE),
    .groups  = "drop"
  )

# All 135 scenarios with pass/fail flag
tab_cov_scenario <- cov_by_scenario |>
  mutate(
    meets_95 = coverage >= 0.95
  )

# Summarise scenarios by treatment (N = 5, each summarising 27 scenarios)
# This tells you: across the 27 scenarios for this treatment, how did coverage rates behave?
tab_cov_by_treatment_scen <- cov_by_scenario |>
  group_by(Treatment) |>
  summarise(
    n_scenarios  = n(),
    mean_cov     = mean(coverage),
    sd_cov       = sd(coverage),
    median_cov   = median(coverage),
    min_cov      = min(coverage),
    max_cov      = max(coverage),
    n_pass       = sum(coverage >= 0.95),
    n_fail       = sum(coverage < 0.95),
    prop_pass    = mean(coverage >= 0.95),
    prop_fail    = mean(coverage < 0.95),
    .groups = "drop"
  )

fn_save_results(tab_cov_overall)
fn_save_results(tab_cov_by_treatment_reps)
fn_save_results(cov_by_scenario)
fn_save_results(tab_cov_scenario)
fn_save_results(tab_cov_by_treatment_scen)
```  

### Plots

```{r cov_scen_freqs}
janitor::tabyl(tab_cov_scenario$meets_95)
 # tab_cov_scenario$meets_95  n   percent
 #                     FALSE 91 0.6740741
 #                      TRUE 44 0.3259259

janitor::tabyl(tab_cov_scenario, Treatment, meets_95) |> 
  janitor::adorn_percentages() |> 
  janitor::adorn_pct_formatting() |> 
  janitor::adorn_ns()

 #       Treatment      FALSE       TRUE
 #                No treatment 77.8% (21) 22.2%  (6)
 #                  Top-coding 59.3% (16) 40.7% (11)
 #   Mean-preserved top-coding 63.0% (17) 37.0% (10)
 # Median-preserved top-coding 63.0% (17) 37.0% (10)
 #                  Truncation 74.1% (20) 25.9%  (7)
```

#### Zip plot  
```{r}
zip_data <- all_df_gamma |>
  filter(!is.na(est), !is.na(se)) |>
  mutate(
    z        = (est - true) / se,
    abs_z    = abs(z),
    ci_lower = est - 1.96 * se,
    ci_upper = est + 1.96 * se
  ) |>
  group_by(Treatment, N, Proportion, Magnitude) |>
  arrange(abs_z) |>
  mutate(frac_centile = row_number() / n() * 100) |>
  ungroup() |>
  mutate(cover_label = if_else(cover_ind == 1, "Covers", "Non-coverer"))

# Pick one scenario to demonstrate (e.g. worst coverage scenario)
# or loop over treatments as Morris does over methods
zip_plot <- zip_data |>
  filter(N == "5,000", Proportion == "0.10", Magnitude == 3) |>
  ggplot(aes(y = frac_centile, color = cover_label)) +
  geom_segment(aes(x = ci_lower, xend = ci_upper,
                   yend = frac_centile),
               alpha = 0.3, linewidth = 0.2) +
  geom_hline(yintercept = 95, linetype = "dashed", color = "goldenrod") +
  geom_vline(xintercept = 0, color = "black", linewidth = 0.4) +
  scale_color_manual(
    values = c("Covers" = "steelblue", "Non-coverer" = "#9b59b6"),
    name = NULL
  ) +
  facet_wrap(~ Treatment, nrow = 1,
             labeller = labeller(Treatment = label_wrap_gen(width = 15))) +
  labs(
    title = "Zip Plot: 95% CI Coverage by Treatment",
    subtitle = "Scenario: N=5,000, Prop=0.10, Magnitude=3 | Gold line = nominal 95%",
    x = "95% Confidence Interval",
    y = "Fractional centile of |z|"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    plot.title = element_text(face = "bold"),
    plot.title.position = "plot",
    strip.text = element_text(face = "bold", size = 8),
    legend.position = "bottom"
  )

zip_plot


ggsave(
  here::here(paste0("figures/gamma_zipplot_", dt, ".png")),
  zip_plot, width = 16, height = 6, dpi = 300
)

```
#### Lollipop

```{r}

# Attach scenario IDs (reuses scenario_key from lolly_setup)
cov_plot_data <- cov_by_scenario |>
  left_join(scenario_key, by = c("N", "Proportion", "Magnitude")) |>
  mutate(
    scenario_id = factor(scenario_id, levels = scenario_id_levels),
    Treatment   = factor(Treatment,   levels = treatment_order_3row),
    cov_flag    = if_else(coverage < 0.95, "Below 95%", "At/Above 95%"),
    cov_flag    = factor(cov_flag, levels = c("At/Above 95%", "Below 95%"))
  )

cov_colors <- c("At/Above 95%" = "#2ca02c", "Below 95%" = "#d62728")
cov_y_lower <- min(0.85, min(cov_plot_data$coverage, na.rm = TRUE) - 0.01)
cov_y_lims  <- c(cov_y_lower, 1.0)

# Coverage panel builder (segment runs from 0.95 to coverage, both coloured)
make_cov_panel <- function(data, show_x_axis, show_y_axis) {
  ggplot(data, aes(x = scenario_id, y = coverage)) +
    geom_hline(yintercept = 0.95, linetype = "dashed",
               color = "grey30", linewidth = 0.5) +
    geom_segment(
      aes(xend = scenario_id, y = 0.95, yend = coverage, color = cov_flag),
      linewidth = 0.5
    ) +
    geom_point(aes(color = cov_flag), size = 2.2) +
    scale_color_manual(name = "Coverage status", values = cov_colors) +
    scale_y_continuous(
      limits = cov_y_lims,
      labels = scales::percent_format(accuracy = 1),
      breaks = seq(0.85, 1.0, by = 0.05)
    ) +
    scale_x_discrete(breaks = scenario_id_levels,
                     limits = scenario_id_levels) +
    labs(y = if (show_y_axis) "Coverage" else "") +
    theme_minimal(base_size = 11) +
    theme(
      panel.grid.major.x  = element_blank(),
      panel.grid.minor    = element_blank(),
      legend.position     = "none",
      axis.text.x  = if (show_x_axis) element_text(size = 8) else element_blank(),
      axis.ticks.x = if (show_x_axis) element_line() else element_blank(),
      axis.title.x = element_blank(),
      axis.title.y = if (show_y_axis) element_text(size = 9) else element_blank(),
      axis.text.y  = element_text(size = 8)
    )
}

make_cov <- function(trt, show_x, show_y) {
  make_cov_panel(
    data        = cov_plot_data |> dplyr::filter(Treatment == trt),
    show_x_axis = show_x,
    show_y_axis = show_y
  ) + ggtitle(trt) +
    theme(plot.title = element_text(face = "bold", size = 10, hjust = 0.5))
}

p_c1 <- make_cov("No treatment",                show_x = FALSE, show_y = TRUE)
p_c2 <- make_cov("Mean-preserved top-coding",   show_x = FALSE, show_y = TRUE)
p_c3 <- make_cov("Median-preserved top-coding", show_x = FALSE, show_y = FALSE)
p_c4 <- make_cov("Top-coding",                  show_x = TRUE,  show_y = TRUE)
p_c5 <- make_cov("Truncation",                  show_x = TRUE,  show_y = FALSE)

# Shared legend
tmp_cov <- p_c1 +
  theme(legend.position = "bottom",
        legend.title = element_text(size = 9),
        legend.text  = element_text(size = 9))
shared_cov_legend <- gtable::gtable_filter(
  ggplot2::ggplotGrob(tmp_cov), "guide-box"
)

cov_patch <- (
    p_c1 + plot_spacer() +
    p_c2 + p_c3 +
    p_c4 + p_c5
  ) +
  plot_layout(nrow = 3, ncol = 2, byrow = TRUE)

cov_title    <- "Gamma Interaction: CI Coverage by Treatment and Scenario"
cov_subtitle <- "X-axis: scenario ID 1-27 (see companion table). Dashed line = nominal 95%."

x_label_cov <- cowplot::ggdraw() +
  cowplot::draw_label("Scenario ID", size = 10, hjust = 0.5)

plot_cov_3row <- cowplot::plot_grid(
  cowplot::plot_grid(
    cowplot::ggdraw() + cowplot::draw_label(cov_title,    fontface = "bold", size = 13, hjust = 0.5),
    cowplot::ggdraw() + cowplot::draw_label(cov_subtitle, size = 10, colour = "grey40", hjust = 0.5),
    ncol = 1, rel_heights = c(0.6, 0.4)
  ),
  cov_patch,
  cowplot::plot_grid(x_label_cov, shared_cov_legend,
                     ncol = 1, rel_heights = c(0.35, 0.65)),
  ncol = 1, rel_heights = c(0.10, 1, 0.15)
)

plot_cov_3row

ggsave(
  here::here(paste0("figures/gamma_coverage_lollipop_3row_", dt, ".png")),
  plot_cov_3row, width = 13, height = 13, dpi = 300
)
```

#### Heatmap  

```{r plot_cov_heat}

cov_min <- floor(min(tab_cov_scenario$coverage, na.rm = TRUE) * 100) / 100
cov_max <- ceiling(max(tab_cov_scenario$coverage, na.rm = TRUE) * 100) / 100

# Map 0.95 exactly to the colour breakpoint.
# values= must be rescaled to [0,1] relative to the data range.
rescale_95 <- (0.95 - cov_min) / (cov_max - cov_min)

plot_cov_heat2 <- tab_cov_scenario %>%
  left_join(scenario_key, by = c("N", "Proportion", "Magnitude")) %>%
  dplyr::mutate(
    scenario_id = factor(scenario_id, levels = 27:1),
    cov_label = paste0(
      scales::number(coverage * 100, accuracy = 0.1), "%",
      ifelse(coverage < 0.95, "*", "")
    )
  ) %>%
  ggplot(aes(x = Treatment, y = scenario_id, fill = coverage)) +
  geom_tile(color = "white", linewidth = 0.8) +
  geom_text(
    aes(
      label = cov_label,
      color = ifelse(coverage < 0.92 | coverage > 0.98, "light", "dark")
    ),
    size = 2.8
  ) +
  scale_color_manual(
    values = c("light" = "grey20", "dark" = "grey20"),
    guide  = "none"
  ) +
  scale_fill_gradientn(
    colours = c("#C7372F", "#f7c4c2", "#f7c4c2", "#a8d5a2", "#2ca02c"),
    values  = scales::rescale(
      c(cov_min,
        0.95 - (0.95 - cov_min) * 0.5,   # halfway between min and 0.95 = light red
        0.9499,                            # just below 0.95 = still light red
        0.95,                              # exactly 0.95 = light green (>=95 is green)
        cov_max),
      to = c(0, 1),
      from = c(cov_min, cov_max)
    ),
    limits = c(cov_min, cov_max),
    labels = scales::percent_format(accuracy = 1)
  ) +
  scale_x_discrete(labels = label_wrap_gen(width = 12)) +
  labs(
    title    = "Gamma Interaction: Coverage by Treatment and Scenario",
    subtitle = "Green >= 95% (nominal); red = undercoverage; * = below 95%",
    x        = NULL,
    y        = "Scenario ID",
    fill     = "Coverage"
  ) +
  theme_minimal(base_size = 10) +
  theme(
    axis.text.x         = element_text(angle = 30, hjust = 1, size = 9),
    axis.text.y         = element_text(size = 8),
    panel.grid          = element_blank(),
    plot.title          = element_text(face = "bold"),
    plot.title.position = "plot",
    legend.position     = "right"
  )

plot_cov_heat2

# Landscape dimensions (width > height)
ggsave(
  here::here(paste0("figures/gamma_coverage_heat2_", dt, ".png")),
  plot_cov_heat2, width = 16, height = 10, dpi = 300
)
```   

```{r}
# Build long-format performance table across treatments
perf_long <- cov_by_scenario |>
  left_join(
    all_df_gamma |>
      group_by(Treatment, N, Proportion, Magnitude) |>
      summarise(
        bias   = mean(bias, na.rm = TRUE),
        emp_se = sd(est, na.rm = TRUE),
        .groups = "drop"
      ),
    by = c("Treatment", "N", "Proportion", "Magnitude")
  ) |>
  pivot_longer(
    cols = c(bias, emp_se, coverage),
    names_to = "measure",
    values_to = "value"
  ) |>
  mutate(
    measure = factor(measure,
                     levels = c("bias", "emp_se", "coverage"),
                     labels = c("Bias", "Empirical SE", "Coverage")),
    ref_line = case_when(
      measure == "Bias"         ~ 0,
      measure == "Coverage"     ~ 0.95,
      measure == "Empirical SE" ~ NA_real_
    )
  )

lollipop_perf <- perf_long |>
  filter(N == "5,000") |>
  ggplot(aes(x = value, y = Treatment, color = Treatment)) +
  geom_vline(aes(xintercept = ref_line), linetype = "dashed",
             color = "grey40", na.rm = TRUE) +
  geom_segment(aes(x = ref_line, xend = value,
                   y = Treatment, yend = Treatment),
               na.rm = TRUE, linewidth = 0.6) +
  geom_point(size = 2) +
  facet_grid(measure ~ Proportion + Magnitude,
             scales = "free_x",
             labeller = labeller(
               Proportion = function(x) paste0("Prop=", x),
               Magnitude  = function(x) paste0("Mag=", x),
               measure    = label_value
             )) +
  scale_y_discrete(limits = rev(c(
  "No treatment",
  "Top-coding",
  "Mean-preserved top-coding",
  "Median-preserved top-coding",
  "Truncation"
))) +
  labs(
    title    = "Performance Measures by Treatment: N=5,000",
    subtitle = "Rows = performance measure; dashed line = reference value (0 for bias, 0.95 for coverage)",
    x        = NULL,
    y        = NULL
  ) +
  theme_minimal(base_size = 9) +
  theme(
    plot.title = element_text(face = "bold"),
    plot.title.position = "plot",
    strip.text = element_text(face = "bold", size = 7),
    legend.position = "none",
    axis.text.x = element_text(angle=90, hjust=1, vjust=0.5)
  )

lollipop_perf

ggsave(
  here::here(paste0("figures/gamma_lollipop_perf_", dt, ".png")),
  lollipop_perf, width = 16, height = 8, dpi = 300
)
```


3. Auto-generate sentences  
Summarize direction, magnitude, reliability per treatment using tables above  
```{r sentences, eval=FALSE}
sentences <- tab_consistency %>%
  mutate(
    dir = ifelse(as.numeric(avg_mean_bias) < 0, "underestimated", "overestimated"),
    abs_avg = abs(as.numeric(avg_mean_bias)),
    txt = glue::glue(
      "On average across {n_scen} scenarios, the {treatment} method {dir} ",
      "the Gamma interaction by {scales::number(abs_avg, accuracy = 0.0001)}. ",
      "Median scenario-mean bias was {med_mean_bias}. ",
      "{scales::percent(share_scen_under, accuracy = 0.1)} of scenarios had negative mean bias, ",
      "and {scales::percent(share_scen_under_majority, accuracy = 0.1)} showed majority underestimation. ",
      "Mean empirical SE was {mean_emp_se}, and mean coverage was {scales::percent(mean_cov, accuracy = 0.1)}."
    )
  ) %>%
  dplyr::pull(txt)

cat(paste0("- ", sentences, collapse = "\n"))
```   

## ATT descr  
```{r fn_att_descr}


# ---- ATT descriptives by treatment: estimates and bias ----

# Helper for clean number formatting
fmt <- function(x) scales::number(x, accuracy = 0.01, big.mark = ",")
fmt_pct <- function(x) scales::percent(x, accuracy = 0.1)


# Overall 
# --- Table 0: mean_est overall ------------------
att_est_overall <- all_df_att |>
  summarise(
    n_scen        = n(),
    est_mean   = mean(est, na.rm = TRUE),
    est_sd     = sd(est, na.rm = TRUE),
    est_median = median(est, na.rm = TRUE),
    est_mad    = mad(est, na.rm = TRUE),
    est_min    = min(est, na.rm = TRUE),
    est_max    = max(est, na.rm = TRUE),
    mean_true       = mean(true, na.rm = TRUE),  # should be ~158 for all
    .groups = "drop"
  )
fn_save_results(att_est_overall)

# --- Table 1: mean_est descriptives by treatment ---
att_est_by_treatment <- all_df_att |>
  group_by(Treatment) |>
  summarise(
    n_scen        = n(),
    est_mean   = mean(est, na.rm = TRUE),
    est_sd     = sd(est, na.rm = TRUE),
    est_median = median(est, na.rm = TRUE),
    est_mad    = mad(est, na.rm = TRUE),
    est_min    = min(est, na.rm = TRUE),
    est_max    = max(est, na.rm = TRUE),
    mean_true       = mean(true, na.rm = TRUE),  # should be ~158 for all
    .groups = "drop"
  )
fn_save_results(att_est_by_treatment)

# --- Table 1: mean_est descriptives by scenario ---
att_est_by_scenario <- all_df_att |>
  group_by(Treatment, N, Proportion, Magnitude) |>
  summarise(
    n_scen        = n(),
    est_mean   = mean(est, na.rm = TRUE),
    est_sd     = sd(est, na.rm = TRUE),
    est_median = median(est, na.rm = TRUE),
    est_mad    = mad(est, na.rm = TRUE),
    est_min    = min(est, na.rm = TRUE),
    est_max    = max(est, na.rm = TRUE),
    mean_true       = mean(true, na.rm = TRUE),  # should be ~158 for all
    .groups = "drop"
  )
fn_save_results(att_est_by_scenario)


# --- Table 2a: ATT bias overall descriptives --- 
att_bias_overall <- all_df_att |>
  summarise(
    n_scen          = n(),
    mean_bias       = mean(bias, na.rm = TRUE),
    sd_bias         = sd(bias, na.rm = TRUE),
    median_bias     = median(bias, na.rm = TRUE),
    mad_bias        = mad(bias, na.rm = TRUE),
    min_bias        = min(bias, na.rm = TRUE),
    max_bias        = max(bias, na.rm = TRUE),
    mean_abs_bias   = mean(abs_bias, na.rm = TRUE),
    median_abs_bias = median(abs_bias, na.rm = TRUE),
    n_neg_bias      = sum(bias < 0),
    prop_neg_bias   = mean(bias < 0)
  )

fn_save_results(att_bias_overall)

# --- Table 2: bias descriptives by treatment ---
att_bias_by_treatment <- all_df_att |>
  group_by(Treatment) |>
  summarise(
    n_scen          = n(),
    mean_bias       = mean(bias, na.rm = TRUE),
    sd_bias         = sd(bias, na.rm = TRUE),
    median_bias     = median(bias, na.rm = TRUE),
    mad_bias        = mad(bias, na.rm = TRUE),
    min_bias        = min(bias, na.rm = TRUE),
    max_bias        = max(bias, na.rm = TRUE),
    mean_abs_bias   = mean(abs_bias, na.rm = TRUE),
    median_abs_bias = median(abs_bias, na.rm = TRUE),
    n_neg_bias      = sum(bias < 0),
    prop_neg_bias   = mean(bias < 0),
    .groups = "drop"
  )

fn_save_results(att_bias_by_treatment)

att_bias_by_scenario <- all_df_att |>
  group_by(Treatment, N, Proportion, Magnitude) |>
  summarise(
    n_scen          = n(),
    mean_bias       = mean(bias, na.rm = TRUE),
    sd_bias         = sd(bias, na.rm = TRUE),
    median_bias     = median(bias, na.rm = TRUE),
    mad_bias        = mad(bias, na.rm = TRUE),
    min_bias        = min(bias, na.rm = TRUE),
    max_bias        = max(bias, na.rm = TRUE),
    mean_abs_bias   = mean(abs_bias, na.rm = TRUE),
    median_abs_bias = median(abs_bias, na.rm = TRUE),
    n_neg_bias      = sum(bias < 0),
    prop_neg_bias   = mean(bias < 0),
    .groups = "drop"
  )

fn_save_results(att_bias_by_scenario)

```  

```{r plot_att_est_bias}
# ================================================================
# ATT ESTIMATE: trends plot
# ================================================================
summ_att <- summ_grid |> 
  filter(model=="ATT") |> 
  select(-c(mean_model_se, rmse, coverage))

plot_att_est_trends <- ggplot(
  summ_att,
  aes(
    x     = Magnitude,
    y     = mean_est,
    color = Treatment
  )
) +
  geom_hline(
    aes(yintercept = mean_true),
    linetype = "dashed", color = "grey30", linewidth = 0.4
  ) +
  geom_jitter(
    width = 0.2,
    height = 0,
    size = 3,
    alpha = 0.7
  ) +
  facet_grid(
    N ~ Proportion,
    labeller = labeller(
      N         = function(x) paste0("N = ", x),
      Proportion = function(x) paste0("Prop. Extreme = ", x)
    )
  ) +
  scale_color_manual(
    name   = "Data Treatment",
    values = c(
      "No treatment"                = "#0072B2",
      "Top-coding"                  = "#E69F00",
      "Mean-preserved top-coding"   = "#009E73",
      "Median-preserved top-coding" = "#CC79A7",
      "Truncation"                  = "#D55E00"
    ),
    labels = label_wrap_gen(width = 20)   # wraps legend text
  ) +
  labs(
    title    = "ATT: Scenario-Level Estimates Across Magnitude of Extremes",
    subtitle = stringr::str_wrap(
      "Rows = N; Cols = proportion extreme; dashed line = zero bias; points show scenario-level bias",
      width = 90   # adjust to match your plot width
    ),
    x = "Magnitude level",
    y = "Bias (ATT scale)"
  ) +
  theme_minimal() +
  theme(
    legend.position  = "bottom",
    legend.title     = element_text(face = "bold"),
    plot.subtitle    = element_text(color = "grey40", size = 9)  # optional styling
  )

plot_att_est_trends
ggsave(here::here(paste0("figures/att_est_trends_", dt, ".png")),
       plot_att_est_trends, width = 11, height = 7, dpi = 300)


# ================================================================
# ATT BIAS: trends plot
# ================================================================

plot_att_bias_trends <- ggplot(
  summ_att,
  aes(
    x     = Magnitude,
    y     = bias,
    color = Treatment
  )
) +
  geom_hline(yintercept = 0, linetype = "dashed", color = "grey30", linewidth = 0.4) +
  geom_jitter(
    width  = 0.2,
    height = 0,
    size   = 3,
    alpha  = 0.7
  ) +
  facet_grid(
    N ~ Proportion,
    labeller = labeller(
      N         = function(x) paste0("N = ", x),
      Proportion = function(x) paste0("Prop. Extreme = ", x)
    )
  ) +
  scale_color_manual(
    name   = "Data Treatment",
    values = c(
      "No treatment"                = "#0072B2",
      "Top-coding"                  = "#E69F00",
      "Mean-preserved top-coding"   = "#009E73",
      "Median-preserved top-coding" = "#CC79A7",
      "Truncation"                  = "#D55E00"
    ),
    labels = label_wrap_gen(width = 20)   # wraps legend text
  ) +
  labs(
    title    = "ATT: Scenario-Level Bias Across Magnitude of Extremes",
    subtitle = stringr::str_wrap(
      "Rows = N; Cols = proportion extreme; dashed line = zero bias; points show scenario-level bias",
      width = 90   # adjust to match your plot width
    ),
    x = "Magnitude level",
    y = "Bias (ATT scale)"
  ) +
  theme_minimal() +
  theme(
    legend.position  = "bottom",
    legend.title     = element_text(face = "bold"),
    plot.subtitle    = element_text(color = "grey40", size = 9)  # optional styling
  )

plot_att_bias_trends
ggsave(here::here(paste0("figures/att_bias_trends_", dt, ".png")),
       plot_att_bias_trends, width = 11, height = 7, dpi = 300)

```




##4 FULL-FACTORIAL ANOVA (RQ answers)



```{r aov_bias}
# Type III ANOVA with Eta² and Partial Eta² for Gamma Bias

# A) factorial ANOVA on gamma bias (at rep-level, per meeting with Tsai)
# Load required packages
pacman::p_load(car, effectsize, dplyr, tibble, knitr, kableExtra)

# Ensure factors are properly set

# Set contrasts for Type III SS (m!)
options(contrasts = c("contr.sum", "contr.poly"))


# 1: Fit the model

model <- aov(
  bias ~ Treatment * N * Proportion * Magnitude, 
  data = all_df_gamma)


# Step 2: Type III Sum of Squares ANOVA Table
type3_anova <- car::Anova(model, type = "III")


# 3: Comb. table ===================================================
# Type III SS + Effect Sizes

# Extract Type III results
type3_df <- type3_anova %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Term") %>%
  filter(Term != "Residuals")

eta2_regular <- effectsize::eta_squared(type3_anova, partial=FALSE)
eta2_partial <- effectsize::eta_squared(type3_anova, partial=TRUE)

# Extract regular eta²
eta2_reg_df <- eta2_regular %>%
  as.data.frame() %>%
  select(Parameter, Eta2)

# Extract partial eta²
eta2_part_df <- eta2_partial %>%
  as.data.frame() %>%
  select(Parameter, Eta2_partial)

# Tried both of these below, came out the same.
# eta2_lsr <- lsr::etaSquared(model, type=3)
# eta2_descTools <- DescTools::EtaSq(model, type=3)

# Combine everything - simplified version (point estimates only)
combined_table <- type3_df %>%
  left_join(eta2_reg_df, by = c("Term" = "Parameter")) %>%
  left_join(eta2_part_df, by = c("Term" = "Parameter")) %>%
  mutate(
    `Sum Sq` = round(`Sum Sq`, 6),
    `F value` = round(`F value`, 2),
    `Pr(>F)` = format.pval(`Pr(>F)`, digits = 3, eps = 0.001),
    Eta2 = round(Eta2, 5),
    Eta2_partial = round(Eta2_partial, 5),
    # Add interpretation column (handle NAs for intercept)
    Interpretation = case_when(
      is.na(Eta2_partial) ~ "N/A",           # Handle NAs first
      Eta2_partial < 0.01 ~ "Trivial",
      Eta2_partial < 0.06 ~ "Small",
      Eta2_partial < 0.14 ~ "Medium",
      TRUE ~ "Large"
    )
  ) %>%
  select(Term, Df, `Sum Sq`, `F value`, `Pr(>F)`, Eta2, Eta2_partial, Interpretation) %>%
  arrange(desc(`F value`))

print(combined_table)

# 4: Export ===================================================
write.csv(combined_table, 
          here::here(paste0("results/aov_bias_type3_", dt, ".csv")),
          row.names = FALSE)


# id sig, large es =========================================
# Identify Significant Effects and Large Effect Sizes

significant_effects <- combined_table %>%
  filter(Term != "(Intercept)") %>%  # Exclude intercept
  filter(`Pr(>F)` < 0.001 | `Pr(>F)` == "<.001") %>%
  arrange(desc(Eta2_partial))

cat("\n=== SIGNIFICANT EFFECTS (p < .001) ===\n")
print(significant_effects)

large_effects <- combined_table %>%
  filter(Term != "(Intercept)") %>%  # Exclude intercept
  filter(Eta2_partial >= 0.01) %>%  # At least "small" effects
  arrange(desc(Eta2_partial))

cat("\n=== SMALL OR LARGER EFFECT SIZES (η²p ≥ .01) ===\n")
print(large_effects)

# 8: Summary stats ===========================================

# Exclude intercept for summary
combined_no_int <- combined_table %>% filter(Term != "(Intercept)")

cat("\n=== SUMMARY ===\n")
cat("Total effects tested:", nrow(combined_no_int), "\n")
cat("Significant at p < .001:", 
    sum(grepl("<.001", combined_no_int$`Pr(>F)`)), "\n")
cat("Significant at p < .05:", 
    sum(as.numeric(gsub("<.001", "0", combined_no_int$`Pr(>F)`)) < 0.05, na.rm = TRUE), "\n")
cat("Small+ effect sizes (η²p ≥ .01):", 
    sum(combined_no_int$Eta2_partial >= 0.01, na.rm = TRUE), "\n")
cat("Largest partial eta²:", 
    round(max(combined_no_int$Eta2_partial, na.rm = TRUE), 5), 
    "for", combined_no_int$Term[which.max(combined_no_int$Eta2_partial)], "\n")

# Summary interpretation
cat("\n=== INTERPRETATION ===\n")
cat("Mean bias across all conditions:", round(mean(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("SD of bias:", round(sd(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("Range of bias:", round(range(all_df_gamma$bias, na.rm = TRUE), 4), "\n")
cat("\nAll effect sizes are negligible (< .01), indicating that treatment method,\n")
cat("sample size, proportion of extremes, and magnitude have minimal practical\n")
cat("impact on bias. The vast majority of variance in bias (>99%) is due to\n")
cat("random sampling variability, not systematic differences between conditions.\n")

# Opt: Post hocs ==============================================
# OPTIONAL: Post-hoc tests for significant main effects

# library(emmeans)
# 
# # Only run post-hoc if effect is significant AND at least small
# sig_main_effects <- significant_effects %>%
#   filter(!grepl(":", Term)) %>%  # Only main effects, not interactions
#   filter(Eta2_partial >= 0.001)  # At least 0.1% variance explained
# 
# if ("treatment" %in% sig_main_effects$Term) {
#   cat("\n=== POST-HOC: Pairwise Comparisons for Treatment ===\n")
#   emm_treatment <- emmeans(model, ~ treatment)
#   pairs_treatment <- pairs(emm_treatment, adjust = "tukey")
#   print(pairs_treatment)
#   
#   # Save post-hoc results
#   write.csv(as.data.frame(pairs_treatment),
#             file = paste0("results/posthoc_treatment_", dt, ".csv"),
#             row.names = FALSE)
# }
# 
# if ("prop_extreme" %in% sig_main_effects$Term) {
#   cat("\n=== POST-HOC: Pairwise Comparisons for Proportion Extreme ===\n")
#   emm_prop <- emmeans(model, ~ prop_extreme)
#   pairs_prop <- pairs(emm_prop, adjust = "tukey")
#   print(pairs_prop)
#   
#   write.csv(as.data.frame(pairs_prop),
#             file = paste0("results/posthoc_prop_extreme_", dt, ".csv"),
#             row.names = FALSE)
# }
# 
# if ("magnitude_level" %in% sig_main_effects$Term) {
#   cat("\n=== POST-HOC: Pairwise Comparisons for Magnitude Level ===\n")
#   emm_mag <- emmeans(model, ~ magnitude_level)
#   pairs_mag <- pairs(emm_mag, adjust = "tukey")
#   print(pairs_mag)
#   
#   write.csv(as.data.frame(pairs_mag),
#             file = paste0("results/posthoc_magnitude_", dt, ".csv"),
#             row.names = FALSE)
# }
# 
# # Opt: Check assumptions =====================================
# # OPTIONAL: Check ANOVA assumptions
# 
# cat("\n=== CHECKING ANOVA ASSUMPTIONS ===\n")
# 
# # 1. Normality of residuals (sample if too large)
# if (nrow(all_df_gamma) > 5000) {
#   shapiro_test <- shapiro.test(sample(residuals(model), 5000))
#   cat("Shapiro-Wilk test for normality (n=5000 sample): W =", 
#       round(shapiro_test$statistic, 4), 
#       ", p =", format.pval(shapiro_test$p.value), "\n")
# } else {
#   shapiro_test <- shapiro.test(residuals(model))
#   cat("Shapiro-Wilk test for normality: W =", 
#       round(shapiro_test$statistic, 4), 
#       ", p =", format.pval(shapiro_test$p.value), "\n")
# }
# 
# # 2. Homogeneity of variance (Levene's test)
# levene_test <- car::leveneTest(bias ~ treatment * n * prop_extreme * magnitude_level, 
#                                data = all_df_gamma)
# cat("Levene's test for homogeneity: F =", round(levene_test$`F value`[1], 4),
#     ", p =", format.pval(levene_test$`Pr(>F)`[1]), "\n")
# 
# # 3. Diagnostic plots
# png(paste0("figures/anova_diagnostics_", dt, ".png"), 
#     width = 10, height = 8, units = "in", res = 300)
# par(mfrow = c(2, 2))
# plot(model)
# dev.off()

# cat("Diagnostic plots saved to figures/anova_diagnostics_", dt, ".png\n")

# Plot significant interactions: 
# --- Shared theme and color scale for both plots ---
trt_colors <- c(
  "No treatment"                = "#0072B2",
  "Top-coding"                  = "#E69F00",
  "Mean-preserved top-coding"   = "#009E73",
  "Median-preserved top-coding" = "#CC79A7",
  "Truncation"                  = "#D55E00"
)

base_theme <- theme_minimal(base_size = 11) +
  theme(
    legend.position     = "bottom",
    legend.title        = element_text(face = "bold"),
    strip.text          = element_text(face = "bold"),
    plot.title          = element_text(face = "bold"),
    plot.title.position = "plot",
    plot.subtitle       = element_text(color = "grey40", size = 9),
    panel.grid.minor    = element_blank()
  )

# ---- Shared mean + SE summaries ----
means_trt_nobs <- all_df_gamma |>
  group_by(Treatment, N) |>
  summarise(
    mean_bias = mean(bias, na.rm = TRUE),
    se_bias   = sd(bias, na.rm = TRUE) / sqrt(n()),
    .groups   = "drop"
  )

means_trt_prop <- all_df_gamma |>
  group_by(Treatment, Proportion) |>
  summarise(
    mean_bias = mean(bias, na.rm = TRUE),
    se_bias   = sd(bias, na.rm = TRUE) / sqrt(n()),
    .groups   = "drop"
  )

# ================================================================
# MEANS-ONLY INTERACTION PLOTS
# ================================================================

# ---- Means-only: faceted by treatment ----

plot_means_trt_nobs_facet <- means_trt_nobs |>
  ggplot(aes(x = N, y = mean_bias, group = 1)) +
  geom_hline(yintercept = 0, linetype = "dashed",
             color = "grey30", linewidth = 0.4) +
  geom_line(linewidth = 0.9, color = "steelblue") +
  geom_errorbar(
    aes(ymin = mean_bias - 1.96*se_bias,
        ymax = mean_bias + 1.96*se_bias),
    width = 0.15, linewidth = 0.6, color = "steelblue"
  ) +
  geom_point(size = 3.5, shape = 18, color = "steelblue") +
  facet_wrap(~ Treatment, nrow = 1,
             labeller = labeller(Treatment = label_wrap_gen(width = 15))) +
  labs(
    title    = "Gamma Interaction Bias: Treatment × Sample Size",
    subtitle = expression(paste(
      "Type III F(8) = 3.50, p < .001, ", eta[p]^2,
      " = .0004 (negligible). Means ± 95% CI.")),
    x = "Sample size (N obs)",
    y = "Mean bias"
  ) +
  base_theme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

plot_means_trt_prop_facet <- means_trt_prop |>
  ggplot(aes(x = Proportion, y = mean_bias, group = 1)) +
  geom_hline(yintercept = 0, linetype = "dashed",
             color = "grey30", linewidth = 0.4) +
  geom_line(linewidth = 0.9, color = "steelblue") +
  geom_errorbar(
    aes(ymin = mean_bias - 1.96*se_bias,
        ymax = mean_bias + 1.96*se_bias),
    width = 0.15, linewidth = 0.6, color = "steelblue"
  ) +
  geom_point(size = 3.5, shape = 18, color = "steelblue") +
  facet_wrap(~ Treatment, nrow = 1,
             labeller = labeller(Treatment = label_wrap_gen(width = 15))) +
  labs(
    title    = "Gamma Interaction Bias: Treatment × Proportion Extreme",
    subtitle = expression(paste(
      "Type III F(8) = 22.52, p < .001, ", eta[p]^2,
      " = .0027 (negligible). Means ± 95% CI.")),
    x = "Proportion of extreme values",
    y = "Mean bias"
  ) +
  base_theme +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

plot_means_trt_nobs_facet
plot_means_trt_prop_facet

ggsave(here::here(paste0("figures/anova_means_trt_nobs_facet_", dt, ".png")),
       plot_means_trt_nobs_facet, width = 13, height = 5, dpi = 300)
ggsave(here::here(paste0("figures/anova_means_trt_prop_facet_", dt, ".png")),
       plot_means_trt_prop_facet, width = 13, height = 5, dpi = 300)
```  



```{r bias_es}
# Plot partial eta² for significant effects
# plot pes ===================================================
# Step 9: Visualize Effect Sizes (CORRECTED)

library(ggplot2)

# Need to go back to BEFORE formatting p-values
plot_data <- type3_df %>%
  left_join(eta2_reg_df, by = c("Term" = "Parameter")) %>%
  filter(Term != "(Intercept)") %>%
  filter(`Pr(>F)` < 0.05) %>%  # Use numeric p-values BEFORE formatting
  mutate(
    Term = reorder(Term, Eta2),
    Significant = case_when(
      `Pr(>F)` < 0.001 ~ "p < .001",
      `Pr(>F)` < 0.01 ~ "p < .01",
      `Pr(>F)` < 0.05 ~ "p < .05",
      TRUE ~ "ns"
    )
  )

library(patchwork)  # For combining plots

# Zoomed-in version 
p_zoomed <- ggplot(
  plot_data, aes(x = Eta2, y = Term, fill = Significant)) +
  geom_col() +
  scale_fill_manual(
    values = c("p < .001" = "steelblue", 
               "p < .01" = "cornflowerblue",
               "p < .05" = "lightblue"),
    name = "Significance"
  ) +
  labs(
    title = "A) Zoomed View",
    x = "η²",
    y = "Effect"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

# Full scale version (shows context)
p_full <- ggplot(
  plot_data, aes(x = Eta2, y = Term, fill = Significant)) +
  geom_col() +
  geom_vline(
    xintercept = 0.01, linetype = "dashed", color = "red", alpha = 0.7) +
  geom_vline(
    xintercept = 0.06, linetype = "dashed", color = "orange", alpha = 0.7) +
  geom_vline(
    xintercept = 0.14, linetype = "dashed", color = "green", alpha = 0.7) +
  annotate(
    "text", x = 0.01, y = 0.3, label = "Small", size = 3, color = "red",
    vjust = 1, angle = 0) +
  annotate(
    "text", x = 0.06, y = 0.3, label = "Med", size = 3, color = "orange",
    vjust = 1, angle = 0) +
  annotate(
    "text", x = 0.14, y = 0.3, label = "Large", size = 3, color = "green",
    vjust = 1, angle = 0) +
  scale_fill_manual(
    values = c("p < .001" = "steelblue", 
               "p < .01" = "cornflowerblue",
               "p < .05" = "lightblue"),
    name = "Significance"
  ) +
  scale_x_continuous(
    limits = c(0, 0.15),
    breaks = seq(0, 0.15, 0.03)
  ) +
  labs(
    title = "B) Full Scale (with benchmarks)",
    x = "η²",
    y = NULL
  ) +
  theme_minimal() +
  theme(
    legend.position    = "bottom",
    legend.justification = "center",
    axis.text.y = element_blank()
  )

# Combine side by side
p_zoomed <- p_zoomed + theme(legend.position = "none")
p_full   <- p_full   + theme(legend.position = "bottom", legend.justification = "center")

# Extract legend from p_full
legend <- cowplot::get_legend(
  p_full + theme(legend.position = "bottom", legend.justification = "center")
)

# Strip legends from both plots
p_zoomed2 <- p_zoomed + theme(legend.position = "none")
p_full2   <- p_full   + theme(legend.position = "none")

# Combine plots
p_row <- cowplot::plot_grid(p_zoomed2, p_full2, nrow = 1)

# Stack with title and legend
title <- cowplot::ggdraw() +
  cowplot::draw_label(
    "Eta-Squared for Significant Effects: Gamma Model Bias",
    fontface = "bold", size = 14)
subtitle <- cowplot::ggdraw() +
  cowplot::draw_label(
    "All effects are trivial - even the largest (0.003) is far below the 'small' benchmark (0.01)",
    size = 11, colour = "gray30")

p_combined <- cowplot::plot_grid(
  title, subtitle, p_row, legend,
  ncol = 1,
  rel_heights = c(0.08, 0.06, 1, 0.1)
)

print(p_combined)


ggsave(here::here(paste0("figures/effect_sizes_combined_", dt, ".png")),
       p_combined, width = 14, height = 6, dpi = 300)

ggsave(here::here(paste0("figures/effect_sizes_", dt, ".png")),
       p_effect_sizes, width = 10, height = 6, dpi = 300)


```    



```{r aov_att_absbias}
# D) Do anova on ATT absolute bias, not bias, at the replicate level.
# Type III ANOVA with Eta² and Partial Eta² for Gamma Bias

# A) factorial ANOVA on gamma bias (at rep-level, per meeting with Tsai)

# Set contrasts for Type III SS (m!)
all_df_att <- all_df_att |> 
  rename(c(
    "Treatment" = Treatment,
    "Proportion" = Proportion,
    "Magnitude" = Magnitude,
    "N" = N))
options(contrasts = c("contr.sum", "contr.poly"))

# 1: Fit the model

model_att <- aov(
  abs_bias ~ Treatment * N * Proportion * Magnitude, 
  data = all_df_att)


# Step 2: Type III Sum of Squares ANOVA Table
type3_anova_att <- car::Anova(model_att, type = "III")


# 3: Comb. table ===================================================
# Type III SS + Effect Sizes

# Extract Type III results
type3_df_att <- type3_anova_att %>%
  as.data.frame() %>%
  tibble::rownames_to_column("Term") %>%
  filter(Term != "Residuals")

eta2_regular_att <- effectsize::eta_squared(type3_anova_att, partial=FALSE)
eta2_partial_att <- effectsize::eta_squared(type3_anova_att, partial=TRUE)

# Extract regular eta²
eta2_reg_df_att <- eta2_regular_att %>%
  as.data.frame() %>%
  select(Parameter, Eta2)

# Extract partial eta²
eta2_part_df_att <- eta2_partial_att %>%
  as.data.frame() %>%
  select(Parameter, Eta2_partial)

# Combine everything - simplified version (point estimates only)
options(scipen=999)
combined_table_att <- type3_df_att %>%
  left_join(eta2_reg_df_att, by = c("Term" = "Parameter")) %>%
  left_join(eta2_part_df_att, by = c("Term" = "Parameter")) %>%
  mutate(
    `Sum Sq` = round(`Sum Sq`, 6),
    `F value` = round(`F value`, 2),
    `Pr(>F)` = format.pval(`Pr(>F)`, digits = 3, eps = 0.001),
    Eta2 = round(Eta2, 5),
    Eta2_partial = round(Eta2_partial, 5),
    # Add interpretation column (handle NAs for intercept)
    Interp_pes = case_when(
      is.na(Eta2_partial) ~ "N/A",           # Handle NAs first
      Eta2_partial < 0.01 ~ "Negligible",
      Eta2_partial < 0.06 ~ "Small",
      Eta2_partial < 0.14 ~ "Medium",
      TRUE ~ "Large"
    ),
    Interp_es = case_when(
      is.na(Eta2) ~ "N/A",           # Handle NAs first
      Eta2 < 0.01 ~ "Negligible",
      Eta2 < 0.06 ~ "Small",
      Eta2 < 0.14 ~ "Medium",
      TRUE ~ "Large")
  ) %>%
  select(Term, Df, `Sum Sq`, `F value`, `Pr(>F)`, Eta2, Interp_es, Eta2_partial, Interp_pes)  %>%
  arrange(desc(`F value`))

print(combined_table_att)

# 4: Export ===================================================
# avoid .csv having scientific notation: 
combined_table_att_export <- combined_table_att |>
  mutate(
    `Sum Sq`     = formatC(`Sum Sq`,     format = "f", digits = 6, big.mark = ","),
    `F value`    = formatC(`F value`,    format = "f", digits = 2),
    Eta2         = formatC(Eta2,         format = "f", digits = 5),
    Eta2_partial = formatC(Eta2_partial, format = "f", digits = 5)
  )

write.csv(combined_table_att_export,
          here::here(paste0("results/aov_att_type3_", dt, ".csv")),
          row.names = FALSE)
```

```{r att_anova_plot}
# Build plot data from ATT ANOVA results
# Use the numeric versions of columns BEFORE any formatting

plot_data_att <- type3_df_att |>
  left_join(eta2_reg_df_att, by = c("Term" = "Parameter")) |>
  filter(Term != "(Intercept)") |>
  filter(`Pr(>F)` < 0.05) |>
  mutate(
    Term = reorder(Term, Eta2),
    Significant = case_when(
      `Pr(>F)` < 0.001 ~ "p < .001",
      `Pr(>F)` < 0.01  ~ "p < .01",
      `Pr(>F)` < 0.05  ~ "p < .05",
      TRUE             ~ "ns"
    )
  )

n_terms <- nrow(plot_data_att)

p_zoomed_att <- ggplot(
  plot_data_att, aes(x = Eta2, y = Term, fill = Significant)) +
  geom_col() +
  scale_fill_manual(
    values = c("p < .001" = "steelblue",
               "p < .01"  = "cornflowerblue",
               "p < .05"  = "lightblue"),
    name = "Significance"
  ) +
  scale_x_continuous(
    limits = c(0, 0.25),
    breaks = seq(0, 0.25, 0.05)
  ) +
  labs(
    title = "A) Zoomed View",
    x     = "η²",
    y     = "Effect"
  ) +
  theme_minimal() +
  theme(legend.position = "none")

p_full_att <- ggplot(
  plot_data_att, aes(x = Eta2, y = Term, fill = Significant)) +
  geom_col() +
  geom_vline(xintercept = 0.01, linetype = "dashed", color = "red",     alpha = 0.7) +
  geom_vline(xintercept = 0.06, linetype = "dashed", color = "orange",  alpha = 0.7) +
  geom_vline(xintercept = 0.14, linetype = "dashed", color = "#1a7a1a", alpha = 0.7) +
  annotate("text", x = 0.01, y = 1, label = "Small", size = 3, color = "red",     hjust = -0.1, vjust = -0.3) +
  annotate("text", x = 0.06, y = 1, label = "Med",   size = 3, color = "orange",  hjust = -0.1, vjust = -0.3) +
  annotate("text", x = 0.14, y = 1, label = "Large", size = 3, color = "#1a7a1a", hjust = -0.1, vjust = -0.3) +
  scale_fill_manual(
    values = c("p < .001" = "steelblue",
               "p < .01"  = "cornflowerblue",
               "p < .05"  = "lightblue"),
    name = "Significance"
  ) +
  scale_x_continuous(
    limits = c(0, 0.25),
    breaks = seq(0, 0.25, 0.05)
  ) +
  labs(
    title    = "Eta-Squared for Significant Effects: ATT Absolute Bias",
    subtitle = "Treatment has the largest effect (η² = 0.222, Large); all effects significant at p < .001",
    x        = "η²",
    y        = "Effect"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom",
        plot.title = element_text(face="bold"),
        plot.title.position = "plot")

print(p_full_att)

ggsave(
  here::here(paste0("figures/effect_sizes_att_absbias_", dt, ".png")),
  p_full_att, width = 10, height = 7, dpi = 300
)

#library(patchwork)
#p_combined_att <- p_zoomed_att + p_full_att +
  # plot_annotation(
  #   title    = "Eta-Squared for Significant Effects: ATT Absolute Bias",
  #   subtitle = "Treatment has the largest effect (η² = 0.222, Large); all effects significant at p < .001"
  # ) *
  # theme(
  #   plot.title    = element_text(face = "bold", size = 14),
  #   plot.subtitle = element_text(size = 11, color = "gray30")
  # )

# print(p_full_att)
# 
# ggsave(
#   here::here(paste0("figures/effect_sizes_att_absbias_combined_", dt, ".png")),
#   p_combined_att, width = 14, height = 7, dpi = 300
# )  

```  

```{r}
# Compute mean absolute bias for each cell of the 4-way interaction
foursway_att <- all_df_att |>
  group_by(Treatment, N, Proportion, Magnitude) |>
  summarise(
    mean_abs_bias = mean(abs_bias, na.rm = TRUE),
    .groups = "drop"
  ) 

pd <- position_dodge(width=0.3) 

plot_4way_att <- ggplot(
  foursway_att,
  aes(x = Magnitude, y = mean_abs_bias, color = Treatment, group = Treatment)
) +
  # geom_line(linewidth = 0.8, position = pd, alpha = 0.6) +
  geom_point(size = 2, position = pd) +
  facet_grid(
    N ~ Proportion,
    labeller = labeller(
      N          = function(x) paste0("N = ", x),
      Proportion = function(x) paste0("Prop = ", x)
    )
  ) +
  scale_color_manual(
    name   = "Treatment",
    values = c(
      "No treatment"                = "#0072B2",
      "Top-coding"                  = "#E69F00",
      "Mean-preserved top-coding"   = "#009E73",
      "Median-preserved top-coding" = "#CC79A7",
      "Truncation"                  = "#D55E00"
    )
  ) +
  guides(color = guide_legend(nrow=2))+
  labs(
    title    = "Four-Way Interaction: ATT Absolute Bias",
    subtitle = "Mean absolute bias by treatment, magnitude, proportion of extremes, and sample size",
    x        = "Magnitude level",
    y        = "Mean absolute bias"
  ) +
  theme_minimal(base_size = 11) +
  theme(
    legend.position     = "bottom",
    strip.text          = element_text(face = "bold"),
    plot.title          = element_text(face = "bold"),
    plot.title.position = "plot"
  )

plot_4way_att

ggsave(
  here::here(paste0("figures/att_absbias_4way_interaction_", dt, ".png")),
  plot_4way_att, width = 12, height = 9, dpi = 300
)

```






