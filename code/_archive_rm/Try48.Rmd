---
title: "Untitled"
author: "Felix"
date: "2/2/2026"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r pkgs}
pacman::p_load(
  broom,
  dplyr,
  effectsize,
  forcats,
  furrr,
  ggforce,
  ggplot2,
  ggrepel,
  glue,
  gt,
  gtsummary,
  here,
  lubridate,
  MASS,
  purrr,
  readr,
  scales,
  tibble,
  tidyr)

conflicted::conflicts_prefer(
  dplyr::select(),
  dplyr::filter()
)

dt <- lubridate::today()
dir.create("results", showWarnings = FALSE)
dir.create("figures", showWarnings = FALSE)

```


#0) ONE SOURCE OF TRUTH: DGP COEFFICIENTS

```{r helpers}
COEF <- list(
  p1 = list(b0 = 0.0, post = 0.2, tx = -0.2, int = 0.0,
            female = 1.2, hisp = -0.8, zpcs = -0.2),
  p2 = list(b0 = 7.0, post = 0.2, tx =  0.2, int = 0.0,
            female = 0.4, hisp = -0.2, zpcs = -0.4)
)

# --- helper: log-uniform draw for extremes ---
rlogunif <- function(n, min_val, max_val) {
  if (n <= 0) return(numeric(0))
  exp(runif(n, log(min_val), log(max_val)))
}

# --- helper: extreme value ranges ---
extreme_range <- function(mag_level) {
  switch(as.character(mag_level),
         "1" = c(5e4, 1e6),
         "2" = c(5e4, 2e6),
         "3" = c(5e4, 3e6),
         stop("Invalid magnitude_level"))
}

```

#1) DGP: two-part Gamma with extremes

```{r sim}
simulate_panel_data <- function(
  n, magnitude_level, prop_extreme = 0.01,
  p_treated = 0.5, sigma_u = 0.5, rho = 0.5,
  gamma_shape = 3,
  COEF
) {
  T <- 2; N <- n * T
  ids <- rep(1:n, each = T)
  ind_post <- rep(0:1, times = n)

  # covariates
  ind_tx_i     <- rbinom(n, 1, p_treated)
  ind_female_i <- rbinom(n, 1, 0.5)
  HISPANX_i    <- rbinom(n, 1, 0.2)
  #INSCOV_i     <- sample(1:3, n, replace = TRUE)

  ind_tx     <- rep(ind_tx_i, each = T)
  ind_female <- rep(ind_female_i, each = T)
  HISPANX    <- rep(HISPANX_i, each = T)
  #INSCOV     <- factor(rep(INSCOV_i, each = T))

  # PCS42 with correlation (keep your approach)
  Sigma <- matrix(c(1, rho, rho, 1), 2, 2)
  pcs   <- MASS::mvrnorm(n, mu = c(50, 50), Sigma = Sigma)
  PCS42 <- as.vector(t(pcs))
  zPCS  <- (PCS42 - 50) / 10  # standardized PCS42

  # random intercept (kept for fidelity; not used in lp by design)
  u_i <- rnorm(n, 0, sigma_u)
  u   <- u_i[ids]

  # Part 1: logistic >0 (use COEF)
  lp_cov <- COEF$p1$b0 +
    COEF$p1$post   * ind_post +
    COEF$p1$tx     * ind_tx +
    COEF$p1$int    * (ind_post * ind_tx) +
    COEF$p1$female * ind_female +
    COEF$p1$hisp   * HISPANX +
    COEF$p1$zpcs   * zPCS

  pr_pos  <- plogis(lp_cov)
  ind_gt0 <- rbinom(N, 1, pr_pos)

  # Part 2: Gamma for positives (use COEF)
  lp_cont <- COEF$p2$b0 +
    COEF$p2$post   * ind_post +
    COEF$p2$tx     * ind_tx +
    COEF$p2$int    * (ind_post * ind_tx) +
    COEF$p2$female * ind_female +
    COEF$p2$hisp   * HISPANX +
    COEF$p2$zpcs   * zPCS

  mu <- exp(lp_cont)
  shape <- gamma_shape
  scale <- mu / shape

  TOTEXPYY <- rep(0, N)
  TOTEXPYY[ind_gt0 == 1] <- rgamma(sum(ind_gt0),
                                   shape = shape,
                                   scale = scale[ind_gt0 == 1])

  # inject extremes
  K_ext <- rbinom(1, N, prop_extreme)
  if (K_ext > 0) {
    rng <- extreme_range(magnitude_level)
    idx_ext <- sample.int(N, size = K_ext, replace = FALSE)
    TOTEXPYY[idx_ext] <- rlogunif(K_ext, rng[1], rng[2])
  } else idx_ext <- integer(0)

  tibble(
    DUPERSID = factor(ids),
    ind_post, ind_tx, ind_female, HISPANX, PCS42, zPCS, #INSCOV,
    ind_gt0 = ind_gt0,
    TOTEXPYY = TOTEXPYY,
    extreme_flag = as.integer(seq_len(N) %in% idx_ext),
    magnitude_level, prop_extreme
  )
}

```


#2) Treatments for extreme values (UPDATED)
# - mean/median preserved uses values > q95 only
# - truncation removes rows (not NA)

```{r treatments}
treat_extremes_df <- function(dat, method = "raw") {
  if (method == "raw") return(dat)

  q95 <- quantile(dat$TOTEXPYY, 0.95, na.rm = TRUE)

  if (method == "topcode") {
    dat$TOTEXPYY <- pmin(dat$TOTEXPYY, q95)
    return(dat)
  }

  if (method == "mean_adj") {
    m <- mean(dat$TOTEXPYY[dat$TOTEXPYY > q95], na.rm = TRUE)
    dat$TOTEXPYY[dat$TOTEXPYY > q95] <- m
    return(dat)
  }

  if (method == "median_adj") {
    m <- median(dat$TOTEXPYY[dat$TOTEXPYY > q95], na.rm = TRUE)
    dat$TOTEXPYY[dat$TOTEXPYY > q95] <- m
    return(dat)
  }

  if (method == "truncate") {
    dat <- dat %>% filter(TOTEXPYY <= q95)
    return(dat)
  }

  stop("Unknown treatment method")
}

```

#3) Safe Gamma fit wrapper
# UPDATED: now returns list(fit, error) instead of fit/NULL
# - captures warning AND error messages for failure logging

```{r safe_gamma}
safe_gamma_fit <- function(dat) {
  dat2 <- dat %>% filter(ind_gt0 == 1, is.finite(TOTEXPYY), TOTEXPYY > 0)
  if (nrow(dat2) < 10) return(list(fit = NULL, error = "too few rows"))

  tryCatch({
    fit <- glm(
      TOTEXPYY ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
      data    = dat2,
      family  = Gamma(link = "log"),
      control = glm.control(maxit = 100, epsilon = 1e-8)
    )
    list(fit = fit, error = NA_character_)
  }, warning = function(w) {
    list(fit = NULL, error = paste("WARNING:", conditionMessage(w)))
  }, error = function(e) {
    list(fit = NULL, error = paste("ERROR:", conditionMessage(e)))
  })
}

```

#3b) Effect size helper:
```{r es_helper}
compute_sd_ref <- function(dat, ref = c("control_pre", "pooled_pre", "control_all")) {

  if (missing(dat) || is.null(dat)) {
    stop("compute_sd_ref(): you must pass a data.frame/tibble as 'dat' (e.g., compute_sd_ref(dat, ref='control_pre')).")
  }

  ref <- match.arg(ref)

  dref <- switch(
    ref,
    control_pre = dat %>% dplyr::filter(ind_tx == 0, ind_post == 0),
    pooled_pre  = dat %>% dplyr::filter(ind_post == 0),
    control_all = dat %>% dplyr::filter(ind_tx == 0)
  )

  sd_ref <- sd(dref$TOTEXPYY, na.rm = TRUE)

  # guard against degenerate / invalid SD
  if (!is.finite(sd_ref) || sd_ref <= 0) return(NA_real_)
  sd_ref
}

```

#4) ATT computation (RQ4): Estimated + TRUE using same COEF
```{r att}
compute_ATT_hat <- function(dat, fit_logit, fit_gamma) {

  treated_post <- dat %>% filter(ind_tx == 1, ind_post == 1)
  if (nrow(treated_post) == 0) return(NA_real_)

  treated_cf <- treated_post %>% mutate(ind_tx = 0)

  # Part 1: Pr(Y>0)
  p_obs <- predict(fit_logit, newdata = treated_post, type = "response")
  p_cf  <- predict(fit_logit, newdata = treated_cf,   type = "response")

  # Part 2: E[Y|Y>0] (Gamma log link; response is on original scale)
  mu_obs <- predict(fit_gamma, newdata = treated_post, type = "response")
  mu_cf  <- predict(fit_gamma, newdata = treated_cf,   type = "response")

  mean(p_obs * mu_obs - p_cf * mu_cf)
}

compute_true_ATT <- function(dat, COEF) {

  treated_post <- dat %>% filter(ind_tx == 1, ind_post == 1)
  if (nrow(treated_post) == 0) return(NA_real_)

  treated_cf <- treated_post %>% mutate(ind_tx = 0)

  # TRUE Part 1
  lp1_obs <- COEF$p1$b0 +
    COEF$p1$post   * treated_post$ind_post +
    COEF$p1$tx     * treated_post$ind_tx +
    COEF$p1$int    * (treated_post$ind_post * treated_post$ind_tx) +
    COEF$p1$female * treated_post$ind_female +
    COEF$p1$hisp   * treated_post$HISPANX +
    COEF$p1$zpcs   * treated_post$zPCS
  p_obs <- plogis(lp1_obs)

  lp1_cf <- COEF$p1$b0 +
    COEF$p1$post   * treated_cf$ind_post +
    COEF$p1$tx     * treated_cf$ind_tx +
    COEF$p1$int    * (treated_cf$ind_post * treated_cf$ind_tx) +
    COEF$p1$female * treated_cf$ind_female +
    COEF$p1$hisp   * treated_cf$HISPANX +
    COEF$p1$zpcs   * treated_cf$zPCS
  p_cf <- plogis(lp1_cf)

  # TRUE Part 2
  lp2_obs <- COEF$p2$b0 +
    COEF$p2$post   * treated_post$ind_post +
    COEF$p2$tx     * treated_post$ind_tx +
    COEF$p2$int    * (treated_post$ind_post * treated_post$ind_tx) +
    COEF$p2$female * treated_post$ind_female +
    COEF$p2$hisp   * treated_post$HISPANX +
    COEF$p2$zpcs   * treated_post$zPCS
  mu_obs <- exp(lp2_obs)

  lp2_cf <- COEF$p2$b0 +
    COEF$p2$post   * treated_cf$ind_post +
    COEF$p2$tx     * treated_cf$ind_tx +
    COEF$p2$int    * (treated_cf$ind_post * treated_cf$ind_tx) +
    COEF$p2$female * treated_cf$ind_female +
    COEF$p2$hisp   * treated_cf$HISPANX +
    COEF$p2$zpcs   * treated_cf$zPCS
  mu_cf <- exp(lp2_cf)

  mean(p_obs * mu_obs - p_cf * mu_cf)
}

```


#5) One replication under one scenario (UPDATED)
- uses zPCS in models
- returns interaction estimates + ATT outputs
- adds ATT effect size (d_est, d_true, d_bias) using baseline SD
- UPDATED: failure logging for both logistic and gamma models

```{r run_one}
run_one <- function(n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF,
                    es_ref = "control_pre") {

  dat <- simulate_panel_data(
    n = n,
    magnitude_level = magnitude_level,
    prop_extreme = prop_extreme,
    gamma_shape = gamma_shape,
    COEF = COEF
  )

  # Apply treatment at the DATAFRAME level
  dat <- treat_extremes_df(dat, treatment)

  # --- Logistic (wrapped for failure logging) ---
  logit_result <- tryCatch({
    fit <- glm(ind_gt0 ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
               data = dat, family = binomial)
    list(fit = fit, error = NA_character_)
  }, warning = function(w) {
    list(fit = NULL, error = paste("WARNING:", conditionMessage(w)))
  }, error = function(e) {
    list(fit = NULL, error = paste("ERROR:", conditionMessage(e)))
  })

  fit1        <- logit_result$fit
  logit_error <- logit_result$error

  c1 <- if (!is.null(fit1)) {
    coef(summary(fit1))["ind_post:ind_tx", c("Estimate", "Std. Error")]
  } else {
    c(NA_real_, NA_real_)
  }

  # --- Gamma fit object (safe, with failure logging) ---
  gamma_result <- safe_gamma_fit(dat)
  fit2         <- gamma_result$fit
  gamma_error  <- gamma_result$error

  c2 <- if (!is.null(fit2)) {
    coef(summary(fit2))["ind_post:ind_tx", c("Estimate", "Std. Error")]
  } else {
    c(NA_real_, NA_real_)
  }

  # --- ATT requires both model objects ---
  ATT_hat  <- if (!is.null(fit1) && !is.null(fit2)) compute_ATT_hat(dat, fit1, fit2) else NA_real_
  ATT_true <- compute_true_ATT(dat, COEF)
  ATT_bias <- ATT_hat - ATT_true

  # --- Effect size (Cohen's d style): standardize ATT by baseline SD ---
  sd_ref <- compute_sd_ref(dat, ref = es_ref)
  d_hat  <- ifelse(is.na(ATT_hat)  || is.na(sd_ref), NA_real_, ATT_hat  / sd_ref)
  d_true <- ifelse(is.na(ATT_true) || is.na(sd_ref), NA_real_, ATT_true / sd_ref)
  d_bias <- d_hat - d_true

  # --- failed flag: TRUE if either model failed ---
  failed <- is.null(fit1) || is.null(fit2)

  tibble(
    model = c("logit", "gamma", "ATT"),
    est   = c(unname(c1[1]), unname(c2[1]), ATT_hat),
    se    = c(unname(c1[2]), unname(c2[2]), NA_real_),
    true  = c(COEF$p1$int, COEF$p2$int, ATT_true),
    bias  = c(unname(c1[1]) - COEF$p1$int,
              unname(c2[1]) - COEF$p2$int,
              ATT_bias),

    # effect-size columns (only meaningful for ATT row; NA for others)
    d_est  = c(NA_real_, NA_real_, d_hat),
    d_true = c(NA_real_, NA_real_, d_true),
    d_bias = c(NA_real_, NA_real_, d_bias),

    n = n, prop_extreme, magnitude_level, gamma_shape, treatment,

    # failure logging columns
    failed      = failed,
    logit_error = c(logit_error, NA_character_, NA_character_),
    gamma_error = c(NA_character_, gamma_error, NA_character_)
  )
}
```  

```{r run_mc}

# UPDATED: run_mc now uses a for loop instead of replicate() so that
# per-replication crashes are caught and logged rather than lost.
# A failure summary is printed to the console after every run.
run_mc <- function(B, n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF,
                   es_ref = "control_pre") {

  results <- vector("list", B)

  for (i in seq_len(B)) {
    results[[i]] <- tryCatch({
      run_one(n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF,
              es_ref = es_ref)
    }, error = function(e) {
      # Complete run_one() crash â€” return a minimal failure record for all 3 model rows
      tibble(
        model           = c("logit", "gamma", "ATT"),
        est             = NA_real_,
        se              = NA_real_,
        true            = NA_real_,
        bias            = NA_real_,
        d_est           = NA_real_,
        d_true          = NA_real_,
        d_bias          = NA_real_,
        n               = n,
        prop_extreme    = prop_extreme,
        magnitude_level = magnitude_level,
        gamma_shape     = gamma_shape,
        treatment       = treatment,
        failed          = TRUE,
        logit_error     = paste("CRASH:", conditionMessage(e)),
        gamma_error     = paste("CRASH:", conditionMessage(e))
      )
    })
  }

  out <- bind_rows(results)

  # --- Print failure summary to console after each run_mc call ---
  n_failed <- out %>%
    filter(model == "gamma", failed == TRUE) %>%
    nrow()

  failure_reasons <- out %>%
    filter(model == "gamma", failed == TRUE) %>%
    count(gamma_error, sort = TRUE)

  message(sprintf(
    "\n--- run_mc failure summary [n=%s, mag=%s, prop=%s, trt=%s]: %d / %d replications failed ---",
    n, magnitude_level, prop_extreme, treatment, n_failed, B
  ))
  if (nrow(failure_reasons) > 0) {
    message("Failure reasons (gamma model):")
    print(failure_reasons)
  }

  out
}

```

#Step 1: Representative dataset (histograms + model fits)
```{r}
set.seed(123)
dat_example <- simulate_panel_data(
  n = 1000,
  magnitude_level = 1,
  prop_extreme = 0.05,
  gamma_shape = 3,
  COEF = COEF
)

p1 <- ggplot(dat_example, aes(x = TOTEXPYY)) +
  geom_histogram(bins = 100, fill = "skyblue", color = "black") +
  scale_x_continuous(labels = scales::comma) +
  labs(title = "Histogram of TOTEXPYY", x = "Spending", y = "Count") +
  theme_minimal()

p2 <- ggplot(dat_example, aes(x = TOTEXPYY)) +
  geom_histogram(bins = 100, fill = "seagreen", color = "black") +
  scale_x_log10(labels = scales::comma) +
  labs(title = "Histogram of TOTEXPYY (log scale)", x = "Spending (log)", y = "Count") +
  theme_minimal()

print(p1); print(p2)

fit_logit <- glm(ind_gt0 ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
                 data = dat_example, family = binomial)

fit_gamma <- glm(TOTEXPYY ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
                 data = dat_example %>% filter(ind_gt0 == 1),
                 family = Gamma(link = "log"))

summary(fit_logit)
summary(fit_gamma)

```

#Step 2: Full Monte Carlo across scenarios
```{r full_mc}
n_vals <- c(5000, 10000, 20000)
prop_extreme_vals <- c(0.01, 0.05, 0.10)
magnitude_vals <- c(1, 2, 3)
treatment_methods <- c("raw", "topcode", "mean_adj", "median_adj", "truncate")

grid <- expand.grid(
  n = n_vals,
  prop_extreme = prop_extreme_vals,
  magnitude_level = magnitude_vals,
  treatment = treatment_methods,
  stringsAsFactors = FALSE
)

set.seed(2025)
B <- 500

# Effect size reference group choice:
# "control_pre" (recommended), "pooled_pre", or "control_all"
ES_REF <- "control_pre"

all_df <- furrr::future_pmap_dfr(
  grid,
  ~ run_mc(B, ..1, ..3, ..2, gamma_shape = 3, ..4, COEF = COEF, es_ref = ES_REF),
  .options=furrr::furrr_options(seed=TRUE)
)

# Save raw simulation output
saveRDS(all_df, file = here::here(paste0("results/all_df_", dt, ".RDS")))
write.csv(all_df, file = here::here(paste0("results/all_df_", dt, ".csv")))

# --- Save a separate failure log for dissertation documentation ---
failure_log <- all_df %>%
  filter(failed == TRUE) %>%
  select(model, n, prop_extreme, magnitude_level, treatment,
         gamma_shape, logit_error, gamma_error) %>%
  distinct()

write.csv(failure_log,
          file = here::here(paste0("results/failure_log_", dt, ".csv")),
          row.names = FALSE)

message(sprintf("\nTotal failed replications (gamma model): %d / %d",
                sum(all_df$model == "gamma" & all_df$failed == TRUE, na.rm = TRUE),
                sum(all_df$model == "gamma")))

```


#Summarise results (includes ATT effect size columns)
```{r}
summ_grid <- all_df %>%
  group_by(model, n, prop_extreme, magnitude_level, treatment) %>%
  summarise(
    mean_est  = round(mean(est, na.rm = TRUE), 6),
    mean_true = round(mean(true, na.rm = TRUE), 6),
    bias      = round(mean(bias, na.rm = TRUE), 6),
    emp_se = round(sd(est, na.rm = TRUE), 6),
    rmse   = round(sqrt(mean((est - true)^2, na.rm = TRUE)), 6),

    coverage = round(
      mean((est - 1.96*se <= true) & (true <= est + 1.96*se), na.rm = TRUE),
      6
    ),

    # Effect size summary (ATT rows only; NA otherwise)
    d_mean   = round(mean(d_est, na.rm = TRUE), 6),
    d_emp_se = round(sd(d_est, na.rm = TRUE), 6),
    d_bias   = round(mean(d_bias, na.rm = TRUE), 6),

    n_fail = sum(is.na(est)),
    .groups = "drop"
  )

print(summ_grid)

saveRDS(summ_grid, file = here::here(paste0("results/summ_grid_", dt, ".RDS")))
write.csv(summ_grid, file = here::here(paste0("results/summ_grid_", dt, ".csv")), row.names = FALSE)

```
