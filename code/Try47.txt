---
title: "Untitled"
author: "Felix"
date: "2/2/2026"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r pkgs}
pacman::p_load(
  MASS,
  dplyr,
  tibble,
  purrr,
  furrr,
  readr,
  ggplot2,
  tidyr,
  broom,
  lubridate,
  here,
  scales
)

dt <- lubridate::today()
dir.create("results", showWarnings = FALSE)
dir.create("figures", showWarnings = FALSE)

```


#0) ONE SOURCE OF TRUTH: DGP COEFFICIENTS

```{r helpers}
COEF <- list(
  p1 = list(b0 = 0.0, post = 0.2, tx = -0.2, int = 0.0,
            female = 1.2, hisp = -0.8, zpcs = -0.2),
  p2 = list(b0 = 7.0, post = 0.2, tx =  0.2, int = 0.0,
            female = 0.4, hisp = -0.2, zpcs = -0.4)
)

# --- helper: log-uniform draw for extremes ---
rlogunif <- function(n, min_val, max_val) {
  if (n <= 0) return(numeric(0))
  exp(runif(n, log(min_val), log(max_val)))
}

# --- helper: extreme value ranges ---
extreme_range <- function(mag_level) {
  switch(as.character(mag_level),
         "1" = c(5e4, 1e6),
         "2" = c(5e4, 2e6),
         "3" = c(5e4, 3e6),
         stop("Invalid magnitude_level"))
}

```

#1) DGP: two-part Gamma with extremes

```{r sim}
simulate_panel_data <- function(
  n, magnitude_level, prop_extreme = 0.01,
  p_treated = 0.5, sigma_u = 0.5, rho = 0.5,
  gamma_shape = 3,
  COEF
) {
  T <- 2; N <- n * T
  ids <- rep(1:n, each = T)
  ind_post <- rep(0:1, times = n)

  # covariates
  ind_tx_i     <- rbinom(n, 1, p_treated)
  ind_female_i <- rbinom(n, 1, 0.5)
  HISPANX_i    <- rbinom(n, 1, 0.2)
  #INSCOV_i     <- sample(1:3, n, replace = TRUE)

  ind_tx     <- rep(ind_tx_i, each = T)
  ind_female <- rep(ind_female_i, each = T)
  HISPANX    <- rep(HISPANX_i, each = T)
  #INSCOV     <- factor(rep(INSCOV_i, each = T))

  # PCS42 with correlation (keep your approach)
  Sigma <- matrix(c(1, rho, rho, 1), 2, 2)
  pcs   <- MASS::mvrnorm(n, mu = c(50, 50), Sigma = Sigma)
  PCS42 <- as.vector(t(pcs))
  zPCS  <- (PCS42 - 50) / 10  # standardized PCS42

  # random intercept (kept for fidelity; not used in lp by design)
  u_i <- rnorm(n, 0, sigma_u)
  u   <- u_i[ids]

  # Part 1: logistic >0 (use COEF)
  lp_cov <- COEF$p1$b0 +
    COEF$p1$post   * ind_post +
    COEF$p1$tx     * ind_tx +
    COEF$p1$int    * (ind_post * ind_tx) +
    COEF$p1$female * ind_female +
    COEF$p1$hisp   * HISPANX +
    COEF$p1$zpcs   * zPCS

  pr_pos  <- plogis(lp_cov)
  ind_gt0 <- rbinom(N, 1, pr_pos)

  # Part 2: Gamma for positives (use COEF)
  lp_cont <- COEF$p2$b0 +
    COEF$p2$post   * ind_post +
    COEF$p2$tx     * ind_tx +
    COEF$p2$int    * (ind_post * ind_tx) +
    COEF$p2$female * ind_female +
    COEF$p2$hisp   * HISPANX +
    COEF$p2$zpcs   * zPCS

  mu <- exp(lp_cont)
  shape <- gamma_shape
  scale <- mu / shape

  TOTEXPYY <- rep(0, N)
  TOTEXPYY[ind_gt0 == 1] <- rgamma(sum(ind_gt0),
                                   shape = shape,
                                   scale = scale[ind_gt0 == 1])

  # inject extremes
  K_ext <- rbinom(1, N, prop_extreme)
  if (K_ext > 0) {
    rng <- extreme_range(magnitude_level)
    idx_ext <- sample.int(N, size = K_ext, replace = FALSE)
    TOTEXPYY[idx_ext] <- rlogunif(K_ext, rng[1], rng[2])
  } else idx_ext <- integer(0)

  tibble(
    DUPERSID = factor(ids),
    ind_post, ind_tx, ind_female, HISPANX, PCS42, zPCS, #INSCOV,
    ind_gt0 = ind_gt0,
    TOTEXPYY = TOTEXPYY,
    extreme_flag = as.integer(seq_len(N) %in% idx_ext),
    magnitude_level, prop_extreme
  )
}

```


#2) Treatments for extreme values (UPDATED)
# - mean/median preserved uses values > q95 only
# - truncation removes rows (not NA)

```{r treatments}
treat_extremes_df <- function(dat, method = "raw") {
  if (method == "raw") return(dat)

  q95 <- quantile(dat$TOTEXPYY, 0.95, na.rm = TRUE)

  if (method == "topcode") {
    dat$TOTEXPYY <- pmin(dat$TOTEXPYY, q95)
    return(dat)
  }

  if (method == "mean_adj") {
    m <- mean(dat$TOTEXPYY[dat$TOTEXPYY > q95], na.rm = TRUE)
    dat$TOTEXPYY[dat$TOTEXPYY > q95] <- m
    return(dat)
  }

  if (method == "median_adj") {
    m <- median(dat$TOTEXPYY[dat$TOTEXPYY > q95], na.rm = TRUE)
    dat$TOTEXPYY[dat$TOTEXPYY > q95] <- m
    return(dat)
  }

  if (method == "truncate") {
    dat <- dat %>% filter(TOTEXPYY <= q95)
    return(dat)
  }

  stop("Unknown treatment method")
}

```

#3) Safe Gamma fit wrapper

```{r safe_gamma}
safe_gamma_fit <- function(dat) {
  dat2 <- dat %>% filter(ind_gt0 == 1, is.finite(TOTEXPYY), TOTEXPYY > 0)
  if (nrow(dat2) < 10) return(NULL)

  out <- tryCatch({
    glm(
      TOTEXPYY ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
      data = dat2,
      family = Gamma(link = "log"),
      control = glm.control(maxit = 100, epsilon = 1e-8)
    )
  }, error = function(e) NULL)

  out
}

```

#3b) Effect size helper:
```{r es_helper}
compute_sd_ref <- function(dat, ref = c("control_pre", "pooled_pre", "control_all")) {

  if (missing(dat) || is.null(dat)) {
    stop("compute_sd_ref(): you must pass a data.frame/tibble as 'dat' (e.g., compute_sd_ref(dat, ref='control_pre')).")
  }

  ref <- match.arg(ref)

  dref <- switch(
    ref,
    control_pre = dat %>% dplyr::filter(ind_tx == 0, ind_post == 0),
    pooled_pre  = dat %>% dplyr::filter(ind_post == 0),
    control_all = dat %>% dplyr::filter(ind_tx == 0)
  )

  sd_ref <- sd(dref$TOTEXPYY, na.rm = TRUE)

  # guard against degenerate / invalid SD
  if (!is.finite(sd_ref) || sd_ref <= 0) return(NA_real_)
  sd_ref
}

```

#4) ATT computation (RQ4): Estimated + TRUE using same COEF
```{r att}
compute_ATT_hat <- function(dat, fit_logit, fit_gamma) {

  treated_post <- dat %>% filter(ind_tx == 1, ind_post == 1)
  if (nrow(treated_post) == 0) return(NA_real_)

  treated_cf <- treated_post %>% mutate(ind_tx = 0)

  # Part 1: Pr(Y>0)
  p_obs <- predict(fit_logit, newdata = treated_post, type = "response")
  p_cf  <- predict(fit_logit, newdata = treated_cf,   type = "response")

  # Part 2: E[Y|Y>0] (Gamma log link; response is on original scale)
  mu_obs <- predict(fit_gamma, newdata = treated_post, type = "response")
  mu_cf  <- predict(fit_gamma, newdata = treated_cf,   type = "response")

  mean(p_obs * mu_obs - p_cf * mu_cf)
}

compute_true_ATT <- function(dat, COEF) {

  treated_post <- dat %>% filter(ind_tx == 1, ind_post == 1)
  if (nrow(treated_post) == 0) return(NA_real_)

  treated_cf <- treated_post %>% mutate(ind_tx = 0)

  # TRUE Part 1
  lp1_obs <- COEF$p1$b0 +
    COEF$p1$post   * treated_post$ind_post +
    COEF$p1$tx     * treated_post$ind_tx +
    COEF$p1$int    * (treated_post$ind_post * treated_post$ind_tx) +
    COEF$p1$female * treated_post$ind_female +
    COEF$p1$hisp   * treated_post$HISPANX +
    COEF$p1$zpcs   * treated_post$zPCS
  p_obs <- plogis(lp1_obs)

  lp1_cf <- COEF$p1$b0 +
    COEF$p1$post   * treated_cf$ind_post +
    COEF$p1$tx     * treated_cf$ind_tx +
    COEF$p1$int    * (treated_cf$ind_post * treated_cf$ind_tx) +
    COEF$p1$female * treated_cf$ind_female +
    COEF$p1$hisp   * treated_cf$HISPANX +
    COEF$p1$zpcs   * treated_cf$zPCS
  p_cf <- plogis(lp1_cf)

  # TRUE Part 2
  lp2_obs <- COEF$p2$b0 +
    COEF$p2$post   * treated_post$ind_post +
    COEF$p2$tx     * treated_post$ind_tx +
    COEF$p2$int    * (treated_post$ind_post * treated_post$ind_tx) +
    COEF$p2$female * treated_post$ind_female +
    COEF$p2$hisp   * treated_post$HISPANX +
    COEF$p2$zpcs   * treated_post$zPCS
  mu_obs <- exp(lp2_obs)

  lp2_cf <- COEF$p2$b0 +
    COEF$p2$post   * treated_cf$ind_post +
    COEF$p2$tx     * treated_cf$ind_tx +
    COEF$p2$int    * (treated_cf$ind_post * treated_cf$ind_tx) +
    COEF$p2$female * treated_cf$ind_female +
    COEF$p2$hisp   * treated_cf$HISPANX +
    COEF$p2$zpcs   * treated_cf$zPCS
  mu_cf <- exp(lp2_cf)

  mean(p_obs * mu_obs - p_cf * mu_cf)
}

```


#5) One replication under one scenario (UPDATED)
- uses zPCS in models
- returns interaction estimates + ATT outputs
- adds ATT effect size (d_est, d_true, d_bias) using baseline SD

```{r run_one}
run_one <- function(n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF,
                    es_ref = "control_pre") {

  dat <- simulate_panel_data(
    n = n,
    magnitude_level = magnitude_level,
    prop_extreme = prop_extreme,
    gamma_shape = gamma_shape,
    COEF = COEF
  )

  # Apply treatment at the DATAFRAME level
  dat <- treat_extremes_df(dat, treatment)

  # Logistic
  fit1 <- glm(ind_gt0 ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
              data = dat, family = binomial)
  c1 <- coef(summary(fit1))["ind_post:ind_tx", c("Estimate","Std. Error")]

  # Gamma fit object (safe)
  fit2 <- safe_gamma_fit(dat)
  if (is.null(fit2)) {
    c2 <- c(NA_real_, NA_real_)
  } else {
    c2 <- coef(summary(fit2))["ind_post:ind_tx", c("Estimate","Std. Error")]
  }

  # ATT requires gamma object
  ATT_hat  <- if (!is.null(fit2)) compute_ATT_hat(dat, fit1, fit2) else NA_real_
  ATT_true <- compute_true_ATT(dat, COEF)
  ATT_bias <- ATT_hat - ATT_true

  # --- Effect size (Cohen's d style): standardize ATT by baseline SD ---
  sd_ref <- compute_sd_ref(dat, ref = es_ref)
  d_hat  <- ifelse(is.na(ATT_hat)  || is.na(sd_ref), NA_real_, ATT_hat  / sd_ref)
  d_true <- ifelse(is.na(ATT_true) || is.na(sd_ref), NA_real_, ATT_true / sd_ref)
  d_bias <- d_hat - d_true

  tibble(
    model = c("logit", "gamma", "ATT"),
    est   = c(unname(c1[1]), unname(c2[1]), ATT_hat),
    se    = c(unname(c1[2]), unname(c2[2]), NA_real_),
    true  = c(COEF$p1$int, COEF$p2$int, ATT_true),
    bias  = c(unname(c1[1]) - COEF$p1$int,
              unname(c2[1]) - COEF$p2$int,
              ATT_bias),

    # effect-size columns (only meaningful for ATT row; NA for others)
    d_est  = c(NA_real_, NA_real_, d_hat),
    d_true = c(NA_real_, NA_real_, d_true),
    d_bias = c(NA_real_, NA_real_, d_bias),

    n = n, prop_extreme, magnitude_level, gamma_shape, treatment
  )
}

run_mc <- function(B, n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF,
                   es_ref = "control_pre") {
  results <- replicate(
    B,
    run_one(n, magnitude_level, prop_extreme, gamma_shape, treatment, COEF, es_ref = es_ref),
    simplify = FALSE
  )
  bind_rows(results)
}

```

#Step 1: Representative dataset (histograms + model fits)
```{r}
set.seed(123)
dat_example <- simulate_panel_data(
  n = 1000,
  magnitude_level = 1,
  prop_extreme = 0.05,
  gamma_shape = 3,
  COEF = COEF
)

p1 <- ggplot(dat_example, aes(x = TOTEXPYY)) +
  geom_histogram(bins = 100, fill = "skyblue", color = "black") +
  scale_x_continuous(labels = scales::comma) +
  labs(title = "Histogram of TOTEXPYY", x = "Spending", y = "Count") +
  theme_minimal()

p2 <- ggplot(dat_example, aes(x = TOTEXPYY)) +
  geom_histogram(bins = 100, fill = "seagreen", color = "black") +
  scale_x_log10(labels = scales::comma) +
  labs(title = "Histogram of TOTEXPYY (log scale)", x = "Spending (log)", y = "Count") +
  theme_minimal()

print(p1); print(p2)

fit_logit <- glm(ind_gt0 ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
                 data = dat_example, family = binomial)

fit_gamma <- glm(TOTEXPYY ~ ind_post*ind_tx + ind_female + HISPANX + zPCS,
                 data = dat_example %>% filter(ind_gt0 == 1),
                 family = Gamma(link = "log"))

summary(fit_logit)
summary(fit_gamma)

```

#Step 2: Full Monte Carlo across scenarios
```{r full_mc}
n_vals <- c(5000, 10000, 20000)
prop_extreme_vals <- c(0.01, 0.05, 0.10)
magnitude_vals <- c(1, 2, 3)
treatment_methods <- c("raw", "topcode", "mean_adj", "median_adj", "truncate")

grid <- expand.grid(
  n = n_vals,
  prop_extreme = prop_extreme_vals,
  magnitude_level = magnitude_vals,
  treatment = treatment_methods,
  stringsAsFactors = FALSE
)

set.seed(2025)
B <- 500

# Effect size reference group choice:
# "control_pre" (recommended), "pooled_pre", or "control_all"
ES_REF <- "control_pre"

all_df <- furrr::future_pmap_dfr(
  grid,
  ~ run_mc(B, ..1, ..3, ..2, gamma_shape = 3, ..4, COEF = COEF, es_ref = ES_REF),
  .options=furrr::furrr_options(seed=TRUE)
)

# Save raw simulation output
saveRDS(all_df, file = here::here(paste0("results/all_df_", dt, ".RDS")))
write.csv(all_df, file = here::here(paste0("results/all_df_", dt, ".csv")), row.names = FALSE)

```


#Summarise results (includes ATT effect size columns)
```{r}
summ_grid <- all_df %>%
  group_by(model, n, prop_extreme, magnitude_level, treatment) %>%
  summarise(
    mean_est  = round(mean(est, na.rm = TRUE), 6),
    mean_true = round(mean(true, na.rm = TRUE), 6),
    bias      = round(mean(bias, na.rm = TRUE), 6),

    emp_se = round(sd(est, na.rm = TRUE), 6),
    rmse   = round(sqrt(mean((est - true)^2, na.rm = TRUE)), 6),

    coverage = round(
      mean((est - 1.96*se <= true) & (true <= est + 1.96*se), na.rm = TRUE),
      6
    ),

    # Effect size summary (ATT rows only; NA otherwise)
    d_mean   = round(mean(d_est, na.rm = TRUE), 6),
    d_emp_se = round(sd(d_est, na.rm = TRUE), 6),
    d_bias   = round(mean(d_bias, na.rm = TRUE), 6),

    n_fail = sum(is.na(est)),
    .groups = "drop"
  )

print(summ_grid)

saveRDS(summ_grid, file = here::here(paste0("results/summ_grid_", dt, ".RDS")))
write.csv(summ_grid, file = here::here(paste0("results/summ_grid_", dt, ".csv")), row.names = FALSE)

```


##4 FULL-FACTORIAL ANOVA (RQ answers)
```{r}
# ---- Gamma (Part 2 interaction): bias, SE, coverage ----
all_df_gamma <- all_df %>%
  dplyr::filter(model == "gamma") %>%
  dplyr::mutate(
    n = factor(n),
    prop_extreme = factor(prop_extreme),
    magnitude_level = factor(magnitude_level),
    treatment = factor(treatment),
    cover_ind = ifelse(is.na(est) | is.na(se), NA_real_,
                       as.numeric((est - 1.96*se <= true) & (true <= est + 1.96*se)))
  )

saveRDS(all_df_gamma, file = here::here(paste0("results/all_df_gamma_", dt, ".RDS")))
write.csv(all_df_gamma, file = here::here(paste0("results/all_df_gamma_", dt, ".csv")), row.names = FALSE)

# A) factorial ANOVA on gamma bias (rep-level)
aov_gamma_bias <- aov(bias ~ treatment * n * prop_extreme * magnitude_level, data = all_df_gamma)
summary(aov_gamma_bias)

# B) factorial ANOVA on gamma SE (rep-level)  <-- model SE
# aov_gamma_se <- aov(se ~ treatment * n * prop_extreme * magnitude_level, data = all_df_gamma)
# summary(aov_gamma_se)

# B v2) factorial ANOVA on gamma emp SE  (vs model SE, bc emp SE is the SD of the 500 est's of the coefficient, not the average of the model SE's, right?)
summ_grid_gamma <- summ_grid |> filter(model=="gamma")
aov_gamma_emp_se <- aov(
	emp_se ~ treatment * n * prop_extreme * magnitude_level, data = summ_grid_gamma )
summary(aov_gamma_emp_se) 

# C) coverage: scenario-level proportion (recommended)
cov_grid <- all_df_gamma %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(coverage = mean(cover_ind, na.rm = TRUE), .groups = "drop")

aov_gamma_cov <- aov(coverage ~ treatment * n * prop_extreme * magnitude_level, data = cov_grid)
summary(aov_gamma_cov)

# ---- ATT (RQ4): ATT_hat, ATT_bias, and effect size across treatments ----
all_df_att <- all_df %>%
  dplyr::filter(model == "ATT") %>%
  dplyr::mutate(
    n = factor(n),
    prop_extreme = factor(prop_extreme),
    magnitude_level = factor(magnitude_level),
    treatment = factor(treatment)
  )

# ATT_hat across conditions
aov_att_hat <- aov(est ~ treatment * n * prop_extreme * magnitude_level, data = all_df_att)
summary(aov_att_hat)

# ATT_bias across conditions (recommended DV)
aov_att_bias <- aov(bias ~ treatment * n * prop_extreme * magnitude_level, data = all_df_att)
summary(aov_att_bias)

# Effect size (d_est) across conditions (optional but usually helpful)
aov_att_d <- aov(d_est ~ treatment * n * prop_extreme * magnitude_level, data = all_df_att)
summary(aov_att_d)

# Save ANOVA-ready datasets
write.csv(all_df_gamma, file = here::here(paste0("results/all_df_gamma_", dt, ".csv")), row.names = FALSE)
write.csv(all_df_att,   file = here::here(paste0("results/all_df_att_", dt, ".csv")), row.names = FALSE)
write.csv(cov_grid,     file = here::here(paste0("results/cov_grid_", dt, ".csv")), row.names = FALSE)

```


#Publication-ready plots

```{r}
# ---- 1) Gamma bias by treatment (scenario-level mean bias) ----
gamma_grid <- all_df_gamma %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(
    mean_bias = mean(bias, na.rm = TRUE),
    mean_se   = mean(se, na.rm = TRUE),
    coverage  = mean(cover_ind, na.rm = TRUE),
    .groups = "drop"
  )

p_gamma_bias <- ggplot(gamma_grid, aes(x = treatment, y = mean_bias)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "Gamma (Part 2) Interaction: Mean Bias by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean bias (est - true)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_gamma_bias)
ggsave(here::here(paste0("figures/gamma_bias_by_treatment_", dt, ".png")),
       p_gamma_bias, width = 10, height = 7, dpi = 300)

# ---- 2) Gamma SE by treatment ----
p_gamma_se <- ggplot(gamma_grid, aes(x = treatment, y = mean_se)) +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "Gamma (Part 2) Interaction: Mean Model SE by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean SE"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_gamma_se)
ggsave(here::here(paste0("figures/gamma_se_by_treatment_", dt, ".png")),
       p_gamma_se, width = 10, height = 7, dpi = 300)

# ---- 3) Gamma coverage by treatment ----
p_gamma_cov <- ggplot(gamma_grid, aes(x = treatment, y = coverage)) +
  geom_hline(yintercept = 0.95, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "Gamma (Part 2) Interaction: Coverage by Treatment",
    subtitle = "Dashed line = nominal 0.95; Rows = prop extreme; Cols = magnitude",
    x = "Treatment method",
    y = "Coverage"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_gamma_cov)
ggsave(here::here(paste0("figures/gamma_coverage_by_treatment_", dt, ".png")),
       p_gamma_cov, width = 10, height = 7, dpi = 300)

# ---- 4) ATT_hat and effect size by treatment ----
att_grid <- all_df_att %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(
    mean_ATT_hat  = mean(est, na.rm = TRUE),
    mean_ATT_bias = mean(bias, na.rm = TRUE),
    mean_d        = mean(d_est, na.rm = TRUE),
    .groups = "drop"
  )

p_att_hat <- ggplot(att_grid, aes(x = treatment, y = mean_ATT_hat)) +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "ATT_hat (RQ4): Mean Estimated ATT by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean ATT_hat"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_att_hat)
ggsave(here::here(paste0("figures/att_hat_by_treatment_", dt, ".png")),
       p_att_hat, width = 10, height = 7, dpi = 300)

p_att_bias <- ggplot(att_grid, aes(x = treatment, y = mean_ATT_bias)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "ATT_bias (RQ4): Mean ATT Bias by Treatment",
    subtitle = "Rows = proportion extreme; Cols = magnitude level",
    x = "Treatment method",
    y = "Mean ATT bias (ATT_hat - ATT_true)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_att_bias)
ggsave(here::here(paste0("figures/att_bias_by_treatment_", dt, ".png")),
       p_att_bias, width = 10, height = 7, dpi = 300)

# ---- 6) Effect size (d) by treatment (optional but recommended) ----
p_att_d <- ggplot(att_grid, aes(x = treatment, y = mean_d)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_point() +
  geom_line(aes(group = 1)) +
  facet_grid(prop_extreme ~ magnitude_level, labeller = label_both) +
  labs(
    title = "ATT Effect Size (d): Mean Standardized ATT by Treatment",
    subtitle = paste0("Standardized by baseline SD (", ES_REF, "); Rows = prop extreme; Cols = magnitude"),
    x = "Treatment method",
    y = "Mean d (ATT / baseline SD)"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

print(p_att_d)
ggsave(here::here(paste0("figures/att_effect_size_d_by_treatment_", dt, ".png")),
       p_att_d, width = 10, height = 7, dpi = 300)

# Export scenario-level grids for tables
write.csv(gamma_grid, file = here::here(paste0("results/gamma_grid_", dt, ".csv")), row.names = FALSE)
write.csv(att_grid,   file = here::here(paste0("results/att_grid_", dt, ".csv")), row.names = FALSE)

```
```{r}
pacman::p_load(glue, gt, forcats, ggrepel)
```  

```{r descriptives}

# Focus on the Gamma Part-2 interaction (can switch to "ATT" similarly)
summ_gamma <- summ_grid %>%
  dplyr::filter(model == "gamma") %>%
  dplyr::mutate(
    treatment = forcats::fct_relevel(
      treatment, "raw", "topcode", "mean_adj", "median_adj", "truncate"
    )
  )

# Table: Descriptive statistics across ALL scenarios (collapse over n/prop/mag)
tab_gamma_overall <- summ_gamma %>%
  group_by(treatment) %>%
  summarise(
    scenarios = dplyr::n(),
    mean_bias   = mean(bias, na.rm = TRUE),
    median_bias = median(bias, na.rm = TRUE),
    mad_bias    = mad(bias, na.rm = TRUE),
    mean_abs_bias = mean(abs(bias), na.rm = TRUE),
    mean_emp_se = mean(emp_se, na.rm = TRUE),
    sd_emp_se   = sd(emp_se, na.rm = TRUE),
    mean_cov    = mean(coverage, na.rm = TRUE),
    p_cov_below_95 = mean(coverage < 0.95, na.rm = TRUE),   # share of scenarios under nominal
    .groups = "drop"
  )

# Render nicely
gt_gamma_overall <- tab_gamma_overall %>%
  mutate(
    mean_bias = scales::number(mean_bias, accuracy = 0.0001),
    median_bias = scales::number(median_bias, accuracy = 0.0001),
    mad_bias = scales::number(mad_bias, accuracy = 0.0001),
    mean_abs_bias = scales::number(mean_abs_bias, accuracy = 0.0001),
    mean_emp_se = scales::number(mean_emp_se, accuracy = 0.0001),
    sd_emp_se = scales::number(sd_emp_se, accuracy = 0.0001),
    mean_cov = scales::percent(mean_cov, accuracy = 0.1),
    p_cov_below_95 = scales::percent(p_cov_below_95, accuracy = 0.1)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction: Descriptive Statistics by Treatment (All Scenarios)",
    subtitle = "Bias (<0 underestimates), empirical SE (MC SD), and coverage"
  ) %>%
  gt::fmt_markdown(columns = everything())

gt_gamma_overall
```  

```{r over_underests}
# Replicate-level indicator of underestimation for gamma model
under_over_scen <- all_df %>%
  dplyr::filter(model == "gamma") %>%
  group_by(treatment, n, prop_extreme, magnitude_level) %>%
  summarise(
    under_rate = mean(est < true, na.rm = TRUE),
    over_rate  = mean(est > true, na.rm = TRUE),
    .groups = "drop"
  )

# Scenario-level merge with your empirical SE and coverage
scenario_stats <- summ_gamma %>%
  left_join(under_over_scen,
            by = c("treatment", "n", "prop_extreme", "magnitude_level")) %>%
  mutate(
    # 'consistently under' if majority of reps are < 0 bias in that scenario
    under_majority = under_rate > 0.5,
    over_majority  = over_rate > 0.5
  )

# Aggregate to treatment-level “consistency” table
tab_consistency <- scenario_stats %>%
  group_by(treatment) %>%
  summarise(
    n_scen = dplyr::n(),
    # scenario-mean bias (your 'bias' already is scenario-level mean bias)
    avg_mean_bias = mean(bias, na.rm = TRUE),
    med_mean_bias = median(bias, na.rm = TRUE),
    share_scen_under = mean(bias < 0, na.rm = TRUE),    # % scenarios with negative mean bias
    share_scen_over  = mean(bias > 0, na.rm = TRUE),
    share_scen_under_majority = mean(under_majority, na.rm = TRUE),
    mean_cov = mean(coverage, na.rm = TRUE),
    mean_emp_se = mean(emp_se, na.rm = TRUE),
    .groups = "drop"
  )

gt_consistency <- tab_consistency %>%
  mutate(
    avg_mean_bias = scales::number(avg_mean_bias, accuracy = 0.0001),
    med_mean_bias = scales::number(med_mean_bias, accuracy = 0.0001),
    share_scen_under = scales::percent(share_scen_under, accuracy = 0.1),
    share_scen_over  = scales::percent(share_scen_over, accuracy = 0.1),
    share_scen_under_majority = scales::percent(share_scen_under_majority, accuracy = 0.1),
    mean_cov = scales::percent(mean_cov, accuracy = 0.1),
    mean_emp_se = scales::number(mean_emp_se, accuracy = 0.0001)
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "Gamma Interaction: Consistency of Under/Over-Estimation by Treatment",
    subtitle = "Share of scenarios with negative mean bias and with majority underestimation"
  )

gt_consistency
```  

```{r plots_dir}

plot_bias_lollipop <- scenario_stats %>%
  group_by(treatment) %>%
  summarise(
    mean_of_means = mean(bias, na.rm = TRUE),
    sd_of_means   = sd(bias, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(sign = ifelse(mean_of_means < 0, "Underestimation (−)", "Overestimation (+)"),
         treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate")) %>%
  ggplot(aes(x = treatment, y = mean_of_means, color = sign)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  geom_segment(aes(xend = treatment, y = 0, yend = mean_of_means), linewidth = 1.2) +
  geom_point(size = 3) +
  scale_color_manual(values = c("Underestimation (−)" = "#C7372F", "Overestimation (+)" = "#2B6CB0")) +
  labs(
    title = "Gamma Interaction: Average Scenario-Mean Bias by Treatment",
    subtitle = "Positive = overestimation; Negative = underestimation",
    x = NULL, y = "Average of scenario means (bias)"
  ) +
  theme_minimal() +
  theme(legend.position = "top")

plot_bias_lollipop
ggsave(here::here(paste0("figures/gamma_bias_lollipop_", dt, ".png")),
       plot_bias_lollipop, width = 8, height = 5, dpi = 300)
```  

# 2B. Trend lines for how bias changes with magnitude of extremes, prop of extremes  
```{r trend_lines}
# Treat magnitude level as numeric for trend fitting
scenario_stats_num <- scenario_stats %>%
  mutate(
    mag = as.numeric(as.character(magnitude_level)),
    treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate")
  )

plot_trends <- ggplot(scenario_stats_num,
                      aes(x = mag, y = bias, color = treatment, group = treatment)) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  stat_summary(fun = mean, geom = "line", linewidth = 1.1) +
  stat_summary(fun = mean, geom = "point", size = 2) +
  facet_grid(. ~ prop_extreme, labeller = label_both) +
  scale_x_continuous(breaks = c(1,2,3), labels = c("1","2","3")) +
  labs(
    title = "Gamma Interaction: Trend in Mean Bias Across Magnitude of Extremes",
    subtitle = "Lines show scenario-means averaged at each magnitude; facets vary the proportion extreme",
    x = "Magnitude level", y = "Scenario-mean bias"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

plot_trends
ggsave(here::here(paste0("figures/gamma_bias_trends_", dt, ".png")),
       plot_trends, width = 10, height = 5.5, dpi = 300)
```

2C. Coverage heatmap vs nominal 0.95  
```{r plot_cov_heat}
plot_cov_heat <- summ_gamma %>%
  mutate(
    treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate"),
    cell = paste0("prop=", prop_extreme, ", mag=", magnitude_level)
  ) %>%
  ggplot(aes(x = treatment, y = cell, fill = coverage)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "#C7372F", mid = "white", high = "#2B6CB0",
                       midpoint = 0.95, limits = c(0,1), labels = scales::percent) +
  labs(
    title = "Gamma Interaction: Coverage by Treatment and Scenario",
    subtitle = "Blue ≥ nominal 95%; red shows undercoverage",
    x = "Treatment", y = "Scenario (prop, mag)", fill = "Coverage"
  ) +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 30, hjust = 1))

plot_cov_heat
ggsave(here::here(paste0("figures/gamma_coverage_heat_", dt, ".png")),
       plot_cov_heat, width = 10, height = 6, dpi = 300)
```  
2D. Consistency bars: % of scenarios with majority underestimation  
```{r fig_underest}

plot_under_consistency <- scenario_stats %>%
  group_by(treatment) %>%
  summarise(share_under_majority = mean(under_majority, na.rm = TRUE), .groups = "drop") %>%
  mutate(treatment = forcats::fct_relevel(treatment, "raw","topcode","mean_adj","median_adj","truncate")) %>%
  ggplot(aes(treatment, share_under_majority)) +
  geom_col(fill = "#C7372F") +
  geom_text(aes(label = scales::percent(share_under_majority, accuracy = 0.1)),
            vjust = -0.3) +
  scale_y_continuous(labels = scales::percent_format()) +
  labs(
    title = "Gamma Interaction: Consistency of Underestimation by Treatment",
    subtitle = "% of scenarios where >50% of reps underestimated",
    x = NULL, y = "% scenarios"
  ) +
  theme_minimal()

plot_under_consistency
ggsave(here::here(paste0("figures/gamma_under_consistency_", dt, ".png")),
       plot_under_consistency, width = 8, height = 5, dpi = 300)
```  

3. Auto-generate sentences  
Summarize direction, magnitude, reliability per treatment using tables above  
```{r sentences}
sentences <- tab_consistency %>%
  mutate(
    dir = ifelse(as.numeric(avg_mean_bias) < 0, "underestimated", "overestimated"),
    abs_avg = abs(as.numeric(avg_mean_bias)),
    txt = glue::glue(
      "On average across {n_scen} scenarios, the {treatment} method {dir} ",
      "the Gamma interaction by {scales::number(abs_avg, accuracy = 0.0001)}. ",
      "Median scenario-mean bias was {med_mean_bias}. ",
      "{scales::percent(share_scen_under, accuracy = 0.1)} of scenarios had negative mean bias, ",
      "and {scales::percent(share_scen_under_majority, accuracy = 0.1)} showed majority underestimation. ",
      "Mean empirical SE was {mean_emp_se}, and mean coverage was {scales::percent(mean_cov, accuracy = 0.1)}."
    )
  ) %>%
  dplyr::pull(txt)

cat(paste0("- ", sentences, collapse = "\n"))
```  

4. Optional same for ATT and effect sizes (d)  
ATT is already computed as are standardized effects (d_est, d_bias) and they're summarized, but we can 
filter model==ATT and reuse same patterns (swapping `bias` with `d_bias` or summarizing `d_est`  
```{r tbl_att}
summ_att <- summ_grid %>% dplyr::filter(model == "ATT")

tab_att <- summ_att %>%
  group_by(treatment) %>%
  summarise(
    scenarios = dplyr::n(),
    mean_ATT_hat = mean(mean_est, na.rm = TRUE),
    mean_ATT_bias = mean(bias, na.rm = TRUE),
    mean_d = mean(d_mean, na.rm = TRUE),
    mean_d_bias = mean(d_bias, na.rm = TRUE),
    .groups = "drop"
  )

gt_att <- tab_att %>%
  mutate(
    across(c(mean_ATT_hat, mean_ATT_bias, mean_d, mean_d_bias),
           ~ scales::number(.x, accuracy = 0.0001))
  ) %>%
  gt::gt() %>%
  gt::tab_header(
    title = "ATT & Effect Size (d): Summary by Treatment"
  )

gt_att
```  

## ANOVA effect-size reporting for eta-squared with p-values for ANOVA  
```{r aov_es_pkgs}
pacman::p_load(effectsize, broom, gt, glue, forcats)
```  

Reusable helper to extract eta-squared and p-values from an aov object  
This should pull p-values from `broom::tidy()` and eta-sq from `effectsize::eta_squared()`
which matches with how ANOVAs are already fit. 

```{r aov_eta_helper} 

eta_with_p <- function(aov_obj, model_label, type = c("eta2", "partial", "generalized"),
                       include_ci = TRUE, conf_level = 0.90) {
  type <- match.arg(type)
  # 1) p-values from ANOVA table
  tab_p <- broom::tidy(aov_obj) %>%
    dplyr::filter(!is.na(term), term != "Residuals") %>%
    dplyr::select(term, p.value)
  # 2) effect sizes
  es <- switch(
    type,
    eta2 = effectsize::eta_squared(aov_obj, ci = include_ci, ci_level = conf_level),
    partial = effectsize::eta_squared(aov_obj, partial = TRUE, ci = include_ci, ci_level = conf_level),
    generalized = effectsize::eta_squared(aov_obj, generalized = TRUE, ci = include_ci, ci_level = conf_level)
  ) %>%
    as.data.frame() %>%
    dplyr::rename(term = Parameter, eta2 = Eta2, ci_low = CI_low, ci_high = CI_high)
  # 3) merge and label
  out <- dplyr::left_join(es, tab_p, by = "term") %>%
    dplyr::mutate(
      model = model_label,
      es_type = switch(type, eta2 = "eta^2", partial = "partial eta^2", generalized = "generalized eta^2"),
      stars = dplyr::case_when(
        p.value < .001 ~ "***",
        p.value < .01  ~ "**",
        p.value < .05  ~ "*",
        p.value < .10  ~ "†",
        TRUE ~ ""
      )
    ) %>%
    dplyr::select(model, es_type, term, eta2, ci_low, ci_high, p.value, stars)
  out
}
```  

Apply to ANOVAs and build tables 
Groups rows by model (gamma bias, gamma coverage, ATT: bias), reports partial eta-eq, 90% CI, p-value, and sign. marks.
If we want Type II/III SS rather than the Type I default of `aov()`, can refit with `car::Anova()` 
and pass that object to `effectsize::eta_squared()`. 
```{r}

# ---- Collect effect sizes for all models ----
es_eta2 <- dplyr::bind_rows(
  eta_with_p(aov_gamma_bias,   "Gamma bias",        "eta2"),
  eta_with_p(aov_gamma_emp_se, "Gamma empirical SE","eta2"),
  eta_with_p(aov_gamma_cov,    "Gamma coverage",    "eta2"),
  eta_with_p(aov_att_hat,      "ATT: est",          "eta2"),
  eta_with_p(aov_att_bias,     "ATT: bias",         "eta2"),
  eta_with_p(aov_att_d,        "ATT: d_est",        "eta2")
)

es_partial <- dplyr::bind_rows(
  eta_with_p(aov_gamma_bias,   "Gamma bias",        "partial"),
  eta_with_p(aov_gamma_emp_se, "Gamma empirical SE","partial"),
  eta_with_p(aov_gamma_cov,    "Gamma coverage",    "partial"),
  eta_with_p(aov_att_hat,      "ATT: est",          "partial"),
  eta_with_p(aov_att_bias,     "ATT: bias",         "partial"),
  eta_with_p(aov_att_d,        "ATT: d_est",        "partial")
)

es_gen <- dplyr::bind_rows(
  eta_with_p(aov_gamma_bias,   "Gamma bias",        "generalized"),
  eta_with_p(aov_gamma_emp_se, "Gamma empirical SE","generalized"),
  eta_with_p(aov_gamma_cov,    "Gamma coverage",    "generalized"),
  eta_with_p(aov_att_hat,      "ATT: est",          "generalized"),
  eta_with_p(aov_att_bias,     "ATT: bias",         "generalized"),
  eta_with_p(aov_att_d,        "ATT: d_est",        "generalized")
)

# ---- Main table: partial eta^2 with p-values ----
tbl_partial <- es_partial %>%
  dplyr::mutate(
    eta2_fmt = ifelse(is.na(eta2), NA_character_, scales::number(eta2, accuracy = 0.0001)),
    ci_fmt = dplyr::if_else(
      is.na(ci_low) | is.na(ci_high), "—",
      paste0("[", scales::number(ci_low, accuracy = 0.0001), ", ",
                  scales::number(ci_high, accuracy = 0.0001), "]")
    ),
    p_fmt = ifelse(is.na(p.value), "—", scales::pvalue(p.value, accuracy = 0.001))
  ) %>%
  dplyr::select(model, term, `partial eta^2` = eta2_fmt, CI = ci_fmt, `p-value` = p_fmt, sig = stars)

gt_partial <- tbl_partial %>%
  gt::gt(groupname_col = "model") %>%
  gt::tab_header(
    title = gt::md("**ANOVA Effects: Partial η² with 90% CI and p-values**"),
    subtitle = "Design factors: treatment, n, prop_extreme, magnitude_level"
  ) %>%
  gt::tab_source_note("Signif.: *** <.001, ** <.01, * <.05, † <.10") %>%
  gt::cols_align(align = "center", columns = c(`partial eta^2`, CI, `p-value`, sig))

gt_partial
```  

4. ES plots (partial eta-sq + CI) with significance marks  
To see which factors drive variance in each outcome (bias, emp_se, coverage, ATT metrics) with CIs and sign. annotations
```{r}
plot_es <- es_partial %>%
  dplyr::mutate(
    term = stringr::str_replace_all(term, ":", " × "),
    term = forcats::fct_reorder(term, eta2, .fun = max, .desc = TRUE),
    model = factor(model, levels = c("Gamma bias","Gamma empirical SE","Gamma coverage",
                                     "ATT: bias", "ATT: est", "ATT: d_est"))
  ) %>%
  ggplot(aes(x = eta2, y = term)) +
  geom_vline(xintercept = 0, linetype = "dashed", color = "grey60") +
  geom_errorbarh(aes(xmin = ci_low, xmax = ci_high), height = 0.20, color = "#2B6CB0") +
  geom_point(aes(color = model), size = 2.5) +
  geom_text(aes(label = stars), nudge_x = 0.005, vjust = 0.4, color = "black") +
  facet_wrap(~ model, ncol = 2, scales = "free_y") +
  scale_x_continuous(labels = scales::number_format(accuracy = 0.01)) +
  labs(
    title = "Effect Sizes from ANOVA: Partial η² with 90% CIs",
    subtitle = "Stars denote p-value significance for each term",
    x = "Partial η²", y = NULL, color = "Model"
  ) +
  theme_minimal() +
  theme(legend.position = "bottom")

plot_es
ggsave(here::here(paste0("figures/anova_effectsizes_partial_", dt, ".png")),
       plot_es, width = 11, height = 8, dpi = 300)
```  

5. Can auto-generate prose for Results section too, summarizing which design factors have non-trivial effects 
(e.g., partial eta-sq >= 0.01) and are stat sig. 
```{r}
summ_text <- es_partial %>%
  dplyr::mutate(
    meaningful = !is.na(eta2) & eta2 >= 0.01,
    sig = !is.na(p.value) & p.value < 0.05
  ) %>%
  dplyr::filter(meaningful | sig) %>%
  dplyr::arrange(model, dplyr::desc(eta2)) %>%
  dplyr::group_by(model) %>%
  dplyr::summarise(
    txt = paste0(
      model, ": ",
      paste0(
        glue::glue(
          "{term} (partial η²={scales::number(eta2, accuracy=0.001)}; ",
          "CI [{scales::number(ci_low, accuracy=0.001)}, {scales::number(ci_high, accuracy=0.001)}]; ",
          "p={scales::pvalue(p.value, accuracy=0.001)})"
        ),
        collapse = "; "
      )
    ),
    .groups = "drop"
  ) %>% dplyr::pull(txt)

cat(paste0("- ", summ_text, collapse = "\n"))
```   

Need to switch to Type-II/III SS? 
Can refit each as: 

```{r}
pacman::p_load(car)
fit_lm <- lm(bias ~ treatment * n * prop_extreme * magnitude_level, data = all_df_gamma)
aov_type3 <- car::Anova(fit_lm, type = 3)
effectsize::eta_squared(aov_type3, partial = TRUE, ci = TRUE)
```









