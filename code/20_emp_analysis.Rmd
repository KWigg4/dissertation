---
title: "Emp Analysis"
author: "KW"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

pacman::p_load(
  dplyr,
  tidyr,
  broom,
  gt,
  MASS,
  fitdistrplus,
  gtsummary,
  ggplot2
)

meps <- readRDS(here::here("data_processed/fyc_processed.RDS")) |> 
	select(-fct_tx) |> 
	mutate(
		fct_tx = if_else(AGELAST >= 27, 1, 0),
		fct_tx = factor(
			fct_tx, 
			levels = c("0","1"),
			labels = c("control (27-29)", "tx (23-25)"))
	)

```  

### zPCS correlation, prepost  

DO NOT USE - DUPERSID isn't right... 

Get prepost correlation for zPCS  

 - First had to average the values where 2 DUPERSID records in pre or post  
 - Pivot wider, count complete cases  

```{r corr_meps, eval=FALSE}

# 1: Some ids had >1 tp per prepost: 
n_gt1_ids <- meps %>%
  summarise(n = n(), .by = c(DUPERSID, ind_post)) %>%
  filter(n > 1) |> 
	nrow()   # 3797 of 16640 (22.82%)

# 2: Avg the records from multiple dupersids by prepost
zpcs_avg_mult <- meps |> 
  group_by(DUPERSID, ind_post) %>%
  summarise(zPCS42 = mean(zPCS42, na.rm = TRUE), .groups = "drop")

# pivot
zpcs_wide <- zpcs_avg_mult |> 
  pivot_wider(names_from = ind_post, values_from = zPCS42, names_prefix = "zPCS42_") |> 
  mutate(complete_obs = if_else(
    (!is.na(zPCS42_1) & !is.na(zPCS42_0) ), 1, 0
  ))

n_corr_cases <- sum(zpcs_wide$complete_obs)

# 4: Corr
zpcs_corr <- cor(zpcs_wide$zPCS42_0, zpcs_wide$zPCS42_1, use = "complete.obs")
# 0.4302

```  

Results:  

 - N=`r n_corr_cases` complete cases (of `r nrow(zpcs_wide)`)  
 - Correlation coefficient = `r zpcs_corr`  
 
## Processing Complete Cases
Find complete cases, average TOTEXPYY & Zpcs if >1 for each timeframe, keep other factors 
NOOOO! DUPERSID not safe to use across years (i.e. after 2018)
I found a person who was younger in 2013 than they were in 2008, 2009 (DUPERSID=40247103). Multiple examples. 

Percentiles:  
(And which is closer to 50k?)  

```{r}
summary(meps$TOTEXPYY)
p99 <- quantile(meps$TOTEXPYY, 0.99)
p95 <- quantile(meps$TOTEXPYY, 0.95)

#How many > 99th percentile? 
n_gt99th <- meps |> filter(TOTEXPYY>p99) |> nrow() #167
n_gt95th <- meps |> filter(TOTEXPYY>p95) |> nrow() #832
```   

 - There are `r n_gt99th` records > 99th percentile  
 - There are `r n_gt95th` records > 95th percentile



## Table One   

```{r}
meps |> 
	select(
		TOTEXPYY,
		pre_post,
		fct_tx,
		AGELAST,
		ind_gt0,
		PCS42,
		zPCS42,
		HISPANX,
		ind_female
		) |> 
	tbl_summary(
		by=fct_tx,
		type = list(
			AGELAST ~ "continuous",
			ind_female ~ "categorical"),
		statistic = list(all_continuous() ~ "{mean} ({sd})")
		) |> 
	add_p() |> 
	add_overall()
```




## DV    

How many zeros? (Mass at zero)  

```{r}
meps |> 
  mutate(ind_gt0 = as.factor(ind_gt0)) |> 
  select(ind_gt0) |> 
  gtsummary::tbl_summary()
```  
How many > 9k?  
```{r}
meps |> 
	mutate(
		ind_gt9k = if_else(TOTEXPYY > 9000, 1, 0),
		ind_gt9k = as.factor(ind_gt9k)) |> 
	select(ind_gt9k) |> 
	tbl_summary()
```  

Maximum value:  
```{r}
summary(meps$TOTEXPYY)
sd(meps$TOTEXPYY)
```




How many do I have > $20k? > 50k?  

```{r}
n_gt50k <- meps |> filter(TOTEXPYY>50000) |> nrow() # 35

n_gt20k <- meps |> filter(TOTEXPYY>20000) |> nrow() # 223

meps_le50k <- meps |> filter(TOTEXPYY<=50000)

meps_le20k <- meps |> filter(TOTEXPYY<=20000)
```  

### Plots  



```{r plot_a}

hist_full <- ggplot(
	meps, aes(x=TOTEXPYY))+
	geom_histogram(
		aes(y = after_stat(count)/sum(after_stat(count))), 
		fill="steelblue", bins=40)+
	theme(
		panel.background = element_blank(), 
		panel.border = element_rect(color="black", fill=NA),
		axis.ticks=element_line(color="black")
	)+
	scale_x_continuous(expand=c(0.02,0))+
	scale_y_continuous(expand=c(0,0)) +
	ylab("Fraction")+
	xlab("Total health care expenditures (dollars)")
```  


```{r hist_le20k}
meps_le20k_gt0 <- meps_le20k |> filter(TOTEXPYY > 0)

hist_le20k <- ggplot(meps_le20k_gt0, aes(x=TOTEXPYY))+
	geom_histogram(
		aes(y = after_stat(count)/sum(after_stat(count))), 
		fill="steelblue", bins=40)+
	theme(
		panel.background = element_blank(), 
		panel.border = element_rect(color="black", fill=NA),
		axis.ticks=element_line(color="black")
	)+
	scale_x_continuous(expand=c(0.02,0))+
	scale_y_continuous(expand=c(0,0), limits=c(0, 0.3)) +
	ylab("Fraction")+
	xlab("Total health care expenditures (dollars)")+
	annotate(
		"text",
		x=17500, y=0.05,
		label = glue::glue(n_gt20k, " have\nexpenditures >$20k"))

```  

```{r bar_gt0}

avg_1s_gt0 <- round(mean(meps$ind_gt0), digits=3)
avg_0s_gt0 <- 1-avg_1s_gt0

bar_gt0_prep <- data.frame(
	Expenditure = factor(c(0, 1), levels = c(0, 1)),
	Fraction = c(avg_0s_gt0, avg_1s_gt0),
	Label = c(
		paste0(avg_0s_gt0*100,"% have\nexpenditures = $0"), 
		paste0(avg_1s_gt0*100,"% have\nexpenditures >$0"))
)

(bar_gt0 <- ggplot(
	bar_gt0_prep, aes(x=Expenditure, y=Fraction))+
	geom_bar(stat="identity", fill="steelblue", width = 0.6)+
	geom_text(aes(label = Label), vjust = -0.5)+
	theme(
		panel.background = element_blank(), 
		panel.border = element_rect(color="black", fill=NA),
		axis.ticks=element_line(color="black"),
	)+
	scale_y_continuous(
		expand=c(0,0), 
		limits = c(0, 0.9))+
	labs(
		x = "Are health care expenditures positive (or 0)?",
		y = "Fraction"
	)+
	# theme_minimal(base_size = 12)+
	theme(
		axis.title.x = element_text(),
		axis.title.y = element_text())
	)

```


```{r hist_log}
meps_log <- meps |> 
  filter(TOTEXPYY > 0) |> 
  mutate(log_totexpy = log(TOTEXPYY))

(hist_log <- ggplot(
	meps_log, aes(x=log_totexpy))+
		geom_histogram(
		aes(y = after_stat(count)/sum(after_stat(count))), 
		fill="steelblue", bins=40)+
	# geom_histogram(
	# 	aes(y = ..density..), bins=30, fill="steelblue", alpha = 0.6)+
	# geom_density(color = "darkgreen")+
	# stat_function(
	# 	fun = dnorm,
	# 	args = list(mean = mean(meps_log$log_totexpy), sd=sd(meps_log$log_totexpy)),
	# 	color = "darkgreen"
	# )+
	theme(
		panel.background = element_blank(), 
		panel.border = element_rect(color="black", fill=NA),
		axis.ticks=element_line(color="black")
	)+
	scale_x_continuous(expand=c(0.02,0))+
	scale_y_continuous(expand=c(0,0), limits = c(0, 0.09)) +
	ylab("Fraction")+
	xlab("ln(Total health care expenditures), if>0"))

```    

Combine plots  

```{r combo_plots}
library(cowplot)

all_plots <- plot_grid(
	plot_grid(hist_full, bar_gt0, ncol = 2, labels = c("a", "b")), 
	NULL,
	plot_grid(hist_le20k, hist_log, ncol = 2, labels = c("c", "d")), 
	ncol = 1,
	# labels = c("a", "b", "c", "d"),
	rel_heights = c(1, 0.15, 1)
	)

all_plots

```   
Figure 1: The distribution of total health care expenditures is displayed four ways: a) full histogram incluing zeros, b) the split between zeros and nonzeros, c) the histogram of just positive values, and d) the histogram of the natural log of positive values.


### Distribution parameters  
 
```{r}
pos_exp <- meps$TOTEXPYY
pos_exp <- pos_exp[pos_exp>0 & !is.na(pos_exp)]

# (fit_gamma <- fitdist(pos_exp, distr = "gamma", method="mme"))  
# fit <- fitdistr(pos_exp, densfun="gamma")

# get shape and scale estimates via Method of Moments
shape_est <- (mean(pos_exp))^2 / var(pos_exp)
scale_est <- var(pos_exp) / mean(pos_exp)

```  

Formulas used for shape and scale estimates, results: 

 - Shape $\alpha = \frac{\mu^2}{\sigma^2}$ = `r shape_est`  
 - Scale $\theta = \frac{\sigma^2}{\mu}$  = `r scale_est`  
 


#### Fit and Compare Dns  

```{r}
fit_gamma <- fitdistrplus::fitdist(pos_exp, "gamma", method = "mme") # Method of moments
fit_lnorm <- fitdistrplus::fitdist(pos_exp, "lnorm", method = "mle") # ML
fit_weibull <- fitdistrplus::fitdist(pos_exp, "weibull", method = "mle") # ML
fitdistrplus::gofstat(list(fit_gamma, fit_lnorm, fit_weibull))
```   

```{r}
plot.legend <- c("Gamma", "Lognormal", "Weibull")
denscomp(list(fit_gamma, fit_lnorm, fit_weibull), legendtext = plot.legend)
cdfcomp(list(fit_gamma, fit_lnorm, fit_weibull), legendtext = plot.legend)
qqcomp(list(fit_gamma, fit_lnorm, fit_weibull), legendtext = plot.legend)
```








### Logit model  

Without random intercept because couldn't get conditional model to converge with random intercept. Do all without.   

```{r}
cor(meps |> select(TOTEXPYY, zPCS42))
gtsummary::tbl_summary(
	data = meps,
	by = ind_post, 
	include = c(ind_post,  zPCS42)
)

```



```{r logit_noRI}
emp_logit <- glm(
  ind_gt0 ~ ind_post*ind_tx + ind_female + HISPANX + zPCS42, 
  data = meps, 
  family = binomial)

summary(emp_logit)
```   

#### Checking for overdispersion  
In LR, variance is inherently a function of the mean so errors are expected to be heteroscedastic by definition.  

However, the variance non-constancy to worry about in LR is overdispersion (when variance in observed binary outcome data is greater than what the binomial distribution predicts). If present, causes SE to be underestimated and makes p-values too small.  

Can check for overdispersion using:  
 - chi-square test ratio: Ratio of the Residual Deviance to the Residual Degrees of freedom. Ratio should be close to 1.  
 

```{r logit_RI, eval=FALSE}
library(lme4)

emp_logit_mixed <- glmer(
  ind_gt0 ~ ind_post * ind_tx + ind_female + HISPANX + zPCS42 + (1 | DUPERSID),
  data = meps,
  family = binomial
)

summary(emp_logit_mixed)
```


```{r}
# Tidy model output, add odds ratios
(logit_table <- tidy(emp_logit) %>%
  mutate(
    odds_ratio = exp(estimate),
    p.value = round(p.value, 4),
    estimate = round(estimate, 3),
    std.error = round(std.error, 3),
    statistic = round(statistic, 2),
    odds_ratio = round(odds_ratio, 2)
  ))
```


### Gamma model  
Without random intercept / stochastic component for now  


```{r gamma_noRI}

emp_gamma <- glm(
  TOTEXPYY ~ ind_post * ind_tx + ind_female + HISPANX + zPCS42,
  data = meps |> 
    filter(ind_gt0 == 1),
  family = Gamma(link = "log")
)
# Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
#  Model failed to converge with max|grad| = 0.994663 (tol = 0.002, component 1)
# Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
#  Model is nearly unidentifiable: very large eigenvalue
# - Rescale variables?

```  


```{r gamma, eval=FALSE}

emp_gamma_mixed <- glmer(
  TOTEXPYY ~ ind_post * ind_tx + ind_female + HISPANX + zPCS42 + (1 | DUPERSID),
  data = meps |> 
    filter(ind_gt0 == 1),
  family = Gamma(link = "log")
)
# Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
#  Model failed to converge with max|grad| = 0.994663 (tol = 0.002, component 1)
# Warning in checkConv(attr(opt, "derivs"), opt$par, ctrl = control$checkConv,  :
#  Model is nearly unidentifiable: very large eigenvalue
# - Rescale variables?

```  

```{r}
(gamma_table <- tidy(emp_gamma) %>%
  mutate(
    exp_coef = exp(estimate),
    p.value = round(p.value, 4),
    estimate = round(estimate, 3),
    std.error = round(std.error, 3),
    statistic = round(statistic, 2),
    exp_coef = round(exp_coef, 2)
  ))
```  





